{"mode":"new","time":"day","days":3,"limit":100,"max_pages":50,"results":[{"subreddit":"MachineLearning","meta":{"subscribers":2991864,"active_user_count":null,"description":"Beginners -&gt; /r/mlquestions or /r/learnmachinelearning , AGI -&gt; /r/singularity, career advices -&gt; /r/cscareerquestions, datasets -&gt; r/datasets","title":"Machine Learning"},"posts":[{"id":"1nnnuwc","subreddit":"MachineLearning","title":"[D] How do you handle provenance for data?","selftext":"(Previously asked on r/mlquestions, but not much traction)    \n\nI have a Python package I'm using that appends to a sidecar (json) file for each data file that I process, one entry for each step. This gives me an audit trail of where the file originated, and what operations were performed on it before being used to train a model, etc.      \nI'm just wondering if I am reinventing the wheel? If you track provenance, how much data you include (git short hash, package versions, etc.)?      \nI currently use dvc and mlflow for experiment tracking. It sometimes seems cumbersome to create/update a dvc.yaml for everything (but maybe that's what I need to do).     \nI did find a couple of provenance packages on GitHub, but the ones I found hadn't been updated in years.    ","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Previously asked on &lt;a href=\"/r/mlquestions\"&gt;r/mlquestions&lt;/a&gt;, but not much traction)    &lt;/p&gt;\n\n&lt;p&gt;I have a Python package I&amp;#39;m using that appends to a sidecar (json) file for each data file that I process, one entry for each step. This gives me an audit trail of where the file originated, and what operations were performed on it before being used to train a model, etc.&lt;br/&gt;\nI&amp;#39;m just wondering if I am reinventing the wheel? If you track provenance, how much data you include (git short hash, package versions, etc.)?&lt;br/&gt;\nI currently use dvc and mlflow for experiment tracking. It sometimes seems cumbersome to create/update a dvc.yaml for everything (but maybe that&amp;#39;s what I need to do).&lt;br/&gt;\nI did find a couple of provenance packages on GitHub, but the ones I found hadn&amp;#39;t been updated in years.    &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"aqjo","url":"https://www.reddit.com/r/MachineLearning/comments/1nnnuwc/d_how_do_you_handle_provenance_for_data/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758550987,"thumbnail":null},{"id":"1nnnogy","subreddit":"MachineLearning","title":"[R] What’s working (or not) for interoperability between AI tools?","selftext":"How are you tackling interoperability between different models/tools and proving ROI beyond pilots for clients? Would love to hear what’s worked (or not) for you.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you tackling interoperability between different models/tools and proving ROI beyond pilots for clients? Would love to hear what’s worked (or not) for you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"nordic_lion","url":"https://www.reddit.com/r/MachineLearning/comments/1nnnogy/r_whats_working_or_not_for_interoperability/","domain":"self.MachineLearning","score":1,"num_comments":0,"created_utc":1758550569,"thumbnail":null},{"id":"1nnlh1w","subreddit":"MachineLearning","title":"[D] Accessing datasets for facial detection of genetic disorders?","selftext":"I’m looking for a theme for my Master’s thesis and I came across the idea of using facial analysis to detect genetic disorders (think Down syndrome, Sanfilippo, etc.). The problem is that I haven’t been able to get access to any major dataset for this, which has been really discouraging.\n\nIf anyone here has worked in this field before — how did you manage to get access to the necessary datasets?\n\nI’m also open to other thesis ideas, but for context:\n\nMy supervisor’s research area is facial analysis with deep learning\n\nI’d like the topic to have a medical focus\n\nAny suggestions or experiences would be super helpful!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m looking for a theme for my Master’s thesis and I came across the idea of using facial analysis to detect genetic disorders (think Down syndrome, Sanfilippo, etc.). The problem is that I haven’t been able to get access to any major dataset for this, which has been really discouraging.&lt;/p&gt;\n\n&lt;p&gt;If anyone here has worked in this field before — how did you manage to get access to the necessary datasets?&lt;/p&gt;\n\n&lt;p&gt;I’m also open to other thesis ideas, but for context:&lt;/p&gt;\n\n&lt;p&gt;My supervisor’s research area is facial analysis with deep learning&lt;/p&gt;\n\n&lt;p&gt;I’d like the topic to have a medical focus&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or experiences would be super helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Own_Application577","url":"https://www.reddit.com/r/MachineLearning/comments/1nnlh1w/d_accessing_datasets_for_facial_detection_of/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758545130,"thumbnail":null},{"id":"1nnlas0","subreddit":"MachineLearning","title":"[D] Implement Mamba from scratch or use the official github repo?","selftext":"Hello. I am looking to use Mamba for a code decoding task for my research. Should I just clone the repo and work on it or implement mamba from scratch? I read in the paper that it utilizes different sections of memory of GPU and if I implement it from scratch, I probably need to do that as well and I am not an expert in GPU programming. But still, I'd desire some level of flexibility. What could be the good option here?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am looking to use Mamba for a code decoding task for my research. Should I just clone the repo and work on it or implement mamba from scratch? I read in the paper that it utilizes different sections of memory of GPU and if I implement it from scratch, I probably need to do that as well and I am not an expert in GPU programming. But still, I&amp;#39;d desire some level of flexibility. What could be the good option here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Express_Proposal8704","url":"https://www.reddit.com/r/MachineLearning/comments/1nnlas0/d_implement_mamba_from_scratch_or_use_the/","domain":"self.MachineLearning","score":1,"num_comments":3,"created_utc":1758544655,"thumbnail":null},{"id":"1nnig4r","subreddit":"MachineLearning","title":"[D] experiment analysis workflow with wandb or mlflow","selftext":"\ndoes any one have any good workflow for analysing experiments?\n\neg the basic run a bunch of experiments, choose the best run is straightforward.\n\n\nbut typically you want to compare multiple runs\n\n# using multiple runs in analysis\n\neg how does the validation error reduce as i increase the number of hidden nodes.\n\nwhat is the relative reduction in the error? and compared to experiment variability?\n\nwhat changed between the selected runs?\n\n# extrapolating validation error\n\ni am running multiple runs, how do i extrapolate the asymptotic error (so eg i can compare runs that eg were stopped earlier, used a different learning rate)\n\n......\n\ni can download the data, but it feels like i am reinventing the wheel\n\n\neg in mlflow i download runs then have to download a separate table of metrics by iteration/epoch....\n\nthen can create a function to identify hyperparams and summarise differences from base run (ignoring eg timestamps)...\n\ntagging and notes could be helpful, but its not clear the best way to use them\n\n\ni am currently working with wandb. \n\n","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;does any one have any good workflow for analysing experiments?&lt;/p&gt;\n\n&lt;p&gt;eg the basic run a bunch of experiments, choose the best run is straightforward.&lt;/p&gt;\n\n&lt;p&gt;but typically you want to compare multiple runs&lt;/p&gt;\n\n&lt;h1&gt;using multiple runs in analysis&lt;/h1&gt;\n\n&lt;p&gt;eg how does the validation error reduce as i increase the number of hidden nodes.&lt;/p&gt;\n\n&lt;p&gt;what is the relative reduction in the error? and compared to experiment variability?&lt;/p&gt;\n\n&lt;p&gt;what changed between the selected runs?&lt;/p&gt;\n\n&lt;h1&gt;extrapolating validation error&lt;/h1&gt;\n\n&lt;p&gt;i am running multiple runs, how do i extrapolate the asymptotic error (so eg i can compare runs that eg were stopped earlier, used a different learning rate)&lt;/p&gt;\n\n&lt;p&gt;......&lt;/p&gt;\n\n&lt;p&gt;i can download the data, but it feels like i am reinventing the wheel&lt;/p&gt;\n\n&lt;p&gt;eg in mlflow i download runs then have to download a separate table of metrics by iteration/epoch....&lt;/p&gt;\n\n&lt;p&gt;then can create a function to identify hyperparams and summarise differences from base run (ignoring eg timestamps)...&lt;/p&gt;\n\n&lt;p&gt;tagging and notes could be helpful, but its not clear the best way to use them&lt;/p&gt;\n\n&lt;p&gt;i am currently working with wandb. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"seanv507","url":"https://www.reddit.com/r/MachineLearning/comments/1nnig4r/d_experiment_analysis_workflow_with_wandb_or/","domain":"self.MachineLearning","score":1,"num_comments":1,"created_utc":1758535593,"thumbnail":null},{"id":"1nni5ld","subreddit":"MachineLearning","title":"[D] Best practice for providing code during review","selftext":"I wonder, now for ICLR, we want to release the code, and we definitely will do (we always have done in the past). But for the submission, what would be the best practice?\n\nYou can upload some code as supplementary material. That has the same deadline as the main paper, and we are currently polishing the paper, and probably won't really have the time to clean up the code until that time. In the code, there is also a lot more than in the paper, lots of other ideas that we have tried but did not report, also potential interesting follow-up ideas that we don't want to publish now.\n\nI saw in some other papers, that they provide a link to an anonymized repo (via https://anonymous.4open.science/). That gives us some more time to maybe also clean up the code further after the submission deadline, as I think we can still update that (right?). So this seems to be a better option?\n\nOr we can just make a statement that we will release the code when it is accepted. So then the reviewers cannot check it right now.\n\nAlso, the code makes use of multiple frameworks which are (mostly) only used by our research group (even though they are public, and could be used by anyone), so it is pretty obvious from whom this work is. Does that already count as violation of the double-anonymous submission rule?\n\nSo, what would be the best thing to do?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wonder, now for ICLR, we want to release the code, and we definitely will do (we always have done in the past). But for the submission, what would be the best practice?&lt;/p&gt;\n\n&lt;p&gt;You can upload some code as supplementary material. That has the same deadline as the main paper, and we are currently polishing the paper, and probably won&amp;#39;t really have the time to clean up the code until that time. In the code, there is also a lot more than in the paper, lots of other ideas that we have tried but did not report, also potential interesting follow-up ideas that we don&amp;#39;t want to publish now.&lt;/p&gt;\n\n&lt;p&gt;I saw in some other papers, that they provide a link to an anonymized repo (via &lt;a href=\"https://anonymous.4open.science/\"&gt;https://anonymous.4open.science/&lt;/a&gt;). That gives us some more time to maybe also clean up the code further after the submission deadline, as I think we can still update that (right?). So this seems to be a better option?&lt;/p&gt;\n\n&lt;p&gt;Or we can just make a statement that we will release the code when it is accepted. So then the reviewers cannot check it right now.&lt;/p&gt;\n\n&lt;p&gt;Also, the code makes use of multiple frameworks which are (mostly) only used by our research group (even though they are public, and could be used by anyone), so it is pretty obvious from whom this work is. Does that already count as violation of the double-anonymous submission rule?&lt;/p&gt;\n\n&lt;p&gt;So, what would be the best thing to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"albertzeyer","url":"https://www.reddit.com/r/MachineLearning/comments/1nni5ld/d_best_practice_for_providing_code_during_review/","domain":"self.MachineLearning","score":7,"num_comments":5,"created_utc":1758534555,"thumbnail":null},{"id":"1nnhkz8","subreddit":"MachineLearning","title":"[D] Is it reasonable that reviewers aren’t required to read the appendix?","selftext":"I’ve noticed that many recent conference author guidelines explicitly say something like: *reviewers are not required to read the appendix.*\n\nTo me, that effectively gives reviewers the right to ignore material that’s already provided there—even if it directly addresses their concerns.\n\nIn a past review of mine, a reviewer gave a low initial score and negative feedback without consulting the appendix. I flagged this to the AC (including a confidential comment), but the AC essentially said this wasn’t mandatory and couldn’t be used to “correct” the reviewer’s action. The final decision went through without considering the appendix.\n\nI’m curious how others see this guideline:\n\n* Is it reasonable?\n* Does it create perverse incentives for authors (e.g., to cram everything into the main text only)?\n* Or is it a necessary boundary given reviewer workload?\n\nWould appreciate perspectives—from authors, reviewers, and ACs—on whether this policy helps or harms review quality.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve noticed that many recent conference author guidelines explicitly say something like: &lt;em&gt;reviewers are not required to read the appendix.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;To me, that effectively gives reviewers the right to ignore material that’s already provided there—even if it directly addresses their concerns.&lt;/p&gt;\n\n&lt;p&gt;In a past review of mine, a reviewer gave a low initial score and negative feedback without consulting the appendix. I flagged this to the AC (including a confidential comment), but the AC essentially said this wasn’t mandatory and couldn’t be used to “correct” the reviewer’s action. The final decision went through without considering the appendix.&lt;/p&gt;\n\n&lt;p&gt;I’m curious how others see this guideline:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is it reasonable?&lt;/li&gt;\n&lt;li&gt;Does it create perverse incentives for authors (e.g., to cram everything into the main text only)?&lt;/li&gt;\n&lt;li&gt;Or is it a necessary boundary given reviewer workload?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would appreciate perspectives—from authors, reviewers, and ACs—on whether this policy helps or harms review quality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Secondhanded_PhD","url":"https://www.reddit.com/r/MachineLearning/comments/1nnhkz8/d_is_it_reasonable_that_reviewers_arent_required/","domain":"self.MachineLearning","score":15,"num_comments":14,"created_utc":1758532340,"thumbnail":null},{"id":"1nnh6gi","subreddit":"MachineLearning","title":"[D] Mixture of Attention?","selftext":" considering a new transformer architecture (for protein/DNA models but feel free to weight in from a language perspective) and I’d love some input before I do any experimenting (low budget this semester)\n\nThe current leading edge of efficient LLMs appear to be mixtures of experts, with a number of quadratic attention layers swapped out for linear layers (IBM granite 4.0, qwen-next for ex).\n\nNVIDIA even has a paper out replacing quadratic attention with linear layers on pre-trained models (https://arxiv.org/abs/2508.15884 ).\n\nSo I wonder if it would be feasible to freeze a model after pre-training (all attention quadratic), one by one training a linear substitute for each quadratic layer.\n\nThen either based on external rules (context length, compute constraint) decide when and how many layers are flicked to linear. Or, train a router with an objective to maximize response quality, keeping generation speed up, while minimizing cost.\n\nEither way you’d have a single model, with fairly coherent tone and knowledge, that based deployment constraints (speed requirements, memory/compute limits) can be adjusted to be more, or less, linear on the fly.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;considering a new transformer architecture (for protein/DNA models but feel free to weight in from a language perspective) and I’d love some input before I do any experimenting (low budget this semester)&lt;/p&gt;\n\n&lt;p&gt;The current leading edge of efficient LLMs appear to be mixtures of experts, with a number of quadratic attention layers swapped out for linear layers (IBM granite 4.0, qwen-next for ex).&lt;/p&gt;\n\n&lt;p&gt;NVIDIA even has a paper out replacing quadratic attention with linear layers on pre-trained models (&lt;a href=\"https://arxiv.org/abs/2508.15884\"&gt;https://arxiv.org/abs/2508.15884&lt;/a&gt; ).&lt;/p&gt;\n\n&lt;p&gt;So I wonder if it would be feasible to freeze a model after pre-training (all attention quadratic), one by one training a linear substitute for each quadratic layer.&lt;/p&gt;\n\n&lt;p&gt;Then either based on external rules (context length, compute constraint) decide when and how many layers are flicked to linear. Or, train a router with an objective to maximize response quality, keeping generation speed up, while minimizing cost.&lt;/p&gt;\n\n&lt;p&gt;Either way you’d have a single model, with fairly coherent tone and knowledge, that based deployment constraints (speed requirements, memory/compute limits) can be adjusted to be more, or less, linear on the fly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Alarming-Ad8154","url":"https://www.reddit.com/r/MachineLearning/comments/1nnh6gi/d_mixture_of_attention/","domain":"self.MachineLearning","score":2,"num_comments":1,"created_utc":1758530752,"thumbnail":null},{"id":"1nngswn","subreddit":"MachineLearning","title":"[D] Semantic image synthesis state-of-the-art?","selftext":"Hi everyone. I've never done this, so decided to post.\n\nI'm looking to create black-and-white images of satellite photos of rivers, from skeletons of river images. Basically I have a dataset where I have \\[satellite\\_river\\_photo, skeleton\\_segmentation\\] pairs, and I want to train a generator to do skeleton-&gt;satellite generations from new unseen skeletons. Having an extra conditioning variable would also be of interest, but not necessarily at the beginning.\n\nSince most of the literature in this area is over 6 years old, I wanted to post and see if anyone in this community has done something similar lately and would be able to provide some guidance and what methods would be the best to start with or what papers to look at. Thanks.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;ve never done this, so decided to post.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to create black-and-white images of satellite photos of rivers, from skeletons of river images. Basically I have a dataset where I have [satellite_river_photo, skeleton_segmentation] pairs, and I want to train a generator to do skeleton-&amp;gt;satellite generations from new unseen skeletons. Having an extra conditioning variable would also be of interest, but not necessarily at the beginning.&lt;/p&gt;\n\n&lt;p&gt;Since most of the literature in this area is over 6 years old, I wanted to post and see if anyone in this community has done something similar lately and would be able to provide some guidance and what methods would be the best to start with or what papers to look at. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Big-Coyote-1785","url":"https://www.reddit.com/r/MachineLearning/comments/1nngswn/d_semantic_image_synthesis_stateoftheart/","domain":"self.MachineLearning","score":2,"num_comments":1,"created_utc":1758529244,"thumbnail":null},{"id":"1nn5x9t","subreddit":"MachineLearning","title":"[P] SDLArch-RL: Multi-Console Gaming Environment for Reinforcement Learning Research","selftext":"Hey r/MachineLearning! I've been working on addressing a persistent pain point in RL gaming research - the setup complexity and limited scope of training environments.\n\n**SDLArch-RL** is a unified RL environment that integrates multiple console emulators (N64, PS2, Dreamcast, GameCube) with standard ML frameworks. Key technical features:\n\n* **Gymnasium-compliant interface** \\- drop-in replacement for existing workflows\n* **Stable-Baselines3 integration** \\- works out-of-the-box with PPO, SAC, TD3, etc.\n* **Efficient state management** \\- leverages native emulator save states for fast episode resets\n* **Configurable observation spaces** \\- raw pixels, processed features, or memory states\n* **Action space mapping** \\- handles complex controller inputs to discrete/continuous actions\n\nCurrently supports 4 emulator backends with plans for modern console integration (PS3, Xbox 360, Wii U). The environment abstracts away emulator-specific APIs while preserving access to low-level features when needed.\n\n**Technical implementation highlights:**\n\n* SDL-based architecture for minimal overhead\n* Memory mapping support for game-specific feature extraction\n* Reproducible training through deterministic save state handling\n* Multi-game training capabilities within single environment instance\n\nThis opens up training on thousands of diverse games vs. the typical handful of custom environments. Particularly useful for transfer learning studies, multi-task RL, and curriculum learning research.\n\nHappy to discuss technical details or answer implementation questions. Thoughts on potential research applications?\n\nGit: [https://github.com/paulo101977/sdlarch-rl](https://github.com/paulo101977/sdlarch-rl)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/MachineLearning\"&gt;r/MachineLearning&lt;/a&gt;! I&amp;#39;ve been working on addressing a persistent pain point in RL gaming research - the setup complexity and limited scope of training environments.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SDLArch-RL&lt;/strong&gt; is a unified RL environment that integrates multiple console emulators (N64, PS2, Dreamcast, GameCube) with standard ML frameworks. Key technical features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Gymnasium-compliant interface&lt;/strong&gt; - drop-in replacement for existing workflows&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stable-Baselines3 integration&lt;/strong&gt; - works out-of-the-box with PPO, SAC, TD3, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficient state management&lt;/strong&gt; - leverages native emulator save states for fast episode resets&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Configurable observation spaces&lt;/strong&gt; - raw pixels, processed features, or memory states&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Action space mapping&lt;/strong&gt; - handles complex controller inputs to discrete/continuous actions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Currently supports 4 emulator backends with plans for modern console integration (PS3, Xbox 360, Wii U). The environment abstracts away emulator-specific APIs while preserving access to low-level features when needed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Technical implementation highlights:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SDL-based architecture for minimal overhead&lt;/li&gt;\n&lt;li&gt;Memory mapping support for game-specific feature extraction&lt;/li&gt;\n&lt;li&gt;Reproducible training through deterministic save state handling&lt;/li&gt;\n&lt;li&gt;Multi-game training capabilities within single environment instance&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This opens up training on thousands of diverse games vs. the typical handful of custom environments. Particularly useful for transfer learning studies, multi-task RL, and curriculum learning research.&lt;/p&gt;\n\n&lt;p&gt;Happy to discuss technical details or answer implementation questions. Thoughts on potential research applications?&lt;/p&gt;\n\n&lt;p&gt;Git: &lt;a href=\"https://github.com/paulo101977/sdlarch-rl\"&gt;https://github.com/paulo101977/sdlarch-rl&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AgeOfEmpires4AOE4","url":"https://www.reddit.com/r/MachineLearning/comments/1nn5x9t/p_sdlarchrl_multiconsole_gaming_environment_for/","domain":"youtube.com","score":5,"num_comments":0,"created_utc":1758494458,"thumbnail":"https://external-preview.redd.it/m5JkpAZWOHWXvY6hDq-zX6iBTfZDuTB1RIqpaESSSco.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=7eb577b6102b1bd688aa4158cd23d5af5dfec83f"},{"id":"1nn5wex","subreddit":"MachineLearning","title":"[P] Tracking generation provenance in multi-model workflows","selftext":"Working on an interesting problem in production RAG systems.\n\nWhen documents are generated through multiple model iterations, we lose the causal chain of prompts and contexts that created them. This makes reproducibility and debugging nearly impossible.\n\nMy approach:\n\n* Store prompt embeddings alongside generated content\n* Track model/version fingerprints\n* Maintain conversation context graphs\n* Enable temporal queries (\"show evolution of auth design\")\n\nInteresting finding: Documents that go through multiple models (Claude→GPT-4→Gemini) show measurably different semantic patterns than single-model outputs. The prompt chain becomes crucial for understanding final output.\n\nCurrently tracking 103 documents with up to 9 versions each. Can query both by content similarity AND prompt similarity.\n\nImplementation uses standard RAG pipeline but indexes prompts separately from outputs. Adds \\~15% storage overhead but query precision improved 40%.\n\nCode: [github.com/VeriTeknik/pluggedin-app](http://github.com/VeriTeknik/pluggedin-app)\n\nHas anyone explored prompt archaeology in production systems? What patterns are you seeing?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on an interesting problem in production RAG systems.&lt;/p&gt;\n\n&lt;p&gt;When documents are generated through multiple model iterations, we lose the causal chain of prompts and contexts that created them. This makes reproducibility and debugging nearly impossible.&lt;/p&gt;\n\n&lt;p&gt;My approach:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Store prompt embeddings alongside generated content&lt;/li&gt;\n&lt;li&gt;Track model/version fingerprints&lt;/li&gt;\n&lt;li&gt;Maintain conversation context graphs&lt;/li&gt;\n&lt;li&gt;Enable temporal queries (&amp;quot;show evolution of auth design&amp;quot;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Interesting finding: Documents that go through multiple models (Claude→GPT-4→Gemini) show measurably different semantic patterns than single-model outputs. The prompt chain becomes crucial for understanding final output.&lt;/p&gt;\n\n&lt;p&gt;Currently tracking 103 documents with up to 9 versions each. Can query both by content similarity AND prompt similarity.&lt;/p&gt;\n\n&lt;p&gt;Implementation uses standard RAG pipeline but indexes prompts separately from outputs. Adds ~15% storage overhead but query precision improved 40%.&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=\"http://github.com/VeriTeknik/pluggedin-app\"&gt;github.com/VeriTeknik/pluggedin-app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Has anyone explored prompt archaeology in production systems? What patterns are you seeing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"babaenki","url":"https://www.reddit.com/r/MachineLearning/comments/1nn5wex/p_tracking_generation_provenance_in_multimodel/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758494399,"thumbnail":null},{"id":"1nn56yu","subreddit":"MachineLearning","title":"[D] Is non-DL related research a poor fit for ICLR?","selftext":"I was one of the lucky people rejected from NEURIPS with 6444 scores but cranky AC, so looking to resubmit now. Since it got good reviews at NEURIPS, I'm considering submitting to ICLR incorporating suggested changes.\n\nHowever, my paper proposes a linear dimensionality reduction technique, based on information geometry. It is my understanding that ICLR is very focused on neural networks and Deep Learning, so I am worried that my paper is not a good fit, so also considering AISTATS.\n\nIs a novel linear dimensionality reduction technique too out of scope for ICLR? I am an outsider to the field, so would very much appreciate opinions.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was one of the lucky people rejected from NEURIPS with 6444 scores but cranky AC, so looking to resubmit now. Since it got good reviews at NEURIPS, I&amp;#39;m considering submitting to ICLR incorporating suggested changes.&lt;/p&gt;\n\n&lt;p&gt;However, my paper proposes a linear dimensionality reduction technique, based on information geometry. It is my understanding that ICLR is very focused on neural networks and Deep Learning, so I am worried that my paper is not a good fit, so also considering AISTATS.&lt;/p&gt;\n\n&lt;p&gt;Is a novel linear dimensionality reduction technique too out of scope for ICLR? I am an outsider to the field, so would very much appreciate opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"dherrera1911","url":"https://www.reddit.com/r/MachineLearning/comments/1nn56yu/d_is_nondl_related_research_a_poor_fit_for_iclr/","domain":"self.MachineLearning","score":32,"num_comments":11,"created_utc":1758492537,"thumbnail":null},{"id":"1nn1ig8","subreddit":"MachineLearning","title":"[D] Strategies for Routing LLMs","selftext":"","selftext_html":"","author":"ApartmentEither4838","url":"https://www.reddit.com/r/MachineLearning/comments/1nn1ig8/d_strategies_for_routing_llms/","domain":"martianlantern.github.io","score":0,"num_comments":0,"created_utc":1758483657,"thumbnail":null},{"id":"1nmu1ad","subreddit":"MachineLearning","title":"[D] Missing AAAI Reviews","selftext":"Apologies in advance if I’ve missed something in conference comms so far, but I can’t seem to see the reviews I’d received on my (rejected) AAAI submission anymore. I was able to view them the other day, but when I just went to reflect on them to help with our next revision, they were gone!\n\nDoes anyone know anything about this? Is it related to the Phase 2 review round starting?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies in advance if I’ve missed something in conference comms so far, but I can’t seem to see the reviews I’d received on my (rejected) AAAI submission anymore. I was able to view them the other day, but when I just went to reflect on them to help with our next revision, they were gone!&lt;/p&gt;\n\n&lt;p&gt;Does anyone know anything about this? Is it related to the Phase 2 review round starting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"dreamykidd","url":"https://www.reddit.com/r/MachineLearning/comments/1nmu1ad/d_missing_aaai_reviews/","domain":"self.MachineLearning","score":9,"num_comments":7,"created_utc":1758466391,"thumbnail":null},{"id":"1nmo57e","subreddit":"MachineLearning","title":"[D] Is peer review overloaded due to rejecting too many papers?","selftext":"The crazy math of queueing theory: When conferences reject a large fraction of papers, many of those submissions come back in the next cycle. But increasing rates a bit reduces drastically the unaccepted paper pool and a percentage of this smaller pool becomes again a similar number of accepted papers as when rates were low! This is not saying we should accept bad papers, the number absolute number of accepted papers changes very little because of the unaccepted pool growth!\n\nSee the interactive model + math: [https://damaru2.github.io/general/queueing\\_to\\_publish\\_in\\_AI\\_or\\_CS/](https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/)\n\nWith lower acceptance rates we end up reviewing much more to reach roughly the same number of accepted works.\n\nWhat do you think about this phenomenon? Are we re-reviewing too many papers? Physical constraints can be easily solved with federated conferences (make Eurips an official option for presentation?) or allowing not to present in person.\n\nBonus: Funnel simulation of the ideal case where authors always resubmit their papers [https://i.postimg.cc/gz88S2hY/funnel2.gif](https://i.postimg.cc/gz88S2hY/funnel2.gif) In here you can see that when authors do not give up submitting (that is, the ideal case, but in the post a more complex model is presented), and the number new of papers per round is the same for both cases, the same number of papers are accepted on average per conference in two scenarios with different acceptance rates.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The crazy math of queueing theory: When conferences reject a large fraction of papers, many of those submissions come back in the next cycle. But increasing rates a bit reduces drastically the unaccepted paper pool and a percentage of this smaller pool becomes again a similar number of accepted papers as when rates were low! This is not saying we should accept bad papers, the number absolute number of accepted papers changes very little because of the unaccepted pool growth!&lt;/p&gt;\n\n&lt;p&gt;See the interactive model + math: &lt;a href=\"https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/\"&gt;https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;With lower acceptance rates we end up reviewing much more to reach roughly the same number of accepted works.&lt;/p&gt;\n\n&lt;p&gt;What do you think about this phenomenon? Are we re-reviewing too many papers? Physical constraints can be easily solved with federated conferences (make Eurips an official option for presentation?) or allowing not to present in person.&lt;/p&gt;\n\n&lt;p&gt;Bonus: Funnel simulation of the ideal case where authors always resubmit their papers &lt;a href=\"https://i.postimg.cc/gz88S2hY/funnel2.gif\"&gt;https://i.postimg.cc/gz88S2hY/funnel2.gif&lt;/a&gt; In here you can see that when authors do not give up submitting (that is, the ideal case, but in the post a more complex model is presented), and the number new of papers per round is the same for both cases, the same number of papers are accepted on average per conference in two scenarios with different acceptance rates.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"jan_Tamalu","url":"https://www.reddit.com/r/MachineLearning/comments/1nmo57e/d_is_peer_review_overloaded_due_to_rejecting_too/","domain":"i.redd.it","score":0,"num_comments":13,"created_utc":1758449183,"thumbnail":"https://b.thumbs.redditmedia.com/_9paQpDH3FU1V5ZVCa3D-m2Iz61CHvoJmOgvlMhv8kA.jpg"},{"id":"1nmbvi5","subreddit":"MachineLearning","title":"[D] ICLR 2026 Submission Count","selftext":"I submitted to ICLR after a NeurIPS reject of a borderline paper. My submission id is above 20k! Wondering how many ICLR submissions there are in total (comment if you have a higher sub id) and how much the venue can even accommodate.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I submitted to ICLR after a NeurIPS reject of a borderline paper. My submission id is above 20k! Wondering how many ICLR submissions there are in total (comment if you have a higher sub id) and how much the venue can even accommodate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"kipthornberry","url":"https://www.reddit.com/r/MachineLearning/comments/1nmbvi5/d_iclr_2026_submission_count/","domain":"self.MachineLearning","score":38,"num_comments":16,"created_utc":1758408327,"thumbnail":null},{"id":"1nmb8as","subreddit":"MachineLearning","title":"[D] NeurIPS: rejecting papers from sanctioned affiliations mid-process","selftext":"I know multiple people and multiple papers who have received this.\n\nIt is probably legally correct. There are legit grounds for these bans.\n\nHowever, I don't think it is okay to do it AFTER reviewing and even accepting the papers. Hundreds of people wasted their time for nothing.\n\nThere was a recent post with messages to SAC about venue constraints, and this might be a way the organizers are solving this problem.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know multiple people and multiple papers who have received this.&lt;/p&gt;\n\n&lt;p&gt;It is probably legally correct. There are legit grounds for these bans.&lt;/p&gt;\n\n&lt;p&gt;However, I don&amp;#39;t think it is okay to do it AFTER reviewing and even accepting the papers. Hundreds of people wasted their time for nothing.&lt;/p&gt;\n\n&lt;p&gt;There was a recent post with messages to SAC about venue constraints, and this might be a way the organizers are solving this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"YallenGusev","url":"https://www.reddit.com/r/MachineLearning/comments/1nmb8as/d_neurips_rejecting_papers_from_sanctioned/","domain":"i.redd.it","score":118,"num_comments":57,"created_utc":1758406590,"thumbnail":"https://a.thumbs.redditmedia.com/C9vhZOKSCL8bcgNAcVnXOmK2B9T55oKMMD8l9K_3U88.jpg"},{"id":"1nmb7jm","subreddit":"MachineLearning","title":"[P] Introducing LabelMob: Connecting ML Teams with Expert Data Annotators","selftext":"Hey [r/machinelearning](https://www.reddit.com/r/machinelearning/),\n\nI've been working in the ML space for a while and noticed a big pain point: finding high-quality, domain-specific data annotators for complex datasets. Whether it's labeling quantum physics simulations, chemical structures, biological sequences, or advanced mathematical models, generic annotation services often fall short. That's why I built [LabelMob.com](https://labelmob.com/) – a platform designed to match companies, universities, and research teams with expert annotators who have real expertise in fields like physics, chemistry, math, biology, data science, and more. How It Works:\n\n* For Hirers (Companies/Universities): Post your annotation projects and specify the expertise needed. We connect you with vetted individuals or specialized annotation companies who can handle niche tasks accurately and efficiently. Think: annotating MRI scans by medical physicists or labeling molecular data by chemists.\n* For Annotators (Experts/Companies): Sign up to showcase your skills and get matched with paid gigs that align with your background. It's a great way for domain experts to monetize their knowledge on a flexible basis.\n\nThe goal is to improve dataset quality for ML models – we all know garbage in, garbage out, right? Better annotations mean better training data, leading to more reliable AI systems in research and industry.\n\n**Why Now?**\n\nWith the explosion of multimodal and specialized ML applications (e.g., drug discovery, climate modeling, autonomous systems), the demand for expert-level labeling is skyrocketing. LabelMob aims to bridge that gap without the overhead of traditional crowdsourcing platforms.\n\nI'd love feedback from this community! Have you struggled with finding the right annotators? What features would make this more useful for your workflows? Check out the site at [labelmob.com](https://labelmob.com/) and let me know your thoughts.\n\nDisclaimer: This is a new platform, so we're in early stages and actively iterating based on user input. No spamming intended – just sharing something I think could help the ML ecosystem.\n\nThanks!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"https://www.reddit.com/r/machinelearning/\"&gt;r/machinelearning&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working in the ML space for a while and noticed a big pain point: finding high-quality, domain-specific data annotators for complex datasets. Whether it&amp;#39;s labeling quantum physics simulations, chemical structures, biological sequences, or advanced mathematical models, generic annotation services often fall short. That&amp;#39;s why I built &lt;a href=\"https://labelmob.com/\"&gt;LabelMob.com&lt;/a&gt; – a platform designed to match companies, universities, and research teams with expert annotators who have real expertise in fields like physics, chemistry, math, biology, data science, and more. How It Works:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;For Hirers (Companies/Universities): Post your annotation projects and specify the expertise needed. We connect you with vetted individuals or specialized annotation companies who can handle niche tasks accurately and efficiently. Think: annotating MRI scans by medical physicists or labeling molecular data by chemists.&lt;/li&gt;\n&lt;li&gt;For Annotators (Experts/Companies): Sign up to showcase your skills and get matched with paid gigs that align with your background. It&amp;#39;s a great way for domain experts to monetize their knowledge on a flexible basis.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The goal is to improve dataset quality for ML models – we all know garbage in, garbage out, right? Better annotations mean better training data, leading to more reliable AI systems in research and industry.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why Now?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With the explosion of multimodal and specialized ML applications (e.g., drug discovery, climate modeling, autonomous systems), the demand for expert-level labeling is skyrocketing. LabelMob aims to bridge that gap without the overhead of traditional crowdsourcing platforms.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love feedback from this community! Have you struggled with finding the right annotators? What features would make this more useful for your workflows? Check out the site at &lt;a href=\"https://labelmob.com/\"&gt;labelmob.com&lt;/a&gt; and let me know your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: This is a new platform, so we&amp;#39;re in early stages and actively iterating based on user input. No spamming intended – just sharing something I think could help the ML ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"singlasahil14","url":"https://www.reddit.com/r/MachineLearning/comments/1nmb7jm/p_introducing_labelmob_connecting_ml_teams_with/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758406539,"thumbnail":null},{"id":"1nlvw1r","subreddit":"MachineLearning","title":"[R] MiniGrid DoorKeys Benchmark Active Inference","selftext":"I am working on an Active Inference Framework since some time and it has managed to constantly and reproducable perform (I guess) very well on MG-DK without any benchmaxing or training.. the numbers (average) are:\n\n8x8: &lt;19 Steps for SR 1 16x16: &lt;60 Steps for SR 1\n\nDo you know someone or a company or so who might be interested in learning more about this solution or the research involved?\n\nThank you!\n\nBest Thom","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on an Active Inference Framework since some time and it has managed to constantly and reproducable perform (I guess) very well on MG-DK without any benchmaxing or training.. the numbers (average) are:&lt;/p&gt;\n\n&lt;p&gt;8x8: &amp;lt;19 Steps for SR 1 16x16: &amp;lt;60 Steps for SR 1&lt;/p&gt;\n\n&lt;p&gt;Do you know someone or a company or so who might be interested in learning more about this solution or the research involved?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;Best Thom&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"thomheinrich","url":"https://www.reddit.com/r/MachineLearning/comments/1nlvw1r/r_minigrid_doorkeys_benchmark_active_inference/","domain":"self.MachineLearning","score":10,"num_comments":5,"created_utc":1758368222,"thumbnail":null},{"id":"1nlvvi1","subreddit":"MachineLearning","title":"[P]  Video prediction pipeline using a frozen VAE and hierarchical LSTMs to learn latent dynamics","selftext":"I wanted to share a personal project I've been working on for the past few months and get some feedback from the community. My goal was to build a stable, interactive system for video prediction by cleanly separating the perception and dynamics modeling. \n\n**The Core Architecture**\n\nThe pipeline processes a live camera feed. The main idea is to avoid expensive end-to-end training and create a more modular system.\n\n* **Frozen VAE (Perception):** I'm using the pre-trained Stable Diffusion VAE to encode frames into a latent space. By keeping it frozen, the \"perceptual manifold\" is stable, which makes learning the dynamics much easier.\n* **Three-Stage LSTM System (Dynamics):** This is where I tried to do something a bit different. Instead of one big LSTM, I'm using a hierarchy:\n   * A **Pattern LSTM** observes short sequences of latents to find basic temporal patterns.\n   * A **Compression LSTM** takes these patterns and learns a dense, compressed representation.\n   * A **Central LSTM** takes this compressed state and predicts the next latent step (Δz).\n\n**\\*NOTE:** This pipeline is capable of ALOT more than just a simple prediction model. For this project I solely focused on the vision aspect. \n\n**Performance and Results**\n\nThe whole system runs at an interactive 4-6 FPS on my consumer hardware and has a simple PyQT GUI to show the live camera feed next to the model's prediction. With better hardware i'm hoping to hit 24 FPS, but balling on a budget right now.\n\nMy main focus was on perceptual quality over raw pixel accuracy. The most encouraging result was in multi-step open-loop rollouts, where the model achieved a **peak SSIM of 0.84**. I was really happy to see this, as it's a result that's competitive with some established benchmarks on standardized datasets (like KTH).\n\n**Link to Project:**\n\nI've documented the architecture, included the performance logs, and wrote a white paper in the GitHub repo if you want to see the technical details:\n\n[github](https://github.com/A1CST/VISION_VAE_OLM_3L_PCC_PREDICTION)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to share a personal project I&amp;#39;ve been working on for the past few months and get some feedback from the community. My goal was to build a stable, interactive system for video prediction by cleanly separating the perception and dynamics modeling. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Core Architecture&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The pipeline processes a live camera feed. The main idea is to avoid expensive end-to-end training and create a more modular system.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Frozen VAE (Perception):&lt;/strong&gt; I&amp;#39;m using the pre-trained Stable Diffusion VAE to encode frames into a latent space. By keeping it frozen, the &amp;quot;perceptual manifold&amp;quot; is stable, which makes learning the dynamics much easier.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Three-Stage LSTM System (Dynamics):&lt;/strong&gt; This is where I tried to do something a bit different. Instead of one big LSTM, I&amp;#39;m using a hierarchy:\n\n&lt;ul&gt;\n&lt;li&gt;A &lt;strong&gt;Pattern LSTM&lt;/strong&gt; observes short sequences of latents to find basic temporal patterns.&lt;/li&gt;\n&lt;li&gt;A &lt;strong&gt;Compression LSTM&lt;/strong&gt; takes these patterns and learns a dense, compressed representation.&lt;/li&gt;\n&lt;li&gt;A &lt;strong&gt;Central LSTM&lt;/strong&gt; takes this compressed state and predicts the next latent step (Δz).&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;*NOTE:&lt;/strong&gt; This pipeline is capable of ALOT more than just a simple prediction model. For this project I solely focused on the vision aspect. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Performance and Results&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The whole system runs at an interactive 4-6 FPS on my consumer hardware and has a simple PyQT GUI to show the live camera feed next to the model&amp;#39;s prediction. With better hardware i&amp;#39;m hoping to hit 24 FPS, but balling on a budget right now.&lt;/p&gt;\n\n&lt;p&gt;My main focus was on perceptual quality over raw pixel accuracy. The most encouraging result was in multi-step open-loop rollouts, where the model achieved a &lt;strong&gt;peak SSIM of 0.84&lt;/strong&gt;. I was really happy to see this, as it&amp;#39;s a result that&amp;#39;s competitive with some established benchmarks on standardized datasets (like KTH).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Link to Project:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve documented the architecture, included the performance logs, and wrote a white paper in the GitHub repo if you want to see the technical details:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/A1CST/VISION_VAE_OLM_3L_PCC_PREDICTION\"&gt;github&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AsyncVibes","url":"https://www.reddit.com/r/MachineLearning/comments/1nlvvi1/p_video_prediction_pipeline_using_a_frozen_vae/","domain":"self.MachineLearning","score":1,"num_comments":0,"created_utc":1758368169,"thumbnail":null},{"id":"1nlnf5g","subreddit":"MachineLearning","title":"[D] AAAI 2026 Phase 2 Review","selftext":"Hi all,\n\nI’m serving as a reviewer for AAAI ’26. Has anyone received additional papers for the Phase 2 review yet? The website indicates that Phase 2 starts on Sep. 16, but I haven’t been assigned any papers so far.\n\n[https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic](https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic)\n\n\n\nEdit (Sep. 21): Just got assigned three extra papers!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I’m serving as a reviewer for AAAI ’26. Has anyone received additional papers for the Phase 2 review yet? The website indicates that Phase 2 starts on Sep. 16, but I haven’t been assigned any papers so far.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic\"&gt;https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit (Sep. 21): Just got assigned three extra papers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"snu95","url":"https://www.reddit.com/r/MachineLearning/comments/1nlnf5g/d_aaai_2026_phase_2_review/","domain":"self.MachineLearning","score":23,"num_comments":7,"created_utc":1758338134,"thumbnail":null},{"id":"1nliq67","subreddit":"MachineLearning","title":"[P] Benchmarked EpilepsyBench #1 winner - found 27x performance gap, now training Bi-Mamba-2 fix","selftext":"Hey all, been learning EEG ML heavily for the past two months or so.\n\nRecently evaluated SeizureTransformer (#1 on [EpilepsyBench ](https://epilepsybenchmarks.com/challenge/)with \\~1 FA/24h) on the Temple EEG dataset using clinical NEDC scoring: **26.89 FA/24h** \\- a 27x gap. Same predictions scored three ways produced 8.59 to 136.73 FA/24h depending on methodology alone.\n\n**Evaluation here:** [https://github.com/Clarity-Digital-Twin/SeizureTransformer](https://github.com/Clarity-Digital-Twin/SeizureTransformer)  \n[PDF](https://drive.google.com/file/d/1T-lmGZuWr_0YnB0m692ccgVdSRjs_Y5n/view?usp=sharing): Gdrive\n\nSo I can actually contribute instead of reproducing, I'm now training the first **Bi-Mamba-2 + U-Net + ResCNN** architecture - O(N) complexity while maintaining temporal modeling.\n\n**Training code:** [https://github.com/Clarity-Digital-Twin/brain-go-brr-v2](https://github.com/Clarity-Digital-Twin/brain-go-brr-v2)\n\nWould appreciate feedback on either if there is any interest. Also seeking arXiv endorsement for cs.LG if anyone finds this worth sharing (independent researcher).","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, been learning EEG ML heavily for the past two months or so.&lt;/p&gt;\n\n&lt;p&gt;Recently evaluated SeizureTransformer (#1 on &lt;a href=\"https://epilepsybenchmarks.com/challenge/\"&gt;EpilepsyBench &lt;/a&gt;with ~1 FA/24h) on the Temple EEG dataset using clinical NEDC scoring: &lt;strong&gt;26.89 FA/24h&lt;/strong&gt; - a 27x gap. Same predictions scored three ways produced 8.59 to 136.73 FA/24h depending on methodology alone.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Evaluation here:&lt;/strong&gt; &lt;a href=\"https://github.com/Clarity-Digital-Twin/SeizureTransformer\"&gt;https://github.com/Clarity-Digital-Twin/SeizureTransformer&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://drive.google.com/file/d/1T-lmGZuWr_0YnB0m692ccgVdSRjs_Y5n/view?usp=sharing\"&gt;PDF&lt;/a&gt;: Gdrive&lt;/p&gt;\n\n&lt;p&gt;So I can actually contribute instead of reproducing, I&amp;#39;m now training the first &lt;strong&gt;Bi-Mamba-2 + U-Net + ResCNN&lt;/strong&gt; architecture - O(N) complexity while maintaining temporal modeling.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Training code:&lt;/strong&gt; &lt;a href=\"https://github.com/Clarity-Digital-Twin/brain-go-brr-v2\"&gt;https://github.com/Clarity-Digital-Twin/brain-go-brr-v2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would appreciate feedback on either if there is any interest. Also seeking arXiv endorsement for cs.LG if anyone finds this worth sharing (independent researcher).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"VibeCoderMcSwaggins","url":"https://www.reddit.com/r/MachineLearning/comments/1nliq67/p_benchmarked_epilepsybench_1_winner_found_27x/","domain":"self.MachineLearning","score":3,"num_comments":0,"created_utc":1758324334,"thumbnail":null},{"id":"1nlfcpq","subreddit":"MachineLearning","title":"[P] Building sub-100ms autocompletion for JetBrains IDEs","selftext":"","selftext_html":"","author":"Kevinlu1248","url":"https://www.reddit.com/r/MachineLearning/comments/1nlfcpq/p_building_sub100ms_autocompletion_for_jetbrains/","domain":"blog.sweep.dev","score":13,"num_comments":2,"created_utc":1758315653,"thumbnail":null},{"id":"1nlc954","subreddit":"MachineLearning","title":"Try a Deterministic Global-Optimum Logistics Demo – Solve Huge Warehouse-to-Route Problems in Seconds [P]","selftext":"Hey everyone,\n\nI’ve been building an optimization engine that can compute **deterministically optimal warehouse-to-route assignments** for massive datasets – up to **10,000 warehouses × 500 routes** – in seconds. I’m sharing a live demo!\n\n⚠️ Heads-up: This runs on my personal machine, so requests are queued and wait times may vary.\n\n**How to use:**\n\n1. Upload a CSV or JSON file.\n2. Rows = warehouses, columns = routes.\n3. Each cell = cost of assigning that warehouse to that route.\n\n**Quick CSV example (3 warehouses × 4 routes):**\n\n    10,20,30,40\n    15,25,35,45\n    20,30,40,50\n\n🔗 **Try it here:** [https://19340a3b2e2b.ngrok-free.app](https://19340a3b2e2b.ngrok-free.app/)\n\nThis is a chance to experiment with a system that produces **true deterministic optima** for large datasets without needing a server cluster. Feedback, testing, or just trying crazy datasets is welcome!\n\n**Open from:** 2:30am AWST → 12pm AWST\n\n*(I jokingly call it a “hypercomputer” because of the speed, but it’s just my personal deterministic optimization engine!)*","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I’ve been building an optimization engine that can compute &lt;strong&gt;deterministically optimal warehouse-to-route assignments&lt;/strong&gt; for massive datasets – up to &lt;strong&gt;10,000 warehouses × 500 routes&lt;/strong&gt; – in seconds. I’m sharing a live demo!&lt;/p&gt;\n\n&lt;p&gt;⚠️ Heads-up: This runs on my personal machine, so requests are queued and wait times may vary.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How to use:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Upload a CSV or JSON file.&lt;/li&gt;\n&lt;li&gt;Rows = warehouses, columns = routes.&lt;/li&gt;\n&lt;li&gt;Each cell = cost of assigning that warehouse to that route.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick CSV example (3 warehouses × 4 routes):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;10,20,30,40\n15,25,35,45\n20,30,40,50\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;🔗 &lt;strong&gt;Try it here:&lt;/strong&gt; &lt;a href=\"https://19340a3b2e2b.ngrok-free.app/\"&gt;https://19340a3b2e2b.ngrok-free.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a chance to experiment with a system that produces &lt;strong&gt;true deterministic optima&lt;/strong&gt; for large datasets without needing a server cluster. Feedback, testing, or just trying crazy datasets is welcome!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Open from:&lt;/strong&gt; 2:30am AWST → 12pm AWST&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(I jokingly call it a “hypercomputer” because of the speed, but it’s just my personal deterministic optimization engine!)&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Active-Midnight-8834","url":"https://www.reddit.com/r/MachineLearning/comments/1nlc954/try_a_deterministic_globaloptimum_logistics_demo/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758308363,"thumbnail":null},{"id":"1nlblaw","subreddit":"MachineLearning","title":"[D] Neurips Position Paper Decisions","selftext":"The decisions will be out next week.  \nI am personally not a fan of how the entire process was conducted. Hoping the best for everyone! Please use this as a thread to discuss how you felt about the process. Fingers crossed!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The decisions will be out next week.&lt;br/&gt;\nI am personally not a fan of how the entire process was conducted. Hoping the best for everyone! Please use this as a thread to discuss how you felt about the process. Fingers crossed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"HelicopterFriendly96","url":"https://www.reddit.com/r/MachineLearning/comments/1nlblaw/d_neurips_position_paper_decisions/","domain":"self.MachineLearning","score":22,"num_comments":5,"created_utc":1758306837,"thumbnail":null},{"id":"1nl8ik3","subreddit":"MachineLearning","title":"[Project] I created an AI photo organizer that uses Ollama to sort photos, filter duplicates, and write Instagram captions.","selftext":"Hey everyone at r/MachineLearning,\n\nI wanted to share a Python project I've been working on called the **AI Instagram Organizer**.\n\n**The Problem:** I had thousands of photos from a recent trip, and the thought of manually sorting them, finding the best ones, and thinking of captions was overwhelming. I wanted a way to automate this using local LLMs.\n\n**The Solution:** I built a script that uses a multimodal model via Ollama (like LLaVA, Gemma, or Llama 3.2 Vision) to do all the heavy lifting.\n\n**Key Features:**\n\n* **Chronological Sorting:** It reads EXIF data to organize posts by the date they were taken.\n* **Advanced Duplicate Filtering:** It uses multiple perceptual hashes and a dynamic threshold to remove repetitive shots.\n* **AI Caption &amp; Hashtag Generation:** For each post folder it creates, it writes several descriptive caption options and a list of hashtags.\n* **Handles HEIC Files:** It automatically converts Apple's HEIC format to JPG.\n\nIt’s been a really fun project and a great way to explore what's possible with local vision models. I'd love to get your feedback and see if it's useful to anyone else!\n\n**GitHub Repo:** [https://github.com/summitsingh/ai-instagram-organizer](https://github.com/summitsingh/ai-instagram-organizer)\n\nSince this is my first time building an open-source AI project, any feedback is welcome. And if you like it, a star on GitHub would really make my day! ⭐","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone at &lt;a href=\"/r/MachineLearning\"&gt;r/MachineLearning&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a Python project I&amp;#39;ve been working on called the &lt;strong&gt;AI Instagram Organizer&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Problem:&lt;/strong&gt; I had thousands of photos from a recent trip, and the thought of manually sorting them, finding the best ones, and thinking of captions was overwhelming. I wanted a way to automate this using local LLMs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; I built a script that uses a multimodal model via Ollama (like LLaVA, Gemma, or Llama 3.2 Vision) to do all the heavy lifting.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Chronological Sorting:&lt;/strong&gt; It reads EXIF data to organize posts by the date they were taken.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Advanced Duplicate Filtering:&lt;/strong&gt; It uses multiple perceptual hashes and a dynamic threshold to remove repetitive shots.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AI Caption &amp;amp; Hashtag Generation:&lt;/strong&gt; For each post folder it creates, it writes several descriptive caption options and a list of hashtags.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Handles HEIC Files:&lt;/strong&gt; It automatically converts Apple&amp;#39;s HEIC format to JPG.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It’s been a really fun project and a great way to explore what&amp;#39;s possible with local vision models. I&amp;#39;d love to get your feedback and see if it&amp;#39;s useful to anyone else!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GitHub Repo:&lt;/strong&gt; &lt;a href=\"https://github.com/summitsingh/ai-instagram-organizer\"&gt;https://github.com/summitsingh/ai-instagram-organizer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since this is my first time building an open-source AI project, any feedback is welcome. And if you like it, a star on GitHub would really make my day! ⭐&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"summitsc","url":"https://www.reddit.com/r/MachineLearning/comments/1nl8ik3/project_i_created_an_ai_photo_organizer_that_uses/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758299859,"thumbnail":null},{"id":"1nl79ah","subreddit":"MachineLearning","title":"[R] A new interpretable clinical model. Tell me what you think","selftext":"Hello everyone, I wrote an article about how an XGBoost can lead to clinically interpretable models like mine. Shap is used to make statistical and mathematical interpretation viewable","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I wrote an article about how an XGBoost can lead to clinically interpretable models like mine. Shap is used to make statistical and mathematical interpretation viewable&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"ksrio64","url":"https://www.reddit.com/r/MachineLearning/comments/1nl79ah/r_a_new_interpretable_clinical_model_tell_me_what/","domain":"researchgate.net","score":0,"num_comments":2,"created_utc":1758297056,"thumbnail":null}],"partial":false}],"fetched_at":1758552494160}