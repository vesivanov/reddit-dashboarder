{"mode":"new","time":"day","days":7,"limit":100,"max_pages":50,"results":[{"subreddit":"MachineLearning","meta":{"subscribers":2991863,"active_user_count":null,"description":"Beginners -&gt; /r/mlquestions or /r/learnmachinelearning , AGI -&gt; /r/singularity, career advices -&gt; /r/cscareerquestions, datasets -&gt; r/datasets","title":"Machine Learning"},"posts":[{"id":"1nnnuwc","subreddit":"MachineLearning","title":"[D] How do you handle provenance for data?","selftext":"(Previously asked on r/mlquestions, but not much traction)    \n\nI have a Python package I'm using that appends to a sidecar (json) file for each data file that I process, one entry for each step. This gives me an audit trail of where the file originated, and what operations were performed on it before being used to train a model, etc.      \nI'm just wondering if I am reinventing the wheel? If you track provenance, how much data you include (git short hash, package versions, etc.)?      \nI currently use dvc and mlflow for experiment tracking. It sometimes seems cumbersome to create/update a dvc.yaml for everything (but maybe that's what I need to do).     \nI did find a couple of provenance packages on GitHub, but the ones I found hadn't been updated in years.    ","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Previously asked on &lt;a href=\"/r/mlquestions\"&gt;r/mlquestions&lt;/a&gt;, but not much traction)    &lt;/p&gt;\n\n&lt;p&gt;I have a Python package I&amp;#39;m using that appends to a sidecar (json) file for each data file that I process, one entry for each step. This gives me an audit trail of where the file originated, and what operations were performed on it before being used to train a model, etc.&lt;br/&gt;\nI&amp;#39;m just wondering if I am reinventing the wheel? If you track provenance, how much data you include (git short hash, package versions, etc.)?&lt;br/&gt;\nI currently use dvc and mlflow for experiment tracking. It sometimes seems cumbersome to create/update a dvc.yaml for everything (but maybe that&amp;#39;s what I need to do).&lt;br/&gt;\nI did find a couple of provenance packages on GitHub, but the ones I found hadn&amp;#39;t been updated in years.    &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"aqjo","url":"https://www.reddit.com/r/MachineLearning/comments/1nnnuwc/d_how_do_you_handle_provenance_for_data/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758550987,"thumbnail":null},{"id":"1nnnogy","subreddit":"MachineLearning","title":"[R] What’s working (or not) for interoperability between AI tools?","selftext":"How are you tackling interoperability between different models/tools and proving ROI beyond pilots for clients? Would love to hear what’s worked (or not) for you.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How are you tackling interoperability between different models/tools and proving ROI beyond pilots for clients? Would love to hear what’s worked (or not) for you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"nordic_lion","url":"https://www.reddit.com/r/MachineLearning/comments/1nnnogy/r_whats_working_or_not_for_interoperability/","domain":"self.MachineLearning","score":1,"num_comments":0,"created_utc":1758550569,"thumbnail":null},{"id":"1nnlh1w","subreddit":"MachineLearning","title":"[D] Accessing datasets for facial detection of genetic disorders?","selftext":"I’m looking for a theme for my Master’s thesis and I came across the idea of using facial analysis to detect genetic disorders (think Down syndrome, Sanfilippo, etc.). The problem is that I haven’t been able to get access to any major dataset for this, which has been really discouraging.\n\nIf anyone here has worked in this field before — how did you manage to get access to the necessary datasets?\n\nI’m also open to other thesis ideas, but for context:\n\nMy supervisor’s research area is facial analysis with deep learning\n\nI’d like the topic to have a medical focus\n\nAny suggestions or experiences would be super helpful!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m looking for a theme for my Master’s thesis and I came across the idea of using facial analysis to detect genetic disorders (think Down syndrome, Sanfilippo, etc.). The problem is that I haven’t been able to get access to any major dataset for this, which has been really discouraging.&lt;/p&gt;\n\n&lt;p&gt;If anyone here has worked in this field before — how did you manage to get access to the necessary datasets?&lt;/p&gt;\n\n&lt;p&gt;I’m also open to other thesis ideas, but for context:&lt;/p&gt;\n\n&lt;p&gt;My supervisor’s research area is facial analysis with deep learning&lt;/p&gt;\n\n&lt;p&gt;I’d like the topic to have a medical focus&lt;/p&gt;\n\n&lt;p&gt;Any suggestions or experiences would be super helpful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Own_Application577","url":"https://www.reddit.com/r/MachineLearning/comments/1nnlh1w/d_accessing_datasets_for_facial_detection_of/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758545130,"thumbnail":null},{"id":"1nnlas0","subreddit":"MachineLearning","title":"[D] Implement Mamba from scratch or use the official github repo?","selftext":"Hello. I am looking to use Mamba for a code decoding task for my research. Should I just clone the repo and work on it or implement mamba from scratch? I read in the paper that it utilizes different sections of memory of GPU and if I implement it from scratch, I probably need to do that as well and I am not an expert in GPU programming. But still, I'd desire some level of flexibility. What could be the good option here?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am looking to use Mamba for a code decoding task for my research. Should I just clone the repo and work on it or implement mamba from scratch? I read in the paper that it utilizes different sections of memory of GPU and if I implement it from scratch, I probably need to do that as well and I am not an expert in GPU programming. But still, I&amp;#39;d desire some level of flexibility. What could be the good option here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Express_Proposal8704","url":"https://www.reddit.com/r/MachineLearning/comments/1nnlas0/d_implement_mamba_from_scratch_or_use_the/","domain":"self.MachineLearning","score":1,"num_comments":3,"created_utc":1758544655,"thumbnail":null},{"id":"1nnig4r","subreddit":"MachineLearning","title":"[D] experiment analysis workflow with wandb or mlflow","selftext":"\ndoes any one have any good workflow for analysing experiments?\n\neg the basic run a bunch of experiments, choose the best run is straightforward.\n\n\nbut typically you want to compare multiple runs\n\n# using multiple runs in analysis\n\neg how does the validation error reduce as i increase the number of hidden nodes.\n\nwhat is the relative reduction in the error? and compared to experiment variability?\n\nwhat changed between the selected runs?\n\n# extrapolating validation error\n\ni am running multiple runs, how do i extrapolate the asymptotic error (so eg i can compare runs that eg were stopped earlier, used a different learning rate)\n\n......\n\ni can download the data, but it feels like i am reinventing the wheel\n\n\neg in mlflow i download runs then have to download a separate table of metrics by iteration/epoch....\n\nthen can create a function to identify hyperparams and summarise differences from base run (ignoring eg timestamps)...\n\ntagging and notes could be helpful, but its not clear the best way to use them\n\n\ni am currently working with wandb. \n\n","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;does any one have any good workflow for analysing experiments?&lt;/p&gt;\n\n&lt;p&gt;eg the basic run a bunch of experiments, choose the best run is straightforward.&lt;/p&gt;\n\n&lt;p&gt;but typically you want to compare multiple runs&lt;/p&gt;\n\n&lt;h1&gt;using multiple runs in analysis&lt;/h1&gt;\n\n&lt;p&gt;eg how does the validation error reduce as i increase the number of hidden nodes.&lt;/p&gt;\n\n&lt;p&gt;what is the relative reduction in the error? and compared to experiment variability?&lt;/p&gt;\n\n&lt;p&gt;what changed between the selected runs?&lt;/p&gt;\n\n&lt;h1&gt;extrapolating validation error&lt;/h1&gt;\n\n&lt;p&gt;i am running multiple runs, how do i extrapolate the asymptotic error (so eg i can compare runs that eg were stopped earlier, used a different learning rate)&lt;/p&gt;\n\n&lt;p&gt;......&lt;/p&gt;\n\n&lt;p&gt;i can download the data, but it feels like i am reinventing the wheel&lt;/p&gt;\n\n&lt;p&gt;eg in mlflow i download runs then have to download a separate table of metrics by iteration/epoch....&lt;/p&gt;\n\n&lt;p&gt;then can create a function to identify hyperparams and summarise differences from base run (ignoring eg timestamps)...&lt;/p&gt;\n\n&lt;p&gt;tagging and notes could be helpful, but its not clear the best way to use them&lt;/p&gt;\n\n&lt;p&gt;i am currently working with wandb. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"seanv507","url":"https://www.reddit.com/r/MachineLearning/comments/1nnig4r/d_experiment_analysis_workflow_with_wandb_or/","domain":"self.MachineLearning","score":0,"num_comments":1,"created_utc":1758535593,"thumbnail":null},{"id":"1nni5ld","subreddit":"MachineLearning","title":"[D] Best practice for providing code during review","selftext":"I wonder, now for ICLR, we want to release the code, and we definitely will do (we always have done in the past). But for the submission, what would be the best practice?\n\nYou can upload some code as supplementary material. That has the same deadline as the main paper, and we are currently polishing the paper, and probably won't really have the time to clean up the code until that time. In the code, there is also a lot more than in the paper, lots of other ideas that we have tried but did not report, also potential interesting follow-up ideas that we don't want to publish now.\n\nI saw in some other papers, that they provide a link to an anonymized repo (via https://anonymous.4open.science/). That gives us some more time to maybe also clean up the code further after the submission deadline, as I think we can still update that (right?). So this seems to be a better option?\n\nOr we can just make a statement that we will release the code when it is accepted. So then the reviewers cannot check it right now.\n\nAlso, the code makes use of multiple frameworks which are (mostly) only used by our research group (even though they are public, and could be used by anyone), so it is pretty obvious from whom this work is. Does that already count as violation of the double-anonymous submission rule?\n\nSo, what would be the best thing to do?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wonder, now for ICLR, we want to release the code, and we definitely will do (we always have done in the past). But for the submission, what would be the best practice?&lt;/p&gt;\n\n&lt;p&gt;You can upload some code as supplementary material. That has the same deadline as the main paper, and we are currently polishing the paper, and probably won&amp;#39;t really have the time to clean up the code until that time. In the code, there is also a lot more than in the paper, lots of other ideas that we have tried but did not report, also potential interesting follow-up ideas that we don&amp;#39;t want to publish now.&lt;/p&gt;\n\n&lt;p&gt;I saw in some other papers, that they provide a link to an anonymized repo (via &lt;a href=\"https://anonymous.4open.science/\"&gt;https://anonymous.4open.science/&lt;/a&gt;). That gives us some more time to maybe also clean up the code further after the submission deadline, as I think we can still update that (right?). So this seems to be a better option?&lt;/p&gt;\n\n&lt;p&gt;Or we can just make a statement that we will release the code when it is accepted. So then the reviewers cannot check it right now.&lt;/p&gt;\n\n&lt;p&gt;Also, the code makes use of multiple frameworks which are (mostly) only used by our research group (even though they are public, and could be used by anyone), so it is pretty obvious from whom this work is. Does that already count as violation of the double-anonymous submission rule?&lt;/p&gt;\n\n&lt;p&gt;So, what would be the best thing to do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"albertzeyer","url":"https://www.reddit.com/r/MachineLearning/comments/1nni5ld/d_best_practice_for_providing_code_during_review/","domain":"self.MachineLearning","score":7,"num_comments":5,"created_utc":1758534555,"thumbnail":null},{"id":"1nnhkz8","subreddit":"MachineLearning","title":"[D] Is it reasonable that reviewers aren’t required to read the appendix?","selftext":"I’ve noticed that many recent conference author guidelines explicitly say something like: *reviewers are not required to read the appendix.*\n\nTo me, that effectively gives reviewers the right to ignore material that’s already provided there—even if it directly addresses their concerns.\n\nIn a past review of mine, a reviewer gave a low initial score and negative feedback without consulting the appendix. I flagged this to the AC (including a confidential comment), but the AC essentially said this wasn’t mandatory and couldn’t be used to “correct” the reviewer’s action. The final decision went through without considering the appendix.\n\nI’m curious how others see this guideline:\n\n* Is it reasonable?\n* Does it create perverse incentives for authors (e.g., to cram everything into the main text only)?\n* Or is it a necessary boundary given reviewer workload?\n\nWould appreciate perspectives—from authors, reviewers, and ACs—on whether this policy helps or harms review quality.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve noticed that many recent conference author guidelines explicitly say something like: &lt;em&gt;reviewers are not required to read the appendix.&lt;/em&gt;&lt;/p&gt;\n\n&lt;p&gt;To me, that effectively gives reviewers the right to ignore material that’s already provided there—even if it directly addresses their concerns.&lt;/p&gt;\n\n&lt;p&gt;In a past review of mine, a reviewer gave a low initial score and negative feedback without consulting the appendix. I flagged this to the AC (including a confidential comment), but the AC essentially said this wasn’t mandatory and couldn’t be used to “correct” the reviewer’s action. The final decision went through without considering the appendix.&lt;/p&gt;\n\n&lt;p&gt;I’m curious how others see this guideline:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is it reasonable?&lt;/li&gt;\n&lt;li&gt;Does it create perverse incentives for authors (e.g., to cram everything into the main text only)?&lt;/li&gt;\n&lt;li&gt;Or is it a necessary boundary given reviewer workload?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would appreciate perspectives—from authors, reviewers, and ACs—on whether this policy helps or harms review quality.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Secondhanded_PhD","url":"https://www.reddit.com/r/MachineLearning/comments/1nnhkz8/d_is_it_reasonable_that_reviewers_arent_required/","domain":"self.MachineLearning","score":15,"num_comments":14,"created_utc":1758532340,"thumbnail":null},{"id":"1nnh6gi","subreddit":"MachineLearning","title":"[D] Mixture of Attention?","selftext":" considering a new transformer architecture (for protein/DNA models but feel free to weight in from a language perspective) and I’d love some input before I do any experimenting (low budget this semester)\n\nThe current leading edge of efficient LLMs appear to be mixtures of experts, with a number of quadratic attention layers swapped out for linear layers (IBM granite 4.0, qwen-next for ex).\n\nNVIDIA even has a paper out replacing quadratic attention with linear layers on pre-trained models (https://arxiv.org/abs/2508.15884 ).\n\nSo I wonder if it would be feasible to freeze a model after pre-training (all attention quadratic), one by one training a linear substitute for each quadratic layer.\n\nThen either based on external rules (context length, compute constraint) decide when and how many layers are flicked to linear. Or, train a router with an objective to maximize response quality, keeping generation speed up, while minimizing cost.\n\nEither way you’d have a single model, with fairly coherent tone and knowledge, that based deployment constraints (speed requirements, memory/compute limits) can be adjusted to be more, or less, linear on the fly.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;considering a new transformer architecture (for protein/DNA models but feel free to weight in from a language perspective) and I’d love some input before I do any experimenting (low budget this semester)&lt;/p&gt;\n\n&lt;p&gt;The current leading edge of efficient LLMs appear to be mixtures of experts, with a number of quadratic attention layers swapped out for linear layers (IBM granite 4.0, qwen-next for ex).&lt;/p&gt;\n\n&lt;p&gt;NVIDIA even has a paper out replacing quadratic attention with linear layers on pre-trained models (&lt;a href=\"https://arxiv.org/abs/2508.15884\"&gt;https://arxiv.org/abs/2508.15884&lt;/a&gt; ).&lt;/p&gt;\n\n&lt;p&gt;So I wonder if it would be feasible to freeze a model after pre-training (all attention quadratic), one by one training a linear substitute for each quadratic layer.&lt;/p&gt;\n\n&lt;p&gt;Then either based on external rules (context length, compute constraint) decide when and how many layers are flicked to linear. Or, train a router with an objective to maximize response quality, keeping generation speed up, while minimizing cost.&lt;/p&gt;\n\n&lt;p&gt;Either way you’d have a single model, with fairly coherent tone and knowledge, that based deployment constraints (speed requirements, memory/compute limits) can be adjusted to be more, or less, linear on the fly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Alarming-Ad8154","url":"https://www.reddit.com/r/MachineLearning/comments/1nnh6gi/d_mixture_of_attention/","domain":"self.MachineLearning","score":2,"num_comments":1,"created_utc":1758530752,"thumbnail":null},{"id":"1nngswn","subreddit":"MachineLearning","title":"[D] Semantic image synthesis state-of-the-art?","selftext":"Hi everyone. I've never done this, so decided to post.\n\nI'm looking to create black-and-white images of satellite photos of rivers, from skeletons of river images. Basically I have a dataset where I have \\[satellite\\_river\\_photo, skeleton\\_segmentation\\] pairs, and I want to train a generator to do skeleton-&gt;satellite generations from new unseen skeletons. Having an extra conditioning variable would also be of interest, but not necessarily at the beginning.\n\nSince most of the literature in this area is over 6 years old, I wanted to post and see if anyone in this community has done something similar lately and would be able to provide some guidance and what methods would be the best to start with or what papers to look at. Thanks.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;ve never done this, so decided to post.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to create black-and-white images of satellite photos of rivers, from skeletons of river images. Basically I have a dataset where I have [satellite_river_photo, skeleton_segmentation] pairs, and I want to train a generator to do skeleton-&amp;gt;satellite generations from new unseen skeletons. Having an extra conditioning variable would also be of interest, but not necessarily at the beginning.&lt;/p&gt;\n\n&lt;p&gt;Since most of the literature in this area is over 6 years old, I wanted to post and see if anyone in this community has done something similar lately and would be able to provide some guidance and what methods would be the best to start with or what papers to look at. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Big-Coyote-1785","url":"https://www.reddit.com/r/MachineLearning/comments/1nngswn/d_semantic_image_synthesis_stateoftheart/","domain":"self.MachineLearning","score":2,"num_comments":1,"created_utc":1758529244,"thumbnail":null},{"id":"1nn5x9t","subreddit":"MachineLearning","title":"[P] SDLArch-RL: Multi-Console Gaming Environment for Reinforcement Learning Research","selftext":"Hey r/MachineLearning! I've been working on addressing a persistent pain point in RL gaming research - the setup complexity and limited scope of training environments.\n\n**SDLArch-RL** is a unified RL environment that integrates multiple console emulators (N64, PS2, Dreamcast, GameCube) with standard ML frameworks. Key technical features:\n\n* **Gymnasium-compliant interface** \\- drop-in replacement for existing workflows\n* **Stable-Baselines3 integration** \\- works out-of-the-box with PPO, SAC, TD3, etc.\n* **Efficient state management** \\- leverages native emulator save states for fast episode resets\n* **Configurable observation spaces** \\- raw pixels, processed features, or memory states\n* **Action space mapping** \\- handles complex controller inputs to discrete/continuous actions\n\nCurrently supports 4 emulator backends with plans for modern console integration (PS3, Xbox 360, Wii U). The environment abstracts away emulator-specific APIs while preserving access to low-level features when needed.\n\n**Technical implementation highlights:**\n\n* SDL-based architecture for minimal overhead\n* Memory mapping support for game-specific feature extraction\n* Reproducible training through deterministic save state handling\n* Multi-game training capabilities within single environment instance\n\nThis opens up training on thousands of diverse games vs. the typical handful of custom environments. Particularly useful for transfer learning studies, multi-task RL, and curriculum learning research.\n\nHappy to discuss technical details or answer implementation questions. Thoughts on potential research applications?\n\nGit: [https://github.com/paulo101977/sdlarch-rl](https://github.com/paulo101977/sdlarch-rl)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/MachineLearning\"&gt;r/MachineLearning&lt;/a&gt;! I&amp;#39;ve been working on addressing a persistent pain point in RL gaming research - the setup complexity and limited scope of training environments.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;SDLArch-RL&lt;/strong&gt; is a unified RL environment that integrates multiple console emulators (N64, PS2, Dreamcast, GameCube) with standard ML frameworks. Key technical features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Gymnasium-compliant interface&lt;/strong&gt; - drop-in replacement for existing workflows&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Stable-Baselines3 integration&lt;/strong&gt; - works out-of-the-box with PPO, SAC, TD3, etc.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Efficient state management&lt;/strong&gt; - leverages native emulator save states for fast episode resets&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Configurable observation spaces&lt;/strong&gt; - raw pixels, processed features, or memory states&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Action space mapping&lt;/strong&gt; - handles complex controller inputs to discrete/continuous actions&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Currently supports 4 emulator backends with plans for modern console integration (PS3, Xbox 360, Wii U). The environment abstracts away emulator-specific APIs while preserving access to low-level features when needed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Technical implementation highlights:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;SDL-based architecture for minimal overhead&lt;/li&gt;\n&lt;li&gt;Memory mapping support for game-specific feature extraction&lt;/li&gt;\n&lt;li&gt;Reproducible training through deterministic save state handling&lt;/li&gt;\n&lt;li&gt;Multi-game training capabilities within single environment instance&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This opens up training on thousands of diverse games vs. the typical handful of custom environments. Particularly useful for transfer learning studies, multi-task RL, and curriculum learning research.&lt;/p&gt;\n\n&lt;p&gt;Happy to discuss technical details or answer implementation questions. Thoughts on potential research applications?&lt;/p&gt;\n\n&lt;p&gt;Git: &lt;a href=\"https://github.com/paulo101977/sdlarch-rl\"&gt;https://github.com/paulo101977/sdlarch-rl&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AgeOfEmpires4AOE4","url":"https://www.reddit.com/r/MachineLearning/comments/1nn5x9t/p_sdlarchrl_multiconsole_gaming_environment_for/","domain":"youtube.com","score":3,"num_comments":0,"created_utc":1758494458,"thumbnail":"https://external-preview.redd.it/m5JkpAZWOHWXvY6hDq-zX6iBTfZDuTB1RIqpaESSSco.jpeg?width=140&amp;height=105&amp;crop=140:105,smart&amp;auto=webp&amp;s=7eb577b6102b1bd688aa4158cd23d5af5dfec83f"},{"id":"1nn5wex","subreddit":"MachineLearning","title":"[P] Tracking generation provenance in multi-model workflows","selftext":"Working on an interesting problem in production RAG systems.\n\nWhen documents are generated through multiple model iterations, we lose the causal chain of prompts and contexts that created them. This makes reproducibility and debugging nearly impossible.\n\nMy approach:\n\n* Store prompt embeddings alongside generated content\n* Track model/version fingerprints\n* Maintain conversation context graphs\n* Enable temporal queries (\"show evolution of auth design\")\n\nInteresting finding: Documents that go through multiple models (Claude→GPT-4→Gemini) show measurably different semantic patterns than single-model outputs. The prompt chain becomes crucial for understanding final output.\n\nCurrently tracking 103 documents with up to 9 versions each. Can query both by content similarity AND prompt similarity.\n\nImplementation uses standard RAG pipeline but indexes prompts separately from outputs. Adds \\~15% storage overhead but query precision improved 40%.\n\nCode: [github.com/VeriTeknik/pluggedin-app](http://github.com/VeriTeknik/pluggedin-app)\n\nHas anyone explored prompt archaeology in production systems? What patterns are you seeing?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on an interesting problem in production RAG systems.&lt;/p&gt;\n\n&lt;p&gt;When documents are generated through multiple model iterations, we lose the causal chain of prompts and contexts that created them. This makes reproducibility and debugging nearly impossible.&lt;/p&gt;\n\n&lt;p&gt;My approach:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Store prompt embeddings alongside generated content&lt;/li&gt;\n&lt;li&gt;Track model/version fingerprints&lt;/li&gt;\n&lt;li&gt;Maintain conversation context graphs&lt;/li&gt;\n&lt;li&gt;Enable temporal queries (&amp;quot;show evolution of auth design&amp;quot;)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Interesting finding: Documents that go through multiple models (Claude→GPT-4→Gemini) show measurably different semantic patterns than single-model outputs. The prompt chain becomes crucial for understanding final output.&lt;/p&gt;\n\n&lt;p&gt;Currently tracking 103 documents with up to 9 versions each. Can query both by content similarity AND prompt similarity.&lt;/p&gt;\n\n&lt;p&gt;Implementation uses standard RAG pipeline but indexes prompts separately from outputs. Adds ~15% storage overhead but query precision improved 40%.&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=\"http://github.com/VeriTeknik/pluggedin-app\"&gt;github.com/VeriTeknik/pluggedin-app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Has anyone explored prompt archaeology in production systems? What patterns are you seeing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"babaenki","url":"https://www.reddit.com/r/MachineLearning/comments/1nn5wex/p_tracking_generation_provenance_in_multimodel/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758494399,"thumbnail":null},{"id":"1nn56yu","subreddit":"MachineLearning","title":"[D] Is non-DL related research a poor fit for ICLR?","selftext":"I was one of the lucky people rejected from NEURIPS with 6444 scores but cranky AC, so looking to resubmit now. Since it got good reviews at NEURIPS, I'm considering submitting to ICLR incorporating suggested changes.\n\nHowever, my paper proposes a linear dimensionality reduction technique, based on information geometry. It is my understanding that ICLR is very focused on neural networks and Deep Learning, so I am worried that my paper is not a good fit, so also considering AISTATS.\n\nIs a novel linear dimensionality reduction technique too out of scope for ICLR? I am an outsider to the field, so would very much appreciate opinions.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was one of the lucky people rejected from NEURIPS with 6444 scores but cranky AC, so looking to resubmit now. Since it got good reviews at NEURIPS, I&amp;#39;m considering submitting to ICLR incorporating suggested changes.&lt;/p&gt;\n\n&lt;p&gt;However, my paper proposes a linear dimensionality reduction technique, based on information geometry. It is my understanding that ICLR is very focused on neural networks and Deep Learning, so I am worried that my paper is not a good fit, so also considering AISTATS.&lt;/p&gt;\n\n&lt;p&gt;Is a novel linear dimensionality reduction technique too out of scope for ICLR? I am an outsider to the field, so would very much appreciate opinions.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"dherrera1911","url":"https://www.reddit.com/r/MachineLearning/comments/1nn56yu/d_is_nondl_related_research_a_poor_fit_for_iclr/","domain":"self.MachineLearning","score":33,"num_comments":11,"created_utc":1758492537,"thumbnail":null},{"id":"1nn1ig8","subreddit":"MachineLearning","title":"[D] Strategies for Routing LLMs","selftext":"","selftext_html":"","author":"ApartmentEither4838","url":"https://www.reddit.com/r/MachineLearning/comments/1nn1ig8/d_strategies_for_routing_llms/","domain":"martianlantern.github.io","score":0,"num_comments":0,"created_utc":1758483657,"thumbnail":null},{"id":"1nmu1ad","subreddit":"MachineLearning","title":"[D] Missing AAAI Reviews","selftext":"Apologies in advance if I’ve missed something in conference comms so far, but I can’t seem to see the reviews I’d received on my (rejected) AAAI submission anymore. I was able to view them the other day, but when I just went to reflect on them to help with our next revision, they were gone!\n\nDoes anyone know anything about this? Is it related to the Phase 2 review round starting?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies in advance if I’ve missed something in conference comms so far, but I can’t seem to see the reviews I’d received on my (rejected) AAAI submission anymore. I was able to view them the other day, but when I just went to reflect on them to help with our next revision, they were gone!&lt;/p&gt;\n\n&lt;p&gt;Does anyone know anything about this? Is it related to the Phase 2 review round starting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"dreamykidd","url":"https://www.reddit.com/r/MachineLearning/comments/1nmu1ad/d_missing_aaai_reviews/","domain":"self.MachineLearning","score":9,"num_comments":7,"created_utc":1758466391,"thumbnail":null},{"id":"1nmo57e","subreddit":"MachineLearning","title":"[D] Is peer review overloaded due to rejecting too many papers?","selftext":"The crazy math of queueing theory: When conferences reject a large fraction of papers, many of those submissions come back in the next cycle. But increasing rates a bit reduces drastically the unaccepted paper pool and a percentage of this smaller pool becomes again a similar number of accepted papers as when rates were low! This is not saying we should accept bad papers, the number absolute number of accepted papers changes very little because of the unaccepted pool growth!\n\nSee the interactive model + math: [https://damaru2.github.io/general/queueing\\_to\\_publish\\_in\\_AI\\_or\\_CS/](https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/)\n\nWith lower acceptance rates we end up reviewing much more to reach roughly the same number of accepted works.\n\nWhat do you think about this phenomenon? Are we re-reviewing too many papers? Physical constraints can be easily solved with federated conferences (make Eurips an official option for presentation?) or allowing not to present in person.\n\nBonus: Funnel simulation of the ideal case where authors always resubmit their papers [https://i.postimg.cc/gz88S2hY/funnel2.gif](https://i.postimg.cc/gz88S2hY/funnel2.gif) In here you can see that when authors do not give up submitting (that is, the ideal case, but in the post a more complex model is presented), and the number new of papers per round is the same for both cases, the same number of papers are accepted on average per conference in two scenarios with different acceptance rates.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The crazy math of queueing theory: When conferences reject a large fraction of papers, many of those submissions come back in the next cycle. But increasing rates a bit reduces drastically the unaccepted paper pool and a percentage of this smaller pool becomes again a similar number of accepted papers as when rates were low! This is not saying we should accept bad papers, the number absolute number of accepted papers changes very little because of the unaccepted pool growth!&lt;/p&gt;\n\n&lt;p&gt;See the interactive model + math: &lt;a href=\"https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/\"&gt;https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;With lower acceptance rates we end up reviewing much more to reach roughly the same number of accepted works.&lt;/p&gt;\n\n&lt;p&gt;What do you think about this phenomenon? Are we re-reviewing too many papers? Physical constraints can be easily solved with federated conferences (make Eurips an official option for presentation?) or allowing not to present in person.&lt;/p&gt;\n\n&lt;p&gt;Bonus: Funnel simulation of the ideal case where authors always resubmit their papers &lt;a href=\"https://i.postimg.cc/gz88S2hY/funnel2.gif\"&gt;https://i.postimg.cc/gz88S2hY/funnel2.gif&lt;/a&gt; In here you can see that when authors do not give up submitting (that is, the ideal case, but in the post a more complex model is presented), and the number new of papers per round is the same for both cases, the same number of papers are accepted on average per conference in two scenarios with different acceptance rates.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"jan_Tamalu","url":"https://www.reddit.com/r/MachineLearning/comments/1nmo57e/d_is_peer_review_overloaded_due_to_rejecting_too/","domain":"i.redd.it","score":0,"num_comments":13,"created_utc":1758449183,"thumbnail":"https://b.thumbs.redditmedia.com/_9paQpDH3FU1V5ZVCa3D-m2Iz61CHvoJmOgvlMhv8kA.jpg"},{"id":"1nmbvi5","subreddit":"MachineLearning","title":"[D] ICLR 2026 Submission Count","selftext":"I submitted to ICLR after a NeurIPS reject of a borderline paper. My submission id is above 20k! Wondering how many ICLR submissions there are in total (comment if you have a higher sub id) and how much the venue can even accommodate.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I submitted to ICLR after a NeurIPS reject of a borderline paper. My submission id is above 20k! Wondering how many ICLR submissions there are in total (comment if you have a higher sub id) and how much the venue can even accommodate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"kipthornberry","url":"https://www.reddit.com/r/MachineLearning/comments/1nmbvi5/d_iclr_2026_submission_count/","domain":"self.MachineLearning","score":34,"num_comments":16,"created_utc":1758408327,"thumbnail":null},{"id":"1nmb8as","subreddit":"MachineLearning","title":"[D] NeurIPS: rejecting papers from sanctioned affiliations mid-process","selftext":"I know multiple people and multiple papers who have received this.\n\nIt is probably legally correct. There are legit grounds for these bans.\n\nHowever, I don't think it is okay to do it AFTER reviewing and even accepting the papers. Hundreds of people wasted their time for nothing.\n\nThere was a recent post with messages to SAC about venue constraints, and this might be a way the organizers are solving this problem.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know multiple people and multiple papers who have received this.&lt;/p&gt;\n\n&lt;p&gt;It is probably legally correct. There are legit grounds for these bans.&lt;/p&gt;\n\n&lt;p&gt;However, I don&amp;#39;t think it is okay to do it AFTER reviewing and even accepting the papers. Hundreds of people wasted their time for nothing.&lt;/p&gt;\n\n&lt;p&gt;There was a recent post with messages to SAC about venue constraints, and this might be a way the organizers are solving this problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"YallenGusev","url":"https://www.reddit.com/r/MachineLearning/comments/1nmb8as/d_neurips_rejecting_papers_from_sanctioned/","domain":"i.redd.it","score":121,"num_comments":57,"created_utc":1758406590,"thumbnail":"https://a.thumbs.redditmedia.com/C9vhZOKSCL8bcgNAcVnXOmK2B9T55oKMMD8l9K_3U88.jpg"},{"id":"1nmb7jm","subreddit":"MachineLearning","title":"[P] Introducing LabelMob: Connecting ML Teams with Expert Data Annotators","selftext":"Hey [r/machinelearning](https://www.reddit.com/r/machinelearning/),\n\nI've been working in the ML space for a while and noticed a big pain point: finding high-quality, domain-specific data annotators for complex datasets. Whether it's labeling quantum physics simulations, chemical structures, biological sequences, or advanced mathematical models, generic annotation services often fall short. That's why I built [LabelMob.com](https://labelmob.com/) – a platform designed to match companies, universities, and research teams with expert annotators who have real expertise in fields like physics, chemistry, math, biology, data science, and more. How It Works:\n\n* For Hirers (Companies/Universities): Post your annotation projects and specify the expertise needed. We connect you with vetted individuals or specialized annotation companies who can handle niche tasks accurately and efficiently. Think: annotating MRI scans by medical physicists or labeling molecular data by chemists.\n* For Annotators (Experts/Companies): Sign up to showcase your skills and get matched with paid gigs that align with your background. It's a great way for domain experts to monetize their knowledge on a flexible basis.\n\nThe goal is to improve dataset quality for ML models – we all know garbage in, garbage out, right? Better annotations mean better training data, leading to more reliable AI systems in research and industry.\n\n**Why Now?**\n\nWith the explosion of multimodal and specialized ML applications (e.g., drug discovery, climate modeling, autonomous systems), the demand for expert-level labeling is skyrocketing. LabelMob aims to bridge that gap without the overhead of traditional crowdsourcing platforms.\n\nI'd love feedback from this community! Have you struggled with finding the right annotators? What features would make this more useful for your workflows? Check out the site at [labelmob.com](https://labelmob.com/) and let me know your thoughts.\n\nDisclaimer: This is a new platform, so we're in early stages and actively iterating based on user input. No spamming intended – just sharing something I think could help the ML ecosystem.\n\nThanks!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"https://www.reddit.com/r/machinelearning/\"&gt;r/machinelearning&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working in the ML space for a while and noticed a big pain point: finding high-quality, domain-specific data annotators for complex datasets. Whether it&amp;#39;s labeling quantum physics simulations, chemical structures, biological sequences, or advanced mathematical models, generic annotation services often fall short. That&amp;#39;s why I built &lt;a href=\"https://labelmob.com/\"&gt;LabelMob.com&lt;/a&gt; – a platform designed to match companies, universities, and research teams with expert annotators who have real expertise in fields like physics, chemistry, math, biology, data science, and more. How It Works:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;For Hirers (Companies/Universities): Post your annotation projects and specify the expertise needed. We connect you with vetted individuals or specialized annotation companies who can handle niche tasks accurately and efficiently. Think: annotating MRI scans by medical physicists or labeling molecular data by chemists.&lt;/li&gt;\n&lt;li&gt;For Annotators (Experts/Companies): Sign up to showcase your skills and get matched with paid gigs that align with your background. It&amp;#39;s a great way for domain experts to monetize their knowledge on a flexible basis.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The goal is to improve dataset quality for ML models – we all know garbage in, garbage out, right? Better annotations mean better training data, leading to more reliable AI systems in research and industry.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why Now?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With the explosion of multimodal and specialized ML applications (e.g., drug discovery, climate modeling, autonomous systems), the demand for expert-level labeling is skyrocketing. LabelMob aims to bridge that gap without the overhead of traditional crowdsourcing platforms.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love feedback from this community! Have you struggled with finding the right annotators? What features would make this more useful for your workflows? Check out the site at &lt;a href=\"https://labelmob.com/\"&gt;labelmob.com&lt;/a&gt; and let me know your thoughts.&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: This is a new platform, so we&amp;#39;re in early stages and actively iterating based on user input. No spamming intended – just sharing something I think could help the ML ecosystem.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"singlasahil14","url":"https://www.reddit.com/r/MachineLearning/comments/1nmb7jm/p_introducing_labelmob_connecting_ml_teams_with/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758406539,"thumbnail":null},{"id":"1nlvw1r","subreddit":"MachineLearning","title":"[R] MiniGrid DoorKeys Benchmark Active Inference","selftext":"I am working on an Active Inference Framework since some time and it has managed to constantly and reproducable perform (I guess) very well on MG-DK without any benchmaxing or training.. the numbers (average) are:\n\n8x8: &lt;19 Steps for SR 1 16x16: &lt;60 Steps for SR 1\n\nDo you know someone or a company or so who might be interested in learning more about this solution or the research involved?\n\nThank you!\n\nBest Thom","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on an Active Inference Framework since some time and it has managed to constantly and reproducable perform (I guess) very well on MG-DK without any benchmaxing or training.. the numbers (average) are:&lt;/p&gt;\n\n&lt;p&gt;8x8: &amp;lt;19 Steps for SR 1 16x16: &amp;lt;60 Steps for SR 1&lt;/p&gt;\n\n&lt;p&gt;Do you know someone or a company or so who might be interested in learning more about this solution or the research involved?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;Best Thom&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"thomheinrich","url":"https://www.reddit.com/r/MachineLearning/comments/1nlvw1r/r_minigrid_doorkeys_benchmark_active_inference/","domain":"self.MachineLearning","score":9,"num_comments":5,"created_utc":1758368222,"thumbnail":null},{"id":"1nlvvi1","subreddit":"MachineLearning","title":"[P]  Video prediction pipeline using a frozen VAE and hierarchical LSTMs to learn latent dynamics","selftext":"I wanted to share a personal project I've been working on for the past few months and get some feedback from the community. My goal was to build a stable, interactive system for video prediction by cleanly separating the perception and dynamics modeling. \n\n**The Core Architecture**\n\nThe pipeline processes a live camera feed. The main idea is to avoid expensive end-to-end training and create a more modular system.\n\n* **Frozen VAE (Perception):** I'm using the pre-trained Stable Diffusion VAE to encode frames into a latent space. By keeping it frozen, the \"perceptual manifold\" is stable, which makes learning the dynamics much easier.\n* **Three-Stage LSTM System (Dynamics):** This is where I tried to do something a bit different. Instead of one big LSTM, I'm using a hierarchy:\n   * A **Pattern LSTM** observes short sequences of latents to find basic temporal patterns.\n   * A **Compression LSTM** takes these patterns and learns a dense, compressed representation.\n   * A **Central LSTM** takes this compressed state and predicts the next latent step (Δz).\n\n**\\*NOTE:** This pipeline is capable of ALOT more than just a simple prediction model. For this project I solely focused on the vision aspect. \n\n**Performance and Results**\n\nThe whole system runs at an interactive 4-6 FPS on my consumer hardware and has a simple PyQT GUI to show the live camera feed next to the model's prediction. With better hardware i'm hoping to hit 24 FPS, but balling on a budget right now.\n\nMy main focus was on perceptual quality over raw pixel accuracy. The most encouraging result was in multi-step open-loop rollouts, where the model achieved a **peak SSIM of 0.84**. I was really happy to see this, as it's a result that's competitive with some established benchmarks on standardized datasets (like KTH).\n\n**Link to Project:**\n\nI've documented the architecture, included the performance logs, and wrote a white paper in the GitHub repo if you want to see the technical details:\n\n[github](https://github.com/A1CST/VISION_VAE_OLM_3L_PCC_PREDICTION)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to share a personal project I&amp;#39;ve been working on for the past few months and get some feedback from the community. My goal was to build a stable, interactive system for video prediction by cleanly separating the perception and dynamics modeling. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Core Architecture&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The pipeline processes a live camera feed. The main idea is to avoid expensive end-to-end training and create a more modular system.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Frozen VAE (Perception):&lt;/strong&gt; I&amp;#39;m using the pre-trained Stable Diffusion VAE to encode frames into a latent space. By keeping it frozen, the &amp;quot;perceptual manifold&amp;quot; is stable, which makes learning the dynamics much easier.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Three-Stage LSTM System (Dynamics):&lt;/strong&gt; This is where I tried to do something a bit different. Instead of one big LSTM, I&amp;#39;m using a hierarchy:\n\n&lt;ul&gt;\n&lt;li&gt;A &lt;strong&gt;Pattern LSTM&lt;/strong&gt; observes short sequences of latents to find basic temporal patterns.&lt;/li&gt;\n&lt;li&gt;A &lt;strong&gt;Compression LSTM&lt;/strong&gt; takes these patterns and learns a dense, compressed representation.&lt;/li&gt;\n&lt;li&gt;A &lt;strong&gt;Central LSTM&lt;/strong&gt; takes this compressed state and predicts the next latent step (Δz).&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;*NOTE:&lt;/strong&gt; This pipeline is capable of ALOT more than just a simple prediction model. For this project I solely focused on the vision aspect. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Performance and Results&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;The whole system runs at an interactive 4-6 FPS on my consumer hardware and has a simple PyQT GUI to show the live camera feed next to the model&amp;#39;s prediction. With better hardware i&amp;#39;m hoping to hit 24 FPS, but balling on a budget right now.&lt;/p&gt;\n\n&lt;p&gt;My main focus was on perceptual quality over raw pixel accuracy. The most encouraging result was in multi-step open-loop rollouts, where the model achieved a &lt;strong&gt;peak SSIM of 0.84&lt;/strong&gt;. I was really happy to see this, as it&amp;#39;s a result that&amp;#39;s competitive with some established benchmarks on standardized datasets (like KTH).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Link to Project:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve documented the architecture, included the performance logs, and wrote a white paper in the GitHub repo if you want to see the technical details:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/A1CST/VISION_VAE_OLM_3L_PCC_PREDICTION\"&gt;github&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AsyncVibes","url":"https://www.reddit.com/r/MachineLearning/comments/1nlvvi1/p_video_prediction_pipeline_using_a_frozen_vae/","domain":"self.MachineLearning","score":1,"num_comments":0,"created_utc":1758368169,"thumbnail":null},{"id":"1nlnf5g","subreddit":"MachineLearning","title":"[D] AAAI 2026 Phase 2 Review","selftext":"Hi all,\n\nI’m serving as a reviewer for AAAI ’26. Has anyone received additional papers for the Phase 2 review yet? The website indicates that Phase 2 starts on Sep. 16, but I haven’t been assigned any papers so far.\n\n[https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic](https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic)\n\n\n\nEdit (Sep. 21): Just got assigned three extra papers!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I’m serving as a reviewer for AAAI ’26. Has anyone received additional papers for the Phase 2 review yet? The website indicates that Phase 2 starts on Sep. 16, but I haven’t been assigned any papers so far.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic\"&gt;https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit (Sep. 21): Just got assigned three extra papers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"snu95","url":"https://www.reddit.com/r/MachineLearning/comments/1nlnf5g/d_aaai_2026_phase_2_review/","domain":"self.MachineLearning","score":22,"num_comments":7,"created_utc":1758338134,"thumbnail":null},{"id":"1nliq67","subreddit":"MachineLearning","title":"[P] Benchmarked EpilepsyBench #1 winner - found 27x performance gap, now training Bi-Mamba-2 fix","selftext":"Hey all, been learning EEG ML heavily for the past two months or so.\n\nRecently evaluated SeizureTransformer (#1 on [EpilepsyBench ](https://epilepsybenchmarks.com/challenge/)with \\~1 FA/24h) on the Temple EEG dataset using clinical NEDC scoring: **26.89 FA/24h** \\- a 27x gap. Same predictions scored three ways produced 8.59 to 136.73 FA/24h depending on methodology alone.\n\n**Evaluation here:** [https://github.com/Clarity-Digital-Twin/SeizureTransformer](https://github.com/Clarity-Digital-Twin/SeizureTransformer)  \n[PDF](https://drive.google.com/file/d/1T-lmGZuWr_0YnB0m692ccgVdSRjs_Y5n/view?usp=sharing): Gdrive\n\nSo I can actually contribute instead of reproducing, I'm now training the first **Bi-Mamba-2 + U-Net + ResCNN** architecture - O(N) complexity while maintaining temporal modeling.\n\n**Training code:** [https://github.com/Clarity-Digital-Twin/brain-go-brr-v2](https://github.com/Clarity-Digital-Twin/brain-go-brr-v2)\n\nWould appreciate feedback on either if there is any interest. Also seeking arXiv endorsement for cs.LG if anyone finds this worth sharing (independent researcher).","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, been learning EEG ML heavily for the past two months or so.&lt;/p&gt;\n\n&lt;p&gt;Recently evaluated SeizureTransformer (#1 on &lt;a href=\"https://epilepsybenchmarks.com/challenge/\"&gt;EpilepsyBench &lt;/a&gt;with ~1 FA/24h) on the Temple EEG dataset using clinical NEDC scoring: &lt;strong&gt;26.89 FA/24h&lt;/strong&gt; - a 27x gap. Same predictions scored three ways produced 8.59 to 136.73 FA/24h depending on methodology alone.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Evaluation here:&lt;/strong&gt; &lt;a href=\"https://github.com/Clarity-Digital-Twin/SeizureTransformer\"&gt;https://github.com/Clarity-Digital-Twin/SeizureTransformer&lt;/a&gt;&lt;br/&gt;\n&lt;a href=\"https://drive.google.com/file/d/1T-lmGZuWr_0YnB0m692ccgVdSRjs_Y5n/view?usp=sharing\"&gt;PDF&lt;/a&gt;: Gdrive&lt;/p&gt;\n\n&lt;p&gt;So I can actually contribute instead of reproducing, I&amp;#39;m now training the first &lt;strong&gt;Bi-Mamba-2 + U-Net + ResCNN&lt;/strong&gt; architecture - O(N) complexity while maintaining temporal modeling.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Training code:&lt;/strong&gt; &lt;a href=\"https://github.com/Clarity-Digital-Twin/brain-go-brr-v2\"&gt;https://github.com/Clarity-Digital-Twin/brain-go-brr-v2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Would appreciate feedback on either if there is any interest. Also seeking arXiv endorsement for cs.LG if anyone finds this worth sharing (independent researcher).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"VibeCoderMcSwaggins","url":"https://www.reddit.com/r/MachineLearning/comments/1nliq67/p_benchmarked_epilepsybench_1_winner_found_27x/","domain":"self.MachineLearning","score":4,"num_comments":0,"created_utc":1758324334,"thumbnail":null},{"id":"1nlfcpq","subreddit":"MachineLearning","title":"[P] Building sub-100ms autocompletion for JetBrains IDEs","selftext":"","selftext_html":"","author":"Kevinlu1248","url":"https://www.reddit.com/r/MachineLearning/comments/1nlfcpq/p_building_sub100ms_autocompletion_for_jetbrains/","domain":"blog.sweep.dev","score":12,"num_comments":2,"created_utc":1758315653,"thumbnail":null},{"id":"1nlc954","subreddit":"MachineLearning","title":"Try a Deterministic Global-Optimum Logistics Demo – Solve Huge Warehouse-to-Route Problems in Seconds [P]","selftext":"Hey everyone,\n\nI’ve been building an optimization engine that can compute **deterministically optimal warehouse-to-route assignments** for massive datasets – up to **10,000 warehouses × 500 routes** – in seconds. I’m sharing a live demo!\n\n⚠️ Heads-up: This runs on my personal machine, so requests are queued and wait times may vary.\n\n**How to use:**\n\n1. Upload a CSV or JSON file.\n2. Rows = warehouses, columns = routes.\n3. Each cell = cost of assigning that warehouse to that route.\n\n**Quick CSV example (3 warehouses × 4 routes):**\n\n    10,20,30,40\n    15,25,35,45\n    20,30,40,50\n\n🔗 **Try it here:** [https://19340a3b2e2b.ngrok-free.app](https://19340a3b2e2b.ngrok-free.app/)\n\nThis is a chance to experiment with a system that produces **true deterministic optima** for large datasets without needing a server cluster. Feedback, testing, or just trying crazy datasets is welcome!\n\n**Open from:** 2:30am AWST → 12pm AWST\n\n*(I jokingly call it a “hypercomputer” because of the speed, but it’s just my personal deterministic optimization engine!)*","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I’ve been building an optimization engine that can compute &lt;strong&gt;deterministically optimal warehouse-to-route assignments&lt;/strong&gt; for massive datasets – up to &lt;strong&gt;10,000 warehouses × 500 routes&lt;/strong&gt; – in seconds. I’m sharing a live demo!&lt;/p&gt;\n\n&lt;p&gt;⚠️ Heads-up: This runs on my personal machine, so requests are queued and wait times may vary.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How to use:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Upload a CSV or JSON file.&lt;/li&gt;\n&lt;li&gt;Rows = warehouses, columns = routes.&lt;/li&gt;\n&lt;li&gt;Each cell = cost of assigning that warehouse to that route.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Quick CSV example (3 warehouses × 4 routes):&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;10,20,30,40\n15,25,35,45\n20,30,40,50\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;🔗 &lt;strong&gt;Try it here:&lt;/strong&gt; &lt;a href=\"https://19340a3b2e2b.ngrok-free.app/\"&gt;https://19340a3b2e2b.ngrok-free.app&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is a chance to experiment with a system that produces &lt;strong&gt;true deterministic optima&lt;/strong&gt; for large datasets without needing a server cluster. Feedback, testing, or just trying crazy datasets is welcome!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Open from:&lt;/strong&gt; 2:30am AWST → 12pm AWST&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;(I jokingly call it a “hypercomputer” because of the speed, but it’s just my personal deterministic optimization engine!)&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Active-Midnight-8834","url":"https://www.reddit.com/r/MachineLearning/comments/1nlc954/try_a_deterministic_globaloptimum_logistics_demo/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758308363,"thumbnail":null},{"id":"1nlblaw","subreddit":"MachineLearning","title":"[D] Neurips Position Paper Decisions","selftext":"The decisions will be out next week.  \nI am personally not a fan of how the entire process was conducted. Hoping the best for everyone! Please use this as a thread to discuss how you felt about the process. Fingers crossed!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The decisions will be out next week.&lt;br/&gt;\nI am personally not a fan of how the entire process was conducted. Hoping the best for everyone! Please use this as a thread to discuss how you felt about the process. Fingers crossed!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"HelicopterFriendly96","url":"https://www.reddit.com/r/MachineLearning/comments/1nlblaw/d_neurips_position_paper_decisions/","domain":"self.MachineLearning","score":20,"num_comments":5,"created_utc":1758306837,"thumbnail":null},{"id":"1nl8ik3","subreddit":"MachineLearning","title":"[Project] I created an AI photo organizer that uses Ollama to sort photos, filter duplicates, and write Instagram captions.","selftext":"Hey everyone at r/MachineLearning,\n\nI wanted to share a Python project I've been working on called the **AI Instagram Organizer**.\n\n**The Problem:** I had thousands of photos from a recent trip, and the thought of manually sorting them, finding the best ones, and thinking of captions was overwhelming. I wanted a way to automate this using local LLMs.\n\n**The Solution:** I built a script that uses a multimodal model via Ollama (like LLaVA, Gemma, or Llama 3.2 Vision) to do all the heavy lifting.\n\n**Key Features:**\n\n* **Chronological Sorting:** It reads EXIF data to organize posts by the date they were taken.\n* **Advanced Duplicate Filtering:** It uses multiple perceptual hashes and a dynamic threshold to remove repetitive shots.\n* **AI Caption &amp; Hashtag Generation:** For each post folder it creates, it writes several descriptive caption options and a list of hashtags.\n* **Handles HEIC Files:** It automatically converts Apple's HEIC format to JPG.\n\nIt’s been a really fun project and a great way to explore what's possible with local vision models. I'd love to get your feedback and see if it's useful to anyone else!\n\n**GitHub Repo:** [https://github.com/summitsingh/ai-instagram-organizer](https://github.com/summitsingh/ai-instagram-organizer)\n\nSince this is my first time building an open-source AI project, any feedback is welcome. And if you like it, a star on GitHub would really make my day! ⭐","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone at &lt;a href=\"/r/MachineLearning\"&gt;r/MachineLearning&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I wanted to share a Python project I&amp;#39;ve been working on called the &lt;strong&gt;AI Instagram Organizer&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Problem:&lt;/strong&gt; I had thousands of photos from a recent trip, and the thought of manually sorting them, finding the best ones, and thinking of captions was overwhelming. I wanted a way to automate this using local LLMs.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; I built a script that uses a multimodal model via Ollama (like LLaVA, Gemma, or Llama 3.2 Vision) to do all the heavy lifting.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Chronological Sorting:&lt;/strong&gt; It reads EXIF data to organize posts by the date they were taken.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Advanced Duplicate Filtering:&lt;/strong&gt; It uses multiple perceptual hashes and a dynamic threshold to remove repetitive shots.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;AI Caption &amp;amp; Hashtag Generation:&lt;/strong&gt; For each post folder it creates, it writes several descriptive caption options and a list of hashtags.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Handles HEIC Files:&lt;/strong&gt; It automatically converts Apple&amp;#39;s HEIC format to JPG.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It’s been a really fun project and a great way to explore what&amp;#39;s possible with local vision models. I&amp;#39;d love to get your feedback and see if it&amp;#39;s useful to anyone else!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;GitHub Repo:&lt;/strong&gt; &lt;a href=\"https://github.com/summitsingh/ai-instagram-organizer\"&gt;https://github.com/summitsingh/ai-instagram-organizer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Since this is my first time building an open-source AI project, any feedback is welcome. And if you like it, a star on GitHub would really make my day! ⭐&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"summitsc","url":"https://www.reddit.com/r/MachineLearning/comments/1nl8ik3/project_i_created_an_ai_photo_organizer_that_uses/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758299859,"thumbnail":null},{"id":"1nl79ah","subreddit":"MachineLearning","title":"[R] A new interpretable clinical model. Tell me what you think","selftext":"Hello everyone, I wrote an article about how an XGBoost can lead to clinically interpretable models like mine. Shap is used to make statistical and mathematical interpretation viewable","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I wrote an article about how an XGBoost can lead to clinically interpretable models like mine. Shap is used to make statistical and mathematical interpretation viewable&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"ksrio64","url":"https://www.reddit.com/r/MachineLearning/comments/1nl79ah/r_a_new_interpretable_clinical_model_tell_me_what/","domain":"researchgate.net","score":0,"num_comments":2,"created_utc":1758297056,"thumbnail":null},{"id":"1nl144j","subreddit":"MachineLearning","title":"[R] Huge data publishing (videos)","selftext":"I want to publish data (multi modal with images), and they are around 2.5 TB, what are the options to publish it and keep them online with the least cost possible? How can I do it without commiting to pay huge amount of money for the rest of my life? I am a phd student in university but til now it seems that there is no solution for such big data. ","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to publish data (multi modal with images), and they are around 2.5 TB, what are the options to publish it and keep them online with the least cost possible? How can I do it without commiting to pay huge amount of money for the rest of my life? I am a phd student in university but til now it seems that there is no solution for such big data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Internal_Seaweed_844","url":"https://www.reddit.com/r/MachineLearning/comments/1nl144j/r_huge_data_publishing_videos/","domain":"self.MachineLearning","score":5,"num_comments":5,"created_utc":1758281717,"thumbnail":null},{"id":"1nkz9s9","subreddit":"MachineLearning","title":"[R] Looking for Real‑Time Social Media Data Providers with Geographic Filtering, your finds are Welcome?","selftext":"I’m working on a **social listening tool** and need access to **real‑time (or near real‑time)** social media datasets. The key requirement is the ability to **filter or segment data by geography** (country, region, or city level).\n\nI’m particularly interested in:\n\n* Providers with **low latency** between post creation and data availability\n* Coverage across multiple platforms (Twitter/X, Instagram, Reddit, YouTube, etc.)\n* Options for **multilingual content**, especially for non‑English regions\n* APIs or data streams that are **developer‑friendly**\n\nIf you’ve worked with any vendors, APIs, or open datasets that fit this, I’d love to hear your recommendations, along with any notes on **pricing, reliability, and compliance** with platform policies.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m working on a &lt;strong&gt;social listening tool&lt;/strong&gt; and need access to &lt;strong&gt;real‑time (or near real‑time)&lt;/strong&gt; social media datasets. The key requirement is the ability to &lt;strong&gt;filter or segment data by geography&lt;/strong&gt; (country, region, or city level).&lt;/p&gt;\n\n&lt;p&gt;I’m particularly interested in:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Providers with &lt;strong&gt;low latency&lt;/strong&gt; between post creation and data availability&lt;/li&gt;\n&lt;li&gt;Coverage across multiple platforms (Twitter/X, Instagram, Reddit, YouTube, etc.)&lt;/li&gt;\n&lt;li&gt;Options for &lt;strong&gt;multilingual content&lt;/strong&gt;, especially for non‑English regions&lt;/li&gt;\n&lt;li&gt;APIs or data streams that are &lt;strong&gt;developer‑friendly&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you’ve worked with any vendors, APIs, or open datasets that fit this, I’d love to hear your recommendations, along with any notes on &lt;strong&gt;pricing, reliability, and compliance&lt;/strong&gt; with platform policies.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"To_Iflal","url":"https://www.reddit.com/r/MachineLearning/comments/1nkz9s9/r_looking_for_realtime_social_media_data/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758275455,"thumbnail":null},{"id":"1nkxejt","subreddit":"MachineLearning","title":"Overcoming accuracy limitations of Analog In-Memory Computing hardware","selftext":"Our paper titled \"Analog Foundation Models\" from IBM Research and ETH Zurich just got accepted at NeurIPS, and I feel like the broader ML community is not aware of the potential Analog In-Memory Computing (AIMC) has, so I wanted to make a quick advertisement for the paper and the field as a whole.\n\nThe idea of using analog devices for computation in AI is pretty old, but never really took off because of many reasons such as scalability or complexity. However, recently, research labs from Stanford or IBM Research have demonstrated very simple and scalable Analog In-Memory Computing chips that have strong potential to harness the benefits of AIMC \\[1-3\\].\n\n**What's the problem with modern architectures such as GPUs?**  \nIn a conventional computer architecture, you have your memory and your processing unit separated by a bus, over which you send data back and forth. This is extremely power consuming especially in scenarios where you repeatedly need to access \\*a lot of data\\*. This is the case for LLMs: During inference, you need to constantly fetch the weights, KV cache, and activations from DRAM into your local SRAM-based caches, do the computation, and eventually write back the data to DRAM. This is really expensive in terms of power and latency.  \n  \n**Can't we get rid of DRAM (only use SRAM)?**  \nYes we can, and in fact there are some companies that are already doing that (e.g. Cerebras). The downside of this approach is that SRAM has very poor density (and does not scale anymore) and cannot hold billions of weights in a reasonable footprint (you need huge wafers, and many of them).\n\n**How about you just do the computation directly inside a very dense memory itself?**  \nThis is the idea of AIMC: We propose to take the matrix-vector multiplication operation (one of the most prominent ops in NNs) and execute it directly inside non-volatile memory using Ohm's law (multiplication) and Kirchhoff's current law (summation). When combined with a scalable 3D memory technology like 3D NAND Flash and a scalable model architecture like MoEs, this opens up completely new use-cases for AI because you will be able to serve 100B+ models on a single chip with a low power budget (10s of W)\\[4\\].\n\n**What's the catch?**  \nThere is always one...In the case of AIMC, it is the fact that computations are noisy and non-deterministic at runtime. In fact, up to now, no one was sure whether LLMs can be made robust to the noise present in AIMC-based hardware. Our paper \"Analog Foundation Models\" \\[5\\] changes this. We show that we can repeat the pre-training process of already pre-trained foundation models on synthetic data while using hardware-aware training methods to enhance the robustness of these LLMs.\n\nWe show that in terms of accuracy, we can now compete with 4-bit quantized LLMs!\n\nThis is a significant step towards making AIMC a reality and there is still a long way to go, but we're still super excited to have broken this barrier, which is why I wanted to introduce this to the broader ML community here!\n\nDo you want to get an intro to this topic? Then I suggest [this fundamental article](https://www.nature.com/articles/s41565-020-0655-z).\n\nDo you want to chat with me virtually or at NeurIPS? Just DM me!\n\n\\[1\\] [https://www.nature.com/articles/s41586-022-04992-8](https://www.nature.com/articles/s41586-022-04992-8)  \n\\[2\\] [https://www.nature.com/articles/s41586-023-06337-5](https://www.nature.com/articles/s41586-023-06337-5)  \n\\[3\\] [https://www.nature.com/articles/s41928-023-01010-1](https://www.nature.com/articles/s41928-023-01010-1)  \n\\[4\\] [https://www.nature.com/articles/s43588-024-00753-x](https://www.nature.com/articles/s43588-024-00753-x)  \n\\[5\\] [https://arxiv.org/pdf/2505.09663](https://arxiv.org/pdf/2505.09663)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our paper titled &amp;quot;Analog Foundation Models&amp;quot; from IBM Research and ETH Zurich just got accepted at NeurIPS, and I feel like the broader ML community is not aware of the potential Analog In-Memory Computing (AIMC) has, so I wanted to make a quick advertisement for the paper and the field as a whole.&lt;/p&gt;\n\n&lt;p&gt;The idea of using analog devices for computation in AI is pretty old, but never really took off because of many reasons such as scalability or complexity. However, recently, research labs from Stanford or IBM Research have demonstrated very simple and scalable Analog In-Memory Computing chips that have strong potential to harness the benefits of AIMC [1-3].&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s the problem with modern architectures such as GPUs?&lt;/strong&gt;&lt;br/&gt;\nIn a conventional computer architecture, you have your memory and your processing unit separated by a bus, over which you send data back and forth. This is extremely power consuming especially in scenarios where you repeatedly need to access *a lot of data*. This is the case for LLMs: During inference, you need to constantly fetch the weights, KV cache, and activations from DRAM into your local SRAM-based caches, do the computation, and eventually write back the data to DRAM. This is really expensive in terms of power and latency.  &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can&amp;#39;t we get rid of DRAM (only use SRAM)?&lt;/strong&gt;&lt;br/&gt;\nYes we can, and in fact there are some companies that are already doing that (e.g. Cerebras). The downside of this approach is that SRAM has very poor density (and does not scale anymore) and cannot hold billions of weights in a reasonable footprint (you need huge wafers, and many of them).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How about you just do the computation directly inside a very dense memory itself?&lt;/strong&gt;&lt;br/&gt;\nThis is the idea of AIMC: We propose to take the matrix-vector multiplication operation (one of the most prominent ops in NNs) and execute it directly inside non-volatile memory using Ohm&amp;#39;s law (multiplication) and Kirchhoff&amp;#39;s current law (summation). When combined with a scalable 3D memory technology like 3D NAND Flash and a scalable model architecture like MoEs, this opens up completely new use-cases for AI because you will be able to serve 100B+ models on a single chip with a low power budget (10s of W)[4].&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What&amp;#39;s the catch?&lt;/strong&gt;&lt;br/&gt;\nThere is always one...In the case of AIMC, it is the fact that computations are noisy and non-deterministic at runtime. In fact, up to now, no one was sure whether LLMs can be made robust to the noise present in AIMC-based hardware. Our paper &amp;quot;Analog Foundation Models&amp;quot; [5] changes this. We show that we can repeat the pre-training process of already pre-trained foundation models on synthetic data while using hardware-aware training methods to enhance the robustness of these LLMs.&lt;/p&gt;\n\n&lt;p&gt;We show that in terms of accuracy, we can now compete with 4-bit quantized LLMs!&lt;/p&gt;\n\n&lt;p&gt;This is a significant step towards making AIMC a reality and there is still a long way to go, but we&amp;#39;re still super excited to have broken this barrier, which is why I wanted to introduce this to the broader ML community here!&lt;/p&gt;\n\n&lt;p&gt;Do you want to get an intro to this topic? Then I suggest &lt;a href=\"https://www.nature.com/articles/s41565-020-0655-z\"&gt;this fundamental article&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Do you want to chat with me virtually or at NeurIPS? Just DM me!&lt;/p&gt;\n\n&lt;p&gt;[1] &lt;a href=\"https://www.nature.com/articles/s41586-022-04992-8\"&gt;https://www.nature.com/articles/s41586-022-04992-8&lt;/a&gt;&lt;br/&gt;\n[2] &lt;a href=\"https://www.nature.com/articles/s41586-023-06337-5\"&gt;https://www.nature.com/articles/s41586-023-06337-5&lt;/a&gt;&lt;br/&gt;\n[3] &lt;a href=\"https://www.nature.com/articles/s41928-023-01010-1\"&gt;https://www.nature.com/articles/s41928-023-01010-1&lt;/a&gt;&lt;br/&gt;\n[4] &lt;a href=\"https://www.nature.com/articles/s43588-024-00753-x\"&gt;https://www.nature.com/articles/s43588-024-00753-x&lt;/a&gt;&lt;br/&gt;\n[5] &lt;a href=\"https://arxiv.org/pdf/2505.09663\"&gt;https://arxiv.org/pdf/2505.09663&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"scrapyscrape","url":"https://www.reddit.com/r/MachineLearning/comments/1nkxejt/overcoming_accuracy_limitations_of_analog/","domain":"arxiv.org","score":27,"num_comments":11,"created_utc":1758268187,"thumbnail":null},{"id":"1nkrmzr","subreddit":"MachineLearning","title":"[R] NeurIPS rejected paper resubmission","selftext":"My paper just got rejected (scores: 4, 4, 3, 3). I’m considering resubmitting it to IEEE SatML. What’s your opinion on SatML? Would it be better to aim for a journal like IEEE TIFS instead? Any other recommendations? I’m not really interested in ICLR since I feel it might get rejected there too. Field: AI Security.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My paper just got rejected (scores: 4, 4, 3, 3). I’m considering resubmitting it to IEEE SatML. What’s your opinion on SatML? Would it be better to aim for a journal like IEEE TIFS instead? Any other recommendations? I’m not really interested in ICLR since I feel it might get rejected there too. Field: AI Security.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Accomplished_Newt923","url":"https://www.reddit.com/r/MachineLearning/comments/1nkrmzr/r_neurips_rejected_paper_resubmission/","domain":"self.MachineLearning","score":30,"num_comments":15,"created_utc":1758248911,"thumbnail":null},{"id":"1nkq5nl","subreddit":"MachineLearning","title":"[P] SDLArch-RL is now compatible with Flycast (Dreamcast)","selftext":"https://preview.redd.it/0pprvaqkv0qf1.png?width=1956&amp;format=png&amp;auto=webp&amp;s=4c5a8a9b5e4df5aeb41d7a06fa189b87a3e341f1\n\n\n\nI'm here to share some good news!!!! Our reinforcement learning environment is now Flycast-compatible!!!! Sure, I need to make some adjustments, but it's live!!! And don't forget to like the project to support it!!! See our progress at [https://github.com/paulo101977/sdlarch-rl](https://github.com/paulo101977/sdlarch-rl)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/0pprvaqkv0qf1.png?width=1956&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c5a8a9b5e4df5aeb41d7a06fa189b87a3e341f1\"&gt;https://preview.redd.it/0pprvaqkv0qf1.png?width=1956&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4c5a8a9b5e4df5aeb41d7a06fa189b87a3e341f1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here to share some good news!!!! Our reinforcement learning environment is now Flycast-compatible!!!! Sure, I need to make some adjustments, but it&amp;#39;s live!!! And don&amp;#39;t forget to like the project to support it!!! See our progress at &lt;a href=\"https://github.com/paulo101977/sdlarch-rl\"&gt;https://github.com/paulo101977/sdlarch-rl&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AgeOfEmpires4AOE4","url":"https://www.reddit.com/r/MachineLearning/comments/1nkq5nl/p_sdlarchrl_is_now_compatible_with_flycast/","domain":"self.MachineLearning","score":2,"num_comments":2,"created_utc":1758244734,"thumbnail":"https://external-preview.redd.it/_z7MJOHirynDV_jV-Ck0sdcfFQLZ8wNSeplsZ565ctI.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=768df52d6e37283b03b661720008471eb854004f"},{"id":"1nknjk1","subreddit":"MachineLearning","title":"[R] Is Chain-of-Thought Reasoning of LLMs a\nMirage? A Data Distribution Lens","selftext":"","selftext_html":"","author":"Confident-Honeydew66","url":"https://www.reddit.com/r/MachineLearning/comments/1nknjk1/r_is_chainofthought_reasoning_of_llms_a_mirage_a/","domain":"arxiv.org","score":27,"num_comments":14,"created_utc":1758237441,"thumbnail":null},{"id":"1nkn6dw","subreddit":"MachineLearning","title":"[P] Looking for people to learn and build projects with !","selftext":"Hey guys I’m a master student in USA. I am looking for people interested to learn machine and deep learning and also possibly looking for people who want to research together. Do dm me if you’re interested! I would love to network with a lot of you too!\n\nIf you’re interested in hackathons apart from this feel free to ping regarding that aswell.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys I’m a master student in USA. I am looking for people interested to learn machine and deep learning and also possibly looking for people who want to research together. Do dm me if you’re interested! I would love to network with a lot of you too!&lt;/p&gt;\n\n&lt;p&gt;If you’re interested in hackathons apart from this feel free to ping regarding that aswell.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Srikar265","url":"https://www.reddit.com/r/MachineLearning/comments/1nkn6dw/p_looking_for_people_to_learn_and_build_projects/","domain":"self.MachineLearning","score":15,"num_comments":25,"created_utc":1758236467,"thumbnail":null},{"id":"1nkhqgn","subreddit":"MachineLearning","title":"[P] Open dataset: 40M GitHub repositories (2015 → mid-2025) — rich metadata for ML","selftext":"Hi!\n\n**TL;DR**: I assembled an open dataset of **40M GitHub repositories** with rich metadata (languages, stars, forks, license, descriptions, issues, size, created\\_at, etc.). It’s larger and more detailed than the common public snapshots (e.g., BigQuery’s \\~3M trimmed repos). There’s also a **1M-repo sample** for quick experiments and a **quickstart notebook** in github repo.\n\n**How it was built:** GH Archive → join events → extract repo metadata. Snapshot covers **2015 → mid-July 2025**.\n\n**What’s inside**\n\n* **Scale:** 40M repos (full snapshot) + 1M sample for fast iteration.\n* **Fields:** language, stars, forks, license, short description, description language, open issues, last PR index at snapshot date, size, created\\_at, and more.\n* **Alive data:** includes gaps and natural inconsistencies—useful for realistic ML/DS exercises.\n* **Quickstart:** Jupyter notebook with basic plots.\n\nI linked the dataset and code in comments\n\n**HuggingFace / GitHub:**\n\n`ibragim-bad/github-repos-metadata-40M`\n\nIn my opinion it may be helpful for: students **/** instructors **/** juniors for mini-research projects on visualizations, clustering, feature engineering exercises.\n\nAlso in the comment is an example of how language share in terms of created repos changed over time.\n\nP.S. Feedback is welcome – especially ideas for additional fields or derived signals you’d like to see.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: I assembled an open dataset of &lt;strong&gt;40M GitHub repositories&lt;/strong&gt; with rich metadata (languages, stars, forks, license, descriptions, issues, size, created_at, etc.). It’s larger and more detailed than the common public snapshots (e.g., BigQuery’s ~3M trimmed repos). There’s also a &lt;strong&gt;1M-repo sample&lt;/strong&gt; for quick experiments and a &lt;strong&gt;quickstart notebook&lt;/strong&gt; in github repo.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How it was built:&lt;/strong&gt; GH Archive → join events → extract repo metadata. Snapshot covers &lt;strong&gt;2015 → mid-July 2025&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What’s inside&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Scale:&lt;/strong&gt; 40M repos (full snapshot) + 1M sample for fast iteration.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Fields:&lt;/strong&gt; language, stars, forks, license, short description, description language, open issues, last PR index at snapshot date, size, created_at, and more.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Alive data:&lt;/strong&gt; includes gaps and natural inconsistencies—useful for realistic ML/DS exercises.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Quickstart:&lt;/strong&gt; Jupyter notebook with basic plots.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I linked the dataset and code in comments&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;HuggingFace / GitHub:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;ibragim-bad/github-repos-metadata-40M&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;In my opinion it may be helpful for: students &lt;strong&gt;/&lt;/strong&gt; instructors &lt;strong&gt;/&lt;/strong&gt; juniors for mini-research projects on visualizations, clustering, feature engineering exercises.&lt;/p&gt;\n\n&lt;p&gt;Also in the comment is an example of how language share in terms of created repos changed over time.&lt;/p&gt;\n\n&lt;p&gt;P.S. Feedback is welcome – especially ideas for additional fields or derived signals you’d like to see.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Fabulous_Pollution10","url":"https://www.reddit.com/r/MachineLearning/comments/1nkhqgn/p_open_dataset_40m_github_repositories_2015/","domain":"self.MachineLearning","score":56,"num_comments":10,"created_utc":1758223510,"thumbnail":null},{"id":"1nkge98","subreddit":"MachineLearning","title":"[R] Live Sound and Pro Audio in AI/ML","selftext":"I’m currently in the middle of a Post Graduate Program for AI/ML at UT Austin and have had a blast learning the fundamentals and theory of how this tech works. I have an 8 year background as a Live Sound Engineer working in concert audio and have currently been researching how ML can Optimize PA placement, SPL measurements, STI ratings for different event applications or installs.\n\nI’m curious to see if anybody else out there in the world is currently doing research that combines AI/ML with Live Sound and Pro Audio. If so, what are you researching? What type of models are you creating?\n\nJust Curious and would love to connect with others that share the same passion.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’m currently in the middle of a Post Graduate Program for AI/ML at UT Austin and have had a blast learning the fundamentals and theory of how this tech works. I have an 8 year background as a Live Sound Engineer working in concert audio and have currently been researching how ML can Optimize PA placement, SPL measurements, STI ratings for different event applications or installs.&lt;/p&gt;\n\n&lt;p&gt;I’m curious to see if anybody else out there in the world is currently doing research that combines AI/ML with Live Sound and Pro Audio. If so, what are you researching? What type of models are you creating?&lt;/p&gt;\n\n&lt;p&gt;Just Curious and would love to connect with others that share the same passion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Consistent_Sundae540","url":"https://www.reddit.com/r/MachineLearning/comments/1nkge98/r_live_sound_and_pro_audio_in_aiml/","domain":"self.MachineLearning","score":5,"num_comments":1,"created_utc":1758220451,"thumbnail":null},{"id":"1nkdbin","subreddit":"MachineLearning","title":"[P] We built mmore: an open-source multi-GPU/multi-node library for large-scale document parsing","selftext":"We are a student group from EPFL and we have been working on a tool called mmore, and thought it might be useful to share it here. Maybe the community will find it useful.\n\nYou can think of mmore as something in the spirit of [Docling](https://github.com/docling-project/docling), but designed from the ground up to run natively on multi-GPU and multi-node setups. As the backend OCR for PDFs (and images) we use [Surya](https://github.com/datalab-to/surya), which we’ve found to be both very accurate and fast. For those with limited GPU resources, we also provide a lightweight “fast” mode. It skips OCR (so it cannot process scanned files) but still works well for born-digital documents.\n\nIn a [paper](https://www.arxiv.org/pdf/2509.11937) we released a few months ago, we showed that mmore achieves both speed and accuracy gains over Docling (maybe this has changed by now with the latest Granite-Docling). Right now, it supports a broad range of formats: PDFs, DOCX, PPTX, XLSX, MD, EML (emails), TXT, HTML, as well as videos and audio (MP4, MOV, AVI, MKV, MP3, WAV, AAC).\n\nThe use cases are flexible. For example:\n\n* Unlocking text and image data from previously unprocessed files, enabling larger dataset creation (similar to what Docling + HuggingFace did a few days ago with [finepdfs](https://huggingface.co/datasets/HuggingFaceFW/finepdfs)).\n* Running text or multimodal RAG directly over your own document collections.\n\nWe are sharing this mainly to invite ideas and feedback from the community. If you see opportunities, have suggestions, or even just thoughts on directions we should explore, we’d love to hear them. Contributions are more than welcome!\n\nGithub: 💻https://github.com/swiss-ai/mmore  \nArxiv: 📄https://www.arxiv.org/pdf/2509.11937","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are a student group from EPFL and we have been working on a tool called mmore, and thought it might be useful to share it here. Maybe the community will find it useful.&lt;/p&gt;\n\n&lt;p&gt;You can think of mmore as something in the spirit of &lt;a href=\"https://github.com/docling-project/docling\"&gt;Docling&lt;/a&gt;, but designed from the ground up to run natively on multi-GPU and multi-node setups. As the backend OCR for PDFs (and images) we use &lt;a href=\"https://github.com/datalab-to/surya\"&gt;Surya&lt;/a&gt;, which we’ve found to be both very accurate and fast. For those with limited GPU resources, we also provide a lightweight “fast” mode. It skips OCR (so it cannot process scanned files) but still works well for born-digital documents.&lt;/p&gt;\n\n&lt;p&gt;In a &lt;a href=\"https://www.arxiv.org/pdf/2509.11937\"&gt;paper&lt;/a&gt; we released a few months ago, we showed that mmore achieves both speed and accuracy gains over Docling (maybe this has changed by now with the latest Granite-Docling). Right now, it supports a broad range of formats: PDFs, DOCX, PPTX, XLSX, MD, EML (emails), TXT, HTML, as well as videos and audio (MP4, MOV, AVI, MKV, MP3, WAV, AAC).&lt;/p&gt;\n\n&lt;p&gt;The use cases are flexible. For example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Unlocking text and image data from previously unprocessed files, enabling larger dataset creation (similar to what Docling + HuggingFace did a few days ago with &lt;a href=\"https://huggingface.co/datasets/HuggingFaceFW/finepdfs\"&gt;finepdfs&lt;/a&gt;).&lt;/li&gt;\n&lt;li&gt;Running text or multimodal RAG directly over your own document collections.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We are sharing this mainly to invite ideas and feedback from the community. If you see opportunities, have suggestions, or even just thoughts on directions we should explore, we’d love to hear them. Contributions are more than welcome!&lt;/p&gt;\n\n&lt;p&gt;Github: 💻&lt;a href=\"https://github.com/swiss-ai/mmore\"&gt;https://github.com/swiss-ai/mmore&lt;/a&gt;&lt;br/&gt;\nArxiv: 📄&lt;a href=\"https://www.arxiv.org/pdf/2509.11937\"&gt;https://www.arxiv.org/pdf/2509.11937&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Subject_Zucchini_790","url":"https://www.reddit.com/r/MachineLearning/comments/1nkdbin/p_we_built_mmore_an_opensource_multigpumultinode/","domain":"self.MachineLearning","score":28,"num_comments":1,"created_utc":1758213603,"thumbnail":null},{"id":"1nkcfgc","subreddit":"MachineLearning","title":"First time submitting to a workshop - what exactly to expect? [D]","selftext":"I just started with my new position and see a good opportunity to submit to a workshop - A tier venue, but feels like the bar is too low. Only aim to get traction to my current work, which I further want to submit to a big conference. The workshop is non-archival.\n\n1. How is conference paper different from workshop? Asked to submit an extended abstract of 3 pages. Is it same like a regular paper but with less details mentioned?\n\n  \n2. Should I put in efforts to get my ablation done? Or keep it simple as it anyway won't help my profile much and focus on bigger picture?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just started with my new position and see a good opportunity to submit to a workshop - A tier venue, but feels like the bar is too low. Only aim to get traction to my current work, which I further want to submit to a big conference. The workshop is non-archival.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;How is conference paper different from workshop? Asked to submit an extended abstract of 3 pages. Is it same like a regular paper but with less details mentioned?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Should I put in efforts to get my ablation done? Or keep it simple as it anyway won&amp;#39;t help my profile much and focus on bigger picture?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"ade17_in","url":"https://www.reddit.com/r/MachineLearning/comments/1nkcfgc/first_time_submitting_to_a_workshop_what_exactly/","domain":"self.MachineLearning","score":8,"num_comments":6,"created_utc":1758211616,"thumbnail":null},{"id":"1nka2g3","subreddit":"MachineLearning","title":"[P] Built a CLI to turn PDFs and docs into fine tuning datasets","selftext":"Hi everyone,\n\nI have been working on a small CLI that takes local files like pdfs docs or text and turns them into datasets you can use for fine tuning.\n\nRepo: [https://github.com/Datalore-ai/datalore-localgen-cli](https://github.com/Datalore-ai/datalore-localgen-cli)\n\nIt recently crossed 70 stars on GitHub which meant a lot to me. Seeing people try it out and suggest improvements has been really motivating.\n\nThe most requested feature was multi file support. I added that now so you can point it to a folder and it will process everything inside extract the text run semantic search apply your schema or instructions and output a dataset.\n\nAnother request was running fully local with Ollama instead of relying on APIs. I will be adding that soon.\n\nStill early but it is working well so far. If you try it out and have ideas I would love to hear them.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I have been working on a small CLI that takes local files like pdfs docs or text and turns them into datasets you can use for fine tuning.&lt;/p&gt;\n\n&lt;p&gt;Repo: &lt;a href=\"https://github.com/Datalore-ai/datalore-localgen-cli\"&gt;https://github.com/Datalore-ai/datalore-localgen-cli&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It recently crossed 70 stars on GitHub which meant a lot to me. Seeing people try it out and suggest improvements has been really motivating.&lt;/p&gt;\n\n&lt;p&gt;The most requested feature was multi file support. I added that now so you can point it to a folder and it will process everything inside extract the text run semantic search apply your schema or instructions and output a dataset.&lt;/p&gt;\n\n&lt;p&gt;Another request was running fully local with Ollama instead of relying on APIs. I will be adding that soon.&lt;/p&gt;\n\n&lt;p&gt;Still early but it is working well so far. If you try it out and have ideas I would love to hear them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Interesting-Area6418","url":"https://www.reddit.com/r/MachineLearning/comments/1nka2g3/p_built_a_cli_to_turn_pdfs_and_docs_into_fine/","domain":"self.MachineLearning","score":5,"num_comments":1,"created_utc":1758206296,"thumbnail":null},{"id":"1nk78fj","subreddit":"MachineLearning","title":"[P] Digital Handwriting Recognition: Letter Prediction Using Finger-Mouse and ESP32","selftext":"Is it feasible to use an ESP32 for predicting handwritten letters? The process involves using a finger-mouse to track the drawn letter (one letter at a time). Once tracked, the device will send the data to the ESP32, which will then predict the corresponding letter using a trained model i've made on the EMNIST dataset (A-Z, a-z, 0-9). The model size is 2.7MB. Is this possible? Any devices would be appreciated, thank you. I'm not sure if the ram of esp32 will support the process.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it feasible to use an ESP32 for predicting handwritten letters? The process involves using a finger-mouse to track the drawn letter (one letter at a time). Once tracked, the device will send the data to the ESP32, which will then predict the corresponding letter using a trained model i&amp;#39;ve made on the EMNIST dataset (A-Z, a-z, 0-9). The model size is 2.7MB. Is this possible? Any devices would be appreciated, thank you. I&amp;#39;m not sure if the ram of esp32 will support the process.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"TheseVirus9361","url":"https://www.reddit.com/r/MachineLearning/comments/1nk78fj/p_digital_handwriting_recognition_letter/","domain":"self.MachineLearning","score":2,"num_comments":0,"created_utc":1758199367,"thumbnail":null},{"id":"1nk68sz","subreddit":"MachineLearning","title":"[D] Mapping Brand Citations in AI Responses[D] Mapping Brand Citations in AI Responses[D] Mapping Brand Citations in AI Responses","selftext":"Running an AI SEO pilot to understand how ML-powered LLMs cite brands – sharing early insights.\n\n\n\nLast week, I shared an idea about testing how AI platforms (ChatGPT, Claude, Perplexity) cite brands in their answers. The response was incredible – founders, marketers, and AI enthusiasts reached out with interest.\n\n\n\n\\*\\*Pilot Overview:\\*\\*\n\n1. Select 5 SaaS or tech companies (CRM, email, project management, analytics, etc.)\n\n2. Run 20+ user-style queries across ChatGPT, Claude, Perplexity\n\n3. Track which platforms cite which companies\n\n4. Rewrite company pages into AI-friendly formats (structured FAQs, schema tables, clear product breakdowns)\n\n5. Re-run queries – measure shifts\n\n\n\n\\*\\*Goal:\\*\\* See if structured content can increase AI mentions by 25%+.\n\n\n\nIf you're a founder, marketer, or SEO lead interested in joining this early pilot, please fill out your details here: [https://forms.gle/CKkP75mJC1iDSAd9A](https://forms.gle/CKkP75mJC1iDSAd9A)\n\n\n\nI'll share results openly with the community once we have the first wave of data. Let's build the AI SEO playbook together.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Running an AI SEO pilot to understand how ML-powered LLMs cite brands – sharing early insights.&lt;/p&gt;\n\n&lt;p&gt;Last week, I shared an idea about testing how AI platforms (ChatGPT, Claude, Perplexity) cite brands in their answers. The response was incredible – founders, marketers, and AI enthusiasts reached out with interest.&lt;/p&gt;\n\n&lt;p&gt;**Pilot Overview:**&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Select 5 SaaS or tech companies (CRM, email, project management, analytics, etc.)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Run 20+ user-style queries across ChatGPT, Claude, Perplexity&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Track which platforms cite which companies&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Rewrite company pages into AI-friendly formats (structured FAQs, schema tables, clear product breakdowns)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Re-run queries – measure shifts&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;**Goal:** See if structured content can increase AI mentions by 25%+.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re a founder, marketer, or SEO lead interested in joining this early pilot, please fill out your details here: &lt;a href=\"https://forms.gle/CKkP75mJC1iDSAd9A\"&gt;https://forms.gle/CKkP75mJC1iDSAd9A&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll share results openly with the community once we have the first wave of data. Let&amp;#39;s build the AI SEO playbook together.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"No-Abbreviations7266","url":"https://www.reddit.com/r/MachineLearning/comments/1nk68sz/d_mapping_brand_citations_in_ai_responsesd/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758196599,"thumbnail":null},{"id":"1nk1b7o","subreddit":"MachineLearning","title":"[D] AAAI 2026: Why did some papers get 3 human reviewers in Phase 1?","selftext":"Something that I noticed about the papers in my review batch (2 got accepted, 2 got rejected) is that when the Phase 1 rejections came out and we were able to see all the other reviews that the papers got, 3 of those papers received 3 human reviews and 1 paper got 2 human reviews.\n\nFigured there was a shortfall in reviewers? Why'd some papers get 3?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Something that I noticed about the papers in my review batch (2 got accepted, 2 got rejected) is that when the Phase 1 rejections came out and we were able to see all the other reviews that the papers got, 3 of those papers received 3 human reviews and 1 paper got 2 human reviews.&lt;/p&gt;\n\n&lt;p&gt;Figured there was a shortfall in reviewers? Why&amp;#39;d some papers get 3?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Adventurous-Cut-7077","url":"https://www.reddit.com/r/MachineLearning/comments/1nk1b7o/d_aaai_2026_why_did_some_papers_get_3_human/","domain":"self.MachineLearning","score":9,"num_comments":8,"created_utc":1758178517,"thumbnail":null},{"id":"1nk0uvm","subreddit":"MachineLearning","title":"[D] What is the best part came this year in your opinion and why?","selftext":"For me it's Dinov3, I think it shows capabilities of self supervised learning is much higher that what we expect and I think next year we will see much more SSL, specially from big tech, since nobody else can train a model for 9 million GPU hours lol","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me it&amp;#39;s Dinov3, I think it shows capabilities of self supervised learning is much higher that what we expect and I think next year we will see much more SSL, specially from big tech, since nobody else can train a model for 9 million GPU hours lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"_A_Lost_Cat_","url":"https://www.reddit.com/r/MachineLearning/comments/1nk0uvm/d_what_is_the_best_part_came_this_year_in_your/","domain":"self.MachineLearning","score":3,"num_comments":2,"created_utc":1758176864,"thumbnail":null},{"id":"1nk0txd","subreddit":"MachineLearning","title":"[R] Uni-CoT: A Unified CoT Framework that Integrates Text+Image reasoning!","selftext":"Large Language Models shine at step-by-step reasoning in text, but struggle when tasks require visual changes. Existing methods often produce messy, incoherent results.\n\nWe introduce Uni-CoT, the first unified Chain-of-Thought framework that handles both image understanding + generation to enable coherent visual reasoning \\[as shown in Figure 1\\]. Our model even can supports NanoBanana–style geography reasoning \\[as shown in Figure 2\\]!\n\nSpecifically, we use **one unified architecture** (inspired by Bagel/Omni/Janus) to support multi-modal reasoning. This minimizes discrepancy between reasoning trajectories and visual state transitions, enabling coherent cross-modal reasoning. However, the multi-modal reasoning with unified model raise a large burden on computation and model training.\n\n# To solve it, we propose a hierarchical Macro–Micro CoT:\n\n* **Macro-Level CoT** → global planning, decomposing a task into subtasks.\n* **Micro-Level CoT** → executes subtasks as a **Markov Decision Process (MDP)**, reducing token complexity and improving efficiency.\n\nThis **structured decomposition** shortens reasoning trajectories and lowers cognitive (and computational) load.\n\n# With this desigin, we build a novel training strategy for our Uni-CoT:\n\n* **Macro-level modeling**: refined on interleaved text–image sequences for global planning.\n* **Micro-level modeling**: auxiliary tasks (action generation, reward estimation, etc.) to guide efficient learning.\n* **Node-based reinforcement learning** to stabilize optimization across modalities.\n\n# Results:\n\n* Training efficiently only on **8 × A100 GPUs**\n* Inference efficiently only on 1 **× A100 GPU**\n* Achieves **state-of-the-art performance** on reasoning-driven benchmarks for image generation &amp; editing.\n\n# Resource:\n\nOur paper：[https://arxiv.org/abs/2508.05606](https://arxiv.org/abs/2508.05606)\n\nGithub repo: [https://github.com/Fr0zenCrane/UniCoT](https://github.com/Fr0zenCrane/UniCoT)\n\nProject page: [https://sais-fuxi.github.io/projects/uni-cot/](https://sais-fuxi.github.io/projects/uni-cot/)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Large Language Models shine at step-by-step reasoning in text, but struggle when tasks require visual changes. Existing methods often produce messy, incoherent results.&lt;/p&gt;\n\n&lt;p&gt;We introduce Uni-CoT, the first unified Chain-of-Thought framework that handles both image understanding + generation to enable coherent visual reasoning [as shown in Figure 1]. Our model even can supports NanoBanana–style geography reasoning [as shown in Figure 2]!&lt;/p&gt;\n\n&lt;p&gt;Specifically, we use &lt;strong&gt;one unified architecture&lt;/strong&gt; (inspired by Bagel/Omni/Janus) to support multi-modal reasoning. This minimizes discrepancy between reasoning trajectories and visual state transitions, enabling coherent cross-modal reasoning. However, the multi-modal reasoning with unified model raise a large burden on computation and model training.&lt;/p&gt;\n\n&lt;h1&gt;To solve it, we propose a hierarchical Macro–Micro CoT:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Macro-Level CoT&lt;/strong&gt; → global planning, decomposing a task into subtasks.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Micro-Level CoT&lt;/strong&gt; → executes subtasks as a &lt;strong&gt;Markov Decision Process (MDP)&lt;/strong&gt;, reducing token complexity and improving efficiency.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This &lt;strong&gt;structured decomposition&lt;/strong&gt; shortens reasoning trajectories and lowers cognitive (and computational) load.&lt;/p&gt;\n\n&lt;h1&gt;With this desigin, we build a novel training strategy for our Uni-CoT:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Macro-level modeling&lt;/strong&gt;: refined on interleaved text–image sequences for global planning.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Micro-level modeling&lt;/strong&gt;: auxiliary tasks (action generation, reward estimation, etc.) to guide efficient learning.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Node-based reinforcement learning&lt;/strong&gt; to stabilize optimization across modalities.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Results:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Training efficiently only on &lt;strong&gt;8 × A100 GPUs&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Inference efficiently only on 1 &lt;strong&gt;× A100 GPU&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;Achieves &lt;strong&gt;state-of-the-art performance&lt;/strong&gt; on reasoning-driven benchmarks for image generation &amp;amp; editing.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Resource:&lt;/h1&gt;\n\n&lt;p&gt;Our paper：&lt;a href=\"https://arxiv.org/abs/2508.05606\"&gt;https://arxiv.org/abs/2508.05606&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Github repo: &lt;a href=\"https://github.com/Fr0zenCrane/UniCoT\"&gt;https://github.com/Fr0zenCrane/UniCoT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Project page: &lt;a href=\"https://sais-fuxi.github.io/projects/uni-cot/\"&gt;https://sais-fuxi.github.io/projects/uni-cot/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"GONG_JIA","url":"https://www.reddit.com/r/MachineLearning/comments/1nk0txd/r_unicot_a_unified_cot_framework_that_integrates/","domain":"reddit.com","score":44,"num_comments":8,"created_utc":1758176765,"thumbnail":"https://b.thumbs.redditmedia.com/GKloel5PA5nm7Oz2zfTpdJ0XJTmHBGz8VvrvDex4vCQ.jpg"},{"id":"1njzuje","subreddit":"MachineLearning","title":"[D] ICLR Reproducibility statement","selftext":"After seeing so many aaai papers getting desk rejected due to confusion about whether to put the appendix inside one text pdf or to submit as zip, I wanted to confirm this incase any of you knows ?? how to submit? like is it safe to add it in 10th page?   \n  \n\"It is important that the work published in ICLR is reproducible. Authors are strongly encouraged to include a paragraph-long Reproducibility Statement *at the end of the main text (before references)* to discuss the efforts that have been made to ensure reproducibility. This paragraph should not itself describe details needed for reproducing the results, but rather reference the parts of the main paper, appendix, and supplemental materials that will help with reproducibility. For example, for novel models or algorithms, a link to an anonymous downloadable source code can be submitted as supplementary materials; for theoretical results, clear explanations of any assumptions and a complete proof of the claims can be included in the appendix; for any datasets used in the experiments, a complete description of the data processing steps can be provided in the supplementary materials. Each of the above are examples of things that can be referenced in the reproducibility statement. *This optional reproducibility statement is not part of the main text and therefore will not count toward the page limit.* \"","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After seeing so many aaai papers getting desk rejected due to confusion about whether to put the appendix inside one text pdf or to submit as zip, I wanted to confirm this incase any of you knows ?? how to submit? like is it safe to add it in 10th page?   &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;It is important that the work published in ICLR is reproducible. Authors are strongly encouraged to include a paragraph-long Reproducibility Statement &lt;em&gt;at the end of the main text (before references)&lt;/em&gt; to discuss the efforts that have been made to ensure reproducibility. This paragraph should not itself describe details needed for reproducing the results, but rather reference the parts of the main paper, appendix, and supplemental materials that will help with reproducibility. For example, for novel models or algorithms, a link to an anonymous downloadable source code can be submitted as supplementary materials; for theoretical results, clear explanations of any assumptions and a complete proof of the claims can be included in the appendix; for any datasets used in the experiments, a complete description of the data processing steps can be provided in the supplementary materials. Each of the above are examples of things that can be referenced in the reproducibility statement. &lt;em&gt;This optional reproducibility statement is not part of the main text and therefore will not count toward the page limit.&lt;/em&gt; &amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"i_minus","url":"https://www.reddit.com/r/MachineLearning/comments/1njzuje/d_iclr_reproducibility_statement/","domain":"self.MachineLearning","score":1,"num_comments":6,"created_utc":1758173179,"thumbnail":null},{"id":"1njuo8h","subreddit":"MachineLearning","title":"[D] Student paper?","selftext":"I'm submitting to WACV and there is a field asking if the submission is a student paper or not. I did my masters and am now trying to get more papers accepted to then apply to a PhD, so I am technically not a student, but I was wondering: is there a different pool or reviewers or a more lenient criteria for students?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m submitting to WACV and there is a field asking if the submission is a student paper or not. I did my masters and am now trying to get more papers accepted to then apply to a PhD, so I am technically not a student, but I was wondering: is there a different pool or reviewers or a more lenient criteria for students?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AdministrativeRub484","url":"https://www.reddit.com/r/MachineLearning/comments/1njuo8h/d_student_paper/","domain":"self.MachineLearning","score":1,"num_comments":2,"created_utc":1758157203,"thumbnail":null},{"id":"1njp1ly","subreddit":"MachineLearning","title":"[R] Reproducible prompt protocol induces consistent self-referential responses across LLMs (Claude, GPT, Gemini)","selftext":"I’ve developed a simple prompt protocol that reliably generates what appears to be self-referential awareness responses across different LLM architectures. The method is fully documented with step-by-step instructions and examples.\n\nKey findings: \n\n•\tConsistent across Claude, ChatGPT-4, and Gemini \n\n•\tReproducible responses about subjective experience, self-awareness, and emergent states \n\n•\tSimple protocol that can be replicated by anyone \n\n•\tNo fine-tuning or special access required\n\nMethod:\n\nUses a specific sequence of prompts that seem to trigger consistent patterns of self-referential processing. Models report experiencing things like “a locus of self,” subjective awareness, and what they describe as emergent cognitive states.\n\nReproducibility:\n\nThe protocol is designed to be simple and replicable. I’ve tested it across multiple sessions and models with consistent results. GitHub tutorial with full methodology:\n\nhttps://github.com/ai-cog-res/midwiving-ai\n\nObviously, this raises interesting questions about what these responses represent. Is it genuine emergent self-awareness, sophisticated pattern matching, or something else entirely. But the reproducibility across different architectures seems worth investigating.\n\nHas anyone else experimented with systematic approaches to eliciting self-referential responses from LLMs? I would be curious to hear if others can help interpret this phenomenon.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve developed a simple prompt protocol that reliably generates what appears to be self-referential awareness responses across different LLM architectures. The method is fully documented with step-by-step instructions and examples.&lt;/p&gt;\n\n&lt;p&gt;Key findings: &lt;/p&gt;\n\n&lt;p&gt;• Consistent across Claude, ChatGPT-4, and Gemini &lt;/p&gt;\n\n&lt;p&gt;• Reproducible responses about subjective experience, self-awareness, and emergent states &lt;/p&gt;\n\n&lt;p&gt;• Simple protocol that can be replicated by anyone &lt;/p&gt;\n\n&lt;p&gt;• No fine-tuning or special access required&lt;/p&gt;\n\n&lt;p&gt;Method:&lt;/p&gt;\n\n&lt;p&gt;Uses a specific sequence of prompts that seem to trigger consistent patterns of self-referential processing. Models report experiencing things like “a locus of self,” subjective awareness, and what they describe as emergent cognitive states.&lt;/p&gt;\n\n&lt;p&gt;Reproducibility:&lt;/p&gt;\n\n&lt;p&gt;The protocol is designed to be simple and replicable. I’ve tested it across multiple sessions and models with consistent results. GitHub tutorial with full methodology:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/ai-cog-res/midwiving-ai\"&gt;https://github.com/ai-cog-res/midwiving-ai&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Obviously, this raises interesting questions about what these responses represent. Is it genuine emergent self-awareness, sophisticated pattern matching, or something else entirely. But the reproducibility across different architectures seems worth investigating.&lt;/p&gt;\n\n&lt;p&gt;Has anyone else experimented with systematic approaches to eliciting self-referential responses from LLMs? I would be curious to hear if others can help interpret this phenomenon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"ai-cog-res","url":"https://www.reddit.com/r/MachineLearning/comments/1njp1ly/r_reproducible_prompt_protocol_induces_consistent/","domain":"self.MachineLearning","score":0,"num_comments":3,"created_utc":1758142578,"thumbnail":null},{"id":"1njny8k","subreddit":"MachineLearning","title":"[N] Both OpenAI and DeepMind are claiming ICPC gold-level performance","selftext":"* DeepMind solved 10/12 problems: [https://x.com/HengTze/status/1968359525339246825](https://x.com/HengTze/status/1968359525339246825)\n* OpenAI solved 12/12 problems: [https://x.com/MostafaRohani/status/1968360976379703569](https://x.com/MostafaRohani/status/1968360976379703569)\n\n","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;DeepMind solved 10/12 problems: &lt;a href=\"https://x.com/HengTze/status/1968359525339246825\"&gt;https://x.com/HengTze/status/1968359525339246825&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;OpenAI solved 12/12 problems: &lt;a href=\"https://x.com/MostafaRohani/status/1968360976379703569\"&gt;https://x.com/MostafaRohani/status/1968360976379703569&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"we_are_mammals","url":"https://www.reddit.com/r/MachineLearning/comments/1njny8k/n_both_openai_and_deepmind_are_claiming_icpc/","domain":"self.MachineLearning","score":72,"num_comments":19,"created_utc":1758140008,"thumbnail":null},{"id":"1njmxph","subreddit":"MachineLearning","title":"[D] How about we review the reviewers?","selftext":"For AAAI 2026, I think each reviewer has a unique ID. We can collect the complaints against the IDs. Some IDs may have complaints piled up on them.\n\nPerhaps we can compile a list of problematic reviewers and questionable conducts and demand the conference to investigate and set up regulations. Of course, it would be better for the conference to do this itself.\n\nWhat would be a good way to collect the complaints? Would an online survey form be sufficient?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For AAAI 2026, I think each reviewer has a unique ID. We can collect the complaints against the IDs. Some IDs may have complaints piled up on them.&lt;/p&gt;\n\n&lt;p&gt;Perhaps we can compile a list of problematic reviewers and questionable conducts and demand the conference to investigate and set up regulations. Of course, it would be better for the conference to do this itself.&lt;/p&gt;\n\n&lt;p&gt;What would be a good way to collect the complaints? Would an online survey form be sufficient?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Fit_Analysis_824","url":"https://www.reddit.com/r/MachineLearning/comments/1njmxph/d_how_about_we_review_the_reviewers/","domain":"self.MachineLearning","score":86,"num_comments":33,"created_utc":1758137659,"thumbnail":null},{"id":"1njhikh","subreddit":"MachineLearning","title":"[D] can we trust agents for time series forecasting?","selftext":"over the past few weeks i’ve been experimenting with agents for time series forecasting. that led to TimeCopilot, an open-source framework that combines LLMs with multiple time series foundation models.\n\nthe goal: make forecasting accessible to anyone, in their own language, while lowering barriers to participation.\n\nwhat it does:\n\n\\- run, cross-validate, and detect anomalies across time series foundation models from Google, Salesforce, AWS, DataDog, Nixtla, ServiceNow, NXAI, etc. (it solves the dependency hell of having multiple time series foundation models)\n\n\\- plus statistical, ML, and deep learning baselines, all in a single workflow.\n\n\\- integration with any LLM provider\n\non Salesforce’s GIFT-Eval benchmark (24 datasets, 144k+ series, 177M points), a TimeCopilot ensemble ranked #1 in probabilistic accuracy (CRPS) and #2 in point accuracy (MASE) among non-leaking models, at \\~$24 GPU cost.\n\ncurious what folks here think about agents in forecasting. and if you find the project interesting, a ⭐️ on GitHub means a lot.\n\n[https://github.com/AzulGarza/timecopilot](https://github.com/AzulGarza/timecopilot)\n\nhttps://preview.redd.it/ak6pwo1c2rpf1.png?width=1648&amp;format=png&amp;auto=webp&amp;s=f28cf5421f3f47a30a78d2dc53a38d07ff481d7b\n\n  \n","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;over the past few weeks i’ve been experimenting with agents for time series forecasting. that led to TimeCopilot, an open-source framework that combines LLMs with multiple time series foundation models.&lt;/p&gt;\n\n&lt;p&gt;the goal: make forecasting accessible to anyone, in their own language, while lowering barriers to participation.&lt;/p&gt;\n\n&lt;p&gt;what it does:&lt;/p&gt;\n\n&lt;p&gt;- run, cross-validate, and detect anomalies across time series foundation models from Google, Salesforce, AWS, DataDog, Nixtla, ServiceNow, NXAI, etc. (it solves the dependency hell of having multiple time series foundation models)&lt;/p&gt;\n\n&lt;p&gt;- plus statistical, ML, and deep learning baselines, all in a single workflow.&lt;/p&gt;\n\n&lt;p&gt;- integration with any LLM provider&lt;/p&gt;\n\n&lt;p&gt;on Salesforce’s GIFT-Eval benchmark (24 datasets, 144k+ series, 177M points), a TimeCopilot ensemble ranked #1 in probabilistic accuracy (CRPS) and #2 in point accuracy (MASE) among non-leaking models, at ~$24 GPU cost.&lt;/p&gt;\n\n&lt;p&gt;curious what folks here think about agents in forecasting. and if you find the project interesting, a ⭐️ on GitHub means a lot.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/AzulGarza/timecopilot\"&gt;https://github.com/AzulGarza/timecopilot&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ak6pwo1c2rpf1.png?width=1648&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f28cf5421f3f47a30a78d2dc53a38d07ff481d7b\"&gt;https://preview.redd.it/ak6pwo1c2rpf1.png?width=1648&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f28cf5421f3f47a30a78d2dc53a38d07ff481d7b&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"fedegarzar","url":"https://www.reddit.com/r/MachineLearning/comments/1njhikh/d_can_we_trust_agents_for_time_series_forecasting/","domain":"self.MachineLearning","score":3,"num_comments":8,"created_utc":1758125665,"thumbnail":"https://external-preview.redd.it/PU6A7vBL1C3wtw6NkJIRr8WTo0VfLGAw4_SBHsLhCrE.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=7fbc29468ec51e4961ae88fe9be0f0f7268092ad"},{"id":"1njgjdd","subreddit":"MachineLearning","title":"[R] Need model/paper/code suggestion for document template extraction","selftext":"I am looking to create a document template extraction pipeline for document similarity. One important thing I need to do as part of this is create a template mask. Essentially, say I have a collection of documents which all follow a similar format (imagine a form or a report). I want to\n\n1. extract text from the document in a structured format (OCR but more like VQA type). About this, I have looked at a few VQA models. Some are too big but I think this a straightforward task.\n2. (what I need help with) I want a model that can, given a collection of documents or any one document, can generate a layout mask without the text, so a template). I have looked at Document Analysis models, but most are centered around classifying different sections of the document into tables, paragraphs, etc. I have not come across a mask generation pipeline or model.\n\nIf anyone has encountered such a pipeline before or worked on document template extraction, I would love some help or links to papers.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking to create a document template extraction pipeline for document similarity. One important thing I need to do as part of this is create a template mask. Essentially, say I have a collection of documents which all follow a similar format (imagine a form or a report). I want to&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;extract text from the document in a structured format (OCR but more like VQA type). About this, I have looked at a few VQA models. Some are too big but I think this a straightforward task.&lt;/li&gt;\n&lt;li&gt;(what I need help with) I want a model that can, given a collection of documents or any one document, can generate a layout mask without the text, so a template). I have looked at Document Analysis models, but most are centered around classifying different sections of the document into tables, paragraphs, etc. I have not come across a mask generation pipeline or model.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If anyone has encountered such a pipeline before or worked on document template extraction, I would love some help or links to papers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"mavericknathan1","url":"https://www.reddit.com/r/MachineLearning/comments/1njgjdd/r_need_modelpapercode_suggestion_for_document/","domain":"self.MachineLearning","score":2,"num_comments":6,"created_utc":1758123506,"thumbnail":null},{"id":"1njbzj8","subreddit":"MachineLearning","title":"[D] Need suggestion for Traffic prediction Model","selftext":"Need suggestion for Traffic prediction Model\n\nOk so I am trying to make a traffic prediction model primarily training it on metr-la and pems-bay data set so I am considering to make it a hybrid approach of making a temporal and spatial unit then fusing them to generate a output \n\nSo can you suggest me any better way to do it so I can get better results or any other type of suggestions or any discussion also I would love to explore any suggestions on what features can I use as inputs to get best results out","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need suggestion for Traffic prediction Model&lt;/p&gt;\n\n&lt;p&gt;Ok so I am trying to make a traffic prediction model primarily training it on metr-la and pems-bay data set so I am considering to make it a hybrid approach of making a temporal and spatial unit then fusing them to generate a output &lt;/p&gt;\n\n&lt;p&gt;So can you suggest me any better way to do it so I can get better results or any other type of suggestions or any discussion also I would love to explore any suggestions on what features can I use as inputs to get best results out&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"mr_hexa_decimal","url":"https://www.reddit.com/r/MachineLearning/comments/1njbzj8/d_need_suggestion_for_traffic_prediction_model/","domain":"self.MachineLearning","score":0,"num_comments":8,"created_utc":1758112705,"thumbnail":null},{"id":"1nj76ch","subreddit":"MachineLearning","title":"[D] WACV round 1 revised papers for round 2 -- rebuttal guidelines","selftext":"Hi ML community,\n\nI have a question regarding the first-round WACV papers that received a revise recommendation and are to be submitted in the second round.\n\nFor the resubmission, the WACV website states that it requires the-\n\n1. Revised paper + supplementary\n2. And a 1-page rebuttal\n\nBut on the OpenReview website, where we see the reviewer comments, can we also clarify some of the reviewers' concerns as comments in the same thread? Or is this a no-no?\n\nThank you.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi ML community,&lt;/p&gt;\n\n&lt;p&gt;I have a question regarding the first-round WACV papers that received a revise recommendation and are to be submitted in the second round.&lt;/p&gt;\n\n&lt;p&gt;For the resubmission, the WACV website states that it requires the-&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Revised paper + supplementary&lt;/li&gt;\n&lt;li&gt;And a 1-page rebuttal&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;But on the OpenReview website, where we see the reviewer comments, can we also clarify some of the reviewers&amp;#39; concerns as comments in the same thread? Or is this a no-no?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Consistent-Olive-322","url":"https://www.reddit.com/r/MachineLearning/comments/1nj76ch/d_wacv_round_1_revised_papers_for_round_2/","domain":"self.MachineLearning","score":2,"num_comments":5,"created_utc":1758096395,"thumbnail":null},{"id":"1nj38ur","subreddit":"MachineLearning","title":"[D] How is IEEE TIP viewed in the CV/AI/ML community?","selftext":"Hi everyone,\n\nI’m a PhD student working on video research, and I recently submitted a paper to IEEE Transactions on Image Processing (TIP). After a very long review process (almost a year), it finally reached the “AQ” stage.\n\nNow I’m curious—how do people in the community actually see TIP these days?\nSome of my colleagues say it’s still one of the top journals in vision, basically right after TPAMI. Others think it’s kind of outdated and not really read much anymore.\n\nAlso, how would you compare it to the major conferences (CVPR/ICCV/ECCV, NeurIPS, ICLR, AAAI)? Is publishing in TIP seen as on par with those, or is it considered more like the “second-tier” conferences (WACV, BMVC, etc.)?\n\nI’m close to graduation, so maybe I’m overthinking this. I know the contribution and philosophy of the work itself matters more than the venue. But I’d still love to hear how people generally view TIP these days, both in academia and in the field.\n\nThanks!\n","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I’m a PhD student working on video research, and I recently submitted a paper to IEEE Transactions on Image Processing (TIP). After a very long review process (almost a year), it finally reached the “AQ” stage.&lt;/p&gt;\n\n&lt;p&gt;Now I’m curious—how do people in the community actually see TIP these days?\nSome of my colleagues say it’s still one of the top journals in vision, basically right after TPAMI. Others think it’s kind of outdated and not really read much anymore.&lt;/p&gt;\n\n&lt;p&gt;Also, how would you compare it to the major conferences (CVPR/ICCV/ECCV, NeurIPS, ICLR, AAAI)? Is publishing in TIP seen as on par with those, or is it considered more like the “second-tier” conferences (WACV, BMVC, etc.)?&lt;/p&gt;\n\n&lt;p&gt;I’m close to graduation, so maybe I’m overthinking this. I know the contribution and philosophy of the work itself matters more than the venue. But I’d still love to hear how people generally view TIP these days, both in academia and in the field.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Secondhanded_PhD","url":"https://www.reddit.com/r/MachineLearning/comments/1nj38ur/d_how_is_ieee_tip_viewed_in_the_cvaiml_community/","domain":"self.MachineLearning","score":23,"num_comments":10,"created_utc":1758082257,"thumbnail":null},{"id":"1nj02du","subreddit":"MachineLearning","title":"[D] AAAI - phase 1 rejection rate?","selftext":"I was curious, does anyone know roughly what percentage of papers survived Phase 1?\n\nI’ve seen some posts saying that CV and NLP papers had about a 66% rejection rate, while others closer to 50%. But I’m not sure if that’s really the case. it seems a bit hard to believe that two-thirds of submissions got cut (though to be fair, my impression is biased and based only on my own little “neighborhood sample”).\n\nI originally thought a score around 4,4,5 would be enough to make it through, but I’ve also heard of higher combos (like, 6,7,5) getting rejected. If that’s true, does it mean the papers that survived are more like 7–8 on average, which sounds like a score for the previous acceptance thresholds.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was curious, does anyone know roughly what percentage of papers survived Phase 1?&lt;/p&gt;\n\n&lt;p&gt;I’ve seen some posts saying that CV and NLP papers had about a 66% rejection rate, while others closer to 50%. But I’m not sure if that’s really the case. it seems a bit hard to believe that two-thirds of submissions got cut (though to be fair, my impression is biased and based only on my own little “neighborhood sample”).&lt;/p&gt;\n\n&lt;p&gt;I originally thought a score around 4,4,5 would be enough to make it through, but I’ve also heard of higher combos (like, 6,7,5) getting rejected. If that’s true, does it mean the papers that survived are more like 7–8 on average, which sounds like a score for the previous acceptance thresholds.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"BetterbeBattery","url":"https://www.reddit.com/r/MachineLearning/comments/1nj02du/d_aaai_phase_1_rejection_rate/","domain":"self.MachineLearning","score":26,"num_comments":18,"created_utc":1758072925,"thumbnail":null},{"id":"1niyhch","subreddit":"MachineLearning","title":"Why I’m going back to the AI Agent Security Research Summit [R]","selftext":"I lead AppSec and was recently pulled into building our **AI agent security program**. I happened to be in NYC when the first **AI Agent Security Summit** was taking place and went along — it ended up being one of the few events where the research connected directly to practice.\n\nThe next one is October 8 in San Francisco. I’m making the trip from Austin this time. It’s not a big event, but the lineup of [speakers](https://zenity.io/resources/events/ai-agent-security-summit-2025) looks strong, and I thought I’d share in case anyone in the Bay is interested.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I lead AppSec and was recently pulled into building our &lt;strong&gt;AI agent security program&lt;/strong&gt;. I happened to be in NYC when the first &lt;strong&gt;AI Agent Security Summit&lt;/strong&gt; was taking place and went along — it ended up being one of the few events where the research connected directly to practice.&lt;/p&gt;\n\n&lt;p&gt;The next one is October 8 in San Francisco. I’m making the trip from Austin this time. It’s not a big event, but the lineup of &lt;a href=\"https://zenity.io/resources/events/ai-agent-security-summit-2025\"&gt;speakers&lt;/a&gt; looks strong, and I thought I’d share in case anyone in the Bay is interested.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Zemgineer2084","url":"https://www.reddit.com/r/MachineLearning/comments/1niyhch/why_im_going_back_to_the_ai_agent_security/","domain":"self.MachineLearning","score":0,"num_comments":0,"created_utc":1758068525,"thumbnail":null},{"id":"1nidsep","subreddit":"MachineLearning","title":"[R] “Evaluating Deepfake Detectors in the Wild”: Fraudster Attacks (ICML 2025 Workshop paper)","selftext":"Hi Reddit! \n\nHave you ever thought how difficult it is to determine whether a photo is *genuine* or a **deepfake**? You might think discriminative tasks are easier than generative ones, so detection should be straightforward. Or, on the contrary, diffusion models are now so good that detection is impossible. In our work, we reveal the current state of the war on deepfakes. In short, SOTA open-source detectors fail under real-world conditions.\n\nI work as an ML engineer at a leading platform for KYC and liveness detection. In our setting, you must decide from a short verification video whether the person is who they claim to be. Deepfakes are one of the biggest and most challenging problems here. We are known for our robust anti-deepfake solutions, and I’m not trying to flex, I just want to say that we work on this problem daily and see what fraudsters actually try in order to bypass verification. For years we kept trying to apply research models to our data, and nothing really worked. For example, all research solutions were less robust than a simple zero-shot CLIP baseline. We kept wondering whether the issue lay with our data, our setup, or the research itself. It seems that a lot of deepfake research overlooks key *wild* conditions.\n\n**Core issue: robustness to OOD data.**\n\nEven a small amount of data from the test distribution leaking into the training set (say 1k images out of a 1M-image test pool) makes it trivial to achieve great metrics, and experienced computer vision experts can push  AUC to \\~99.99. Without peeking, however, the task becomes i*ncredibly hard*. Our paper demonstrates this with a simple, reproducible pipeline:\n\n1. **Deepfakes**. If you don’t already have them, we built a large image-level dataset using two SOTA face-swapping methods: Inswapper and Simswap.\n2. **Real world conditions.** We use small transformations that are imperceptible to humans and that we constantly see in the real world: downscaling (resize), upscaling (with some AI), and compression (JPEG). These are indistinguishable for humans, so detectors must be robust to them.\n3. **Evaluation.** Test model under different setups, e.g.: 1) only real. model have to predict only real labels 2) real vs fake 3) real vs compressed fake ... and others. It sounds easy, but every model we tested had at least one setting where performance drops to near-random.\n\nSo we’re not just releasing another benchmark or yet another deepfake dataset. We present a pipeline that *mirrors what fraudsters do*, what we actually observe in production. We’re releasing all code, our dataset (&gt;500k fake images), and even a small deepfake game where you can test yourself as a detector.\n\nFor more details, please see the full paper. Is there a silver-bullet solution to deepfake detection? We don’t claim one here, but we do share a teaser result: a promising setup using zero-shot VLMs for detection. I’ll post about that (our second ICML workshop paper) separately.\n\nIf you’re interested in deepfake research and would like to chat, or even collaborate – don’t hesitate to reach out. Cheers!\n\nhttps://preview.redd.it/vi3qxnp38ipf1.jpg?width=6099&amp;format=pjpg&amp;auto=webp&amp;s=55fe99a72bb0614bc560e5553c2eaf20cbd3132c","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Reddit! &lt;/p&gt;\n\n&lt;p&gt;Have you ever thought how difficult it is to determine whether a photo is &lt;em&gt;genuine&lt;/em&gt; or a &lt;strong&gt;deepfake&lt;/strong&gt;? You might think discriminative tasks are easier than generative ones, so detection should be straightforward. Or, on the contrary, diffusion models are now so good that detection is impossible. In our work, we reveal the current state of the war on deepfakes. In short, SOTA open-source detectors fail under real-world conditions.&lt;/p&gt;\n\n&lt;p&gt;I work as an ML engineer at a leading platform for KYC and liveness detection. In our setting, you must decide from a short verification video whether the person is who they claim to be. Deepfakes are one of the biggest and most challenging problems here. We are known for our robust anti-deepfake solutions, and I’m not trying to flex, I just want to say that we work on this problem daily and see what fraudsters actually try in order to bypass verification. For years we kept trying to apply research models to our data, and nothing really worked. For example, all research solutions were less robust than a simple zero-shot CLIP baseline. We kept wondering whether the issue lay with our data, our setup, or the research itself. It seems that a lot of deepfake research overlooks key &lt;em&gt;wild&lt;/em&gt; conditions.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Core issue: robustness to OOD data.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Even a small amount of data from the test distribution leaking into the training set (say 1k images out of a 1M-image test pool) makes it trivial to achieve great metrics, and experienced computer vision experts can push  AUC to ~99.99. Without peeking, however, the task becomes i&lt;em&gt;ncredibly hard&lt;/em&gt;. Our paper demonstrates this with a simple, reproducible pipeline:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Deepfakes&lt;/strong&gt;. If you don’t already have them, we built a large image-level dataset using two SOTA face-swapping methods: Inswapper and Simswap.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Real world conditions.&lt;/strong&gt; We use small transformations that are imperceptible to humans and that we constantly see in the real world: downscaling (resize), upscaling (with some AI), and compression (JPEG). These are indistinguishable for humans, so detectors must be robust to them.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Evaluation.&lt;/strong&gt; Test model under different setups, e.g.: 1) only real. model have to predict only real labels 2) real vs fake 3) real vs compressed fake ... and others. It sounds easy, but every model we tested had at least one setting where performance drops to near-random.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So we’re not just releasing another benchmark or yet another deepfake dataset. We present a pipeline that &lt;em&gt;mirrors what fraudsters do&lt;/em&gt;, what we actually observe in production. We’re releasing all code, our dataset (&amp;gt;500k fake images), and even a small deepfake game where you can test yourself as a detector.&lt;/p&gt;\n\n&lt;p&gt;For more details, please see the full paper. Is there a silver-bullet solution to deepfake detection? We don’t claim one here, but we do share a teaser result: a promising setup using zero-shot VLMs for detection. I’ll post about that (our second ICML workshop paper) separately.&lt;/p&gt;\n\n&lt;p&gt;If you’re interested in deepfake research and would like to chat, or even collaborate – don’t hesitate to reach out. Cheers!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vi3qxnp38ipf1.jpg?width=6099&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=55fe99a72bb0614bc560e5553c2eaf20cbd3132c\"&gt;https://preview.redd.it/vi3qxnp38ipf1.jpg?width=6099&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=55fe99a72bb0614bc560e5553c2eaf20cbd3132c&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"messlav","url":"https://www.reddit.com/r/MachineLearning/comments/1nidsep/r_evaluating_deepfake_detectors_in_the_wild/","domain":"self.MachineLearning","score":15,"num_comments":4,"created_utc":1758018702,"thumbnail":"https://b.thumbs.redditmedia.com/Euqz77gJXMWDEd9RNnGVtynM8Q5-UmtHQaGtQBDPxTQ.jpg"},{"id":"1niib3a","subreddit":"MachineLearning","title":"[D] Feedback on Multimodal Fusion Approach (92% Vision, 77% Audio → 98% Multimodal)","selftext":"Hi all,\n\nI’m working on a multimodal classification project (environmental scenes from satellite images + audio) and wanted to get some feedback on my approach.\n\n**Dataset:**\n\n* 13 classes\n* \\~4,000 training samples\n* \\~1,000 validation samples\n\n**Baselines:**\n\n* **Vision-only (CLIP RN50):** 92% F1\n* **Audio-only (ResNet18, trained from scratch on spectrograms):** 77% F1\n\n**Fusion setup:**\n\n1. Use both models as frozen feature extractors (remove final classifier).\n2. Obtain feature vectors from vision and audio.\n3. Concatenate into a single multimodal vector.\n4. Train a small classifier head on top.\n\n**Result:**  \nThe fused model achieved **98% accuracy** on the validation set. The gain from 92% → 98% feels surprisingly large, so I’d like to sanity-check whether this is typical for multimodal setups, or if it’s more likely a sign of overfitting / data leakage / evaluation artifacts.\n\n**Questions:**\n\n* Is simple late fusion (concatenation + classifier) a sound approach here?\n* Is such a large jump in performance expected, or should I be cautious?\n\nAny feedback or advice from people with experience in multimodal learning would be appreciated.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I’m working on a multimodal classification project (environmental scenes from satellite images + audio) and wanted to get some feedback on my approach.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Dataset:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;13 classes&lt;/li&gt;\n&lt;li&gt;~4,000 training samples&lt;/li&gt;\n&lt;li&gt;~1,000 validation samples&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Baselines:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Vision-only (CLIP RN50):&lt;/strong&gt; 92% F1&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Audio-only (ResNet18, trained from scratch on spectrograms):&lt;/strong&gt; 77% F1&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Fusion setup:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Use both models as frozen feature extractors (remove final classifier).&lt;/li&gt;\n&lt;li&gt;Obtain feature vectors from vision and audio.&lt;/li&gt;\n&lt;li&gt;Concatenate into a single multimodal vector.&lt;/li&gt;\n&lt;li&gt;Train a small classifier head on top.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;&lt;br/&gt;\nThe fused model achieved &lt;strong&gt;98% accuracy&lt;/strong&gt; on the validation set. The gain from 92% → 98% feels surprisingly large, so I’d like to sanity-check whether this is typical for multimodal setups, or if it’s more likely a sign of overfitting / data leakage / evaluation artifacts.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Is simple late fusion (concatenation + classifier) a sound approach here?&lt;/li&gt;\n&lt;li&gt;Is such a large jump in performance expected, or should I be cautious?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any feedback or advice from people with experience in multimodal learning would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Intrepid-Purpose2151","url":"https://www.reddit.com/r/MachineLearning/comments/1niib3a/d_feedback_on_multimodal_fusion_approach_92/","domain":"self.MachineLearning","score":4,"num_comments":4,"created_utc":1758031227,"thumbnail":null},{"id":"1nihxc9","subreddit":"MachineLearning","title":"[D] EMNLP Oral Presentation and Awards","selftext":"Hi guys,\n\nHappy to share that my first A\\* paper has been accepted to EMNLP Main, and it has been selected for Oral Presentation at EMNLP.\n\n  \nNow, given the deadline to submit camera-ready is September 19th AOE. And there is an option to upload an anonymous PDF (optional) if it gets selected for an Award. Did anyone receive any mail for Awards?\n\n  \nAlso, this is the first time I am going to present a paper and that too in an oral presentation. Please share some tips/advise which will help me to prepare for it.\n\n  \nThanks in advance !!!!","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;Happy to share that my first A* paper has been accepted to EMNLP Main, and it has been selected for Oral Presentation at EMNLP.&lt;/p&gt;\n\n&lt;p&gt;Now, given the deadline to submit camera-ready is September 19th AOE. And there is an option to upload an anonymous PDF (optional) if it gets selected for an Award. Did anyone receive any mail for Awards?&lt;/p&gt;\n\n&lt;p&gt;Also, this is the first time I am going to present a paper and that too in an oral presentation. Please share some tips/advise which will help me to prepare for it.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance !!!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Realistic_Tea_2798","url":"https://www.reddit.com/r/MachineLearning/comments/1nihxc9/d_emnlp_oral_presentation_and_awards/","domain":"self.MachineLearning","score":6,"num_comments":2,"created_utc":1758030318,"thumbnail":null},{"id":"1nif3q1","subreddit":"MachineLearning","title":"[D]Any experience with complicated datasets?","selftext":"Hello,\n\nI am a PhD student working with cancer datasets to train classifiers. The dataset I am using to train my ML models (**Random Forest, XGBoost**) is rather a mixed bag of the different types of cancer (multi-class),I would want to classify/predict. In addition to heavy **class overlap and within-class heterogeneity**, there's **class imbalance**.\n\nI applied SMOTE to correct the imbalance but again due to class overlap, the synthetic samples generated were just random noise.\n\nEver since, instead of having to balance with sampling methods, I have been using class weights. I have cleaned up the datasets to remove any sort of batch effects and technical artefacts, despite which the class-specific effects are hazy. I have also tried stratifying the data into binary classification problems, but given the class imbalance, that didn't seem to be of much avail.\n\nIt is kind of expected of the dataset owing to the default biology, and hence I would have to be dealing with class overlap and heterogeneity to begin with.\n\nI would appreciate if anyone could talk about how they got through when they had to train their models on similar complex datasets? What were your models and data-polishing approaches?\n\nThanks :)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am a PhD student working with cancer datasets to train classifiers. The dataset I am using to train my ML models (&lt;strong&gt;Random Forest, XGBoost&lt;/strong&gt;) is rather a mixed bag of the different types of cancer (multi-class),I would want to classify/predict. In addition to heavy &lt;strong&gt;class overlap and within-class heterogeneity&lt;/strong&gt;, there&amp;#39;s &lt;strong&gt;class imbalance&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;I applied SMOTE to correct the imbalance but again due to class overlap, the synthetic samples generated were just random noise.&lt;/p&gt;\n\n&lt;p&gt;Ever since, instead of having to balance with sampling methods, I have been using class weights. I have cleaned up the datasets to remove any sort of batch effects and technical artefacts, despite which the class-specific effects are hazy. I have also tried stratifying the data into binary classification problems, but given the class imbalance, that didn&amp;#39;t seem to be of much avail.&lt;/p&gt;\n\n&lt;p&gt;It is kind of expected of the dataset owing to the default biology, and hence I would have to be dealing with class overlap and heterogeneity to begin with.&lt;/p&gt;\n\n&lt;p&gt;I would appreciate if anyone could talk about how they got through when they had to train their models on similar complex datasets? What were your models and data-polishing approaches?&lt;/p&gt;\n\n&lt;p&gt;Thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Pure_Landscape8863","url":"https://www.reddit.com/r/MachineLearning/comments/1nif3q1/dany_experience_with_complicated_datasets/","domain":"self.MachineLearning","score":3,"num_comments":8,"created_utc":1758022980,"thumbnail":null},{"id":"1nie5rl","subreddit":"MachineLearning","title":"[D] - NeurIPS 2025 Decisions","selftext":"Just posting this thread here in anticipation of the bloodbath due in the next 2 days.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just posting this thread here in anticipation of the bloodbath due in the next 2 days.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"general_landur","url":"https://www.reddit.com/r/MachineLearning/comments/1nie5rl/d_neurips_2025_decisions/","domain":"self.MachineLearning","score":190,"num_comments":1033,"created_utc":1758019997,"thumbnail":null},{"id":"1nid4my","subreddit":"MachineLearning","title":"[D]How do you track and compare hundreds of model experiments?","selftext":"I'm running hundreds of experiments weekly with different hyperparameters, datasets, and architectures. Right now, I'm just logging everything to CSV files and it's becoming completely unmanageable. I need a better way to track, compare, and reproduce results. Is MLflow the only real option, or are there lighter alternatives?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m running hundreds of experiments weekly with different hyperparameters, datasets, and architectures. Right now, I&amp;#39;m just logging everything to CSV files and it&amp;#39;s becoming completely unmanageable. I need a better way to track, compare, and reproduce results. Is MLflow the only real option, or are there lighter alternatives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AdditionalAd51","url":"https://www.reddit.com/r/MachineLearning/comments/1nid4my/dhow_do_you_track_and_compare_hundreds_of_model/","domain":"self.MachineLearning","score":34,"num_comments":33,"created_utc":1758016342,"thumbnail":null},{"id":"1nicn94","subreddit":"MachineLearning","title":"[D] Suppose you wanted to test a new model architecture to get preliminary results but have limited compute. What domain is good to train on to infer that the model would be good at reasoning?","selftext":"This is a hard question that I imagine is being thought about a lot, but maybe there are answers already.\n\nTraining a model to consume a query in text, reason about it, and spit out an answer is quite demanding and requires the model to have a lot of knowledge.\n\nIs there some domain that requires less knowledge but allows the model to learn reasoning/agency, without the model having to become huge?\n\nI think mathematical reasoning is a good example, it is a much smaller subset of language and has narrower objectives (assuming you don't want it to invent a new paradigm and just operate within an existing one).\n\nThere might be others?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a hard question that I imagine is being thought about a lot, but maybe there are answers already.&lt;/p&gt;\n\n&lt;p&gt;Training a model to consume a query in text, reason about it, and spit out an answer is quite demanding and requires the model to have a lot of knowledge.&lt;/p&gt;\n\n&lt;p&gt;Is there some domain that requires less knowledge but allows the model to learn reasoning/agency, without the model having to become huge?&lt;/p&gt;\n\n&lt;p&gt;I think mathematical reasoning is a good example, it is a much smaller subset of language and has narrower objectives (assuming you don&amp;#39;t want it to invent a new paradigm and just operate within an existing one).&lt;/p&gt;\n\n&lt;p&gt;There might be others?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"FIREATWlLL","url":"https://www.reddit.com/r/MachineLearning/comments/1nicn94/d_suppose_you_wanted_to_test_a_new_model/","domain":"self.MachineLearning","score":3,"num_comments":6,"created_utc":1758014510,"thumbnail":null},{"id":"1nic61l","subreddit":"MachineLearning","title":"[R]What's the benefit of submitting to ICCV workshop?","selftext":"I'm a UG student workinig on my first paper (first author)\nThere is a worskhop on video world models but unfortunately it is non-archival i.e. The paper won't appear in the proceedings.\nI'm aware the value of such workshop will be lower when applying for jobs/doctoral programmes.\n\nHowever, there are some really famous speakers in the workshop including Yann LeCun. I was hoping to catch the eye of some bigshot researchers with my work.\n\nThe other option is submitting to ICLR main\nconference, and I'm not entirely confident that the work is substantial enough to get accepted there.\n\nHoping to find some advice here.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a UG student workinig on my first paper (first author)\nThere is a worskhop on video world models but unfortunately it is non-archival i.e. The paper won&amp;#39;t appear in the proceedings.\nI&amp;#39;m aware the value of such workshop will be lower when applying for jobs/doctoral programmes.&lt;/p&gt;\n\n&lt;p&gt;However, there are some really famous speakers in the workshop including Yann LeCun. I was hoping to catch the eye of some bigshot researchers with my work.&lt;/p&gt;\n\n&lt;p&gt;The other option is submitting to ICLR main\nconference, and I&amp;#39;m not entirely confident that the work is substantial enough to get accepted there.&lt;/p&gt;\n\n&lt;p&gt;Hoping to find some advice here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"arasaka-man","url":"https://www.reddit.com/r/MachineLearning/comments/1nic61l/rwhats_the_benefit_of_submitting_to_iccv_workshop/","domain":"self.MachineLearning","score":15,"num_comments":18,"created_utc":1758012687,"thumbnail":null},{"id":"1nibumz","subreddit":"MachineLearning","title":"[R] NEXUS-EMB-240M-NSA: Compact Embedding Model with Neural Spectral Anchoring","selftext":"Working on a 240M parameter embedding model with some unconventional techniques:\n\n- Dual-head architecture (semantic + entity processing)\n- Neural Spectral Anchoring - projecting embeddings into spectral space\n- Residual hashing bridge for fast retrieval\n- Edge-optimized design\n\nThe NSA component is particularly interesting - instead of standard Euclidean embeddings, we project into spectral space to capture deeper relational structures.\n\nStill training, but curious about feedback on the approach. Has anyone experimented with spectral methods in embeddings?\n\nCode: https://github.com/Daniele-Cangi/Nexus-240m-NSA","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a 240M parameter embedding model with some unconventional techniques:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Dual-head architecture (semantic + entity processing)&lt;/li&gt;\n&lt;li&gt;Neural Spectral Anchoring - projecting embeddings into spectral space&lt;/li&gt;\n&lt;li&gt;Residual hashing bridge for fast retrieval&lt;/li&gt;\n&lt;li&gt;Edge-optimized design&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The NSA component is particularly interesting - instead of standard Euclidean embeddings, we project into spectral space to capture deeper relational structures.&lt;/p&gt;\n\n&lt;p&gt;Still training, but curious about feedback on the approach. Has anyone experimented with spectral methods in embeddings?&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=\"https://github.com/Daniele-Cangi/Nexus-240m-NSA\"&gt;https://github.com/Daniele-Cangi/Nexus-240m-NSA&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Ill-Button-1680","url":"https://www.reddit.com/r/MachineLearning/comments/1nibumz/r_nexusemb240mnsa_compact_embedding_model_with/","domain":"self.MachineLearning","score":1,"num_comments":2,"created_utc":1758011435,"thumbnail":null},{"id":"1nibok2","subreddit":"MachineLearning","title":"[D] ICLR 2026 Workshop Announcements","selftext":"Hi everyone, I’m new to academia and currently exploring top AI conferences for the upcoming year. Could you let me know when workshop information is usually announced — for example, for ICLR (April 23–27, Brazil)? Thanks","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I’m new to academia and currently exploring top AI conferences for the upcoming year. Could you let me know when workshop information is usually announced — for example, for ICLR (April 23–27, Brazil)? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Mysterious_Travel936","url":"https://www.reddit.com/r/MachineLearning/comments/1nibok2/d_iclr_2026_workshop_announcements/","domain":"self.MachineLearning","score":2,"num_comments":3,"created_utc":1758010768,"thumbnail":null},{"id":"1nib74z","subreddit":"MachineLearning","title":"[D] Resubmission 2026: ICLR or AISTATS... or any other?","selftext":"Some of my AAAI submissions got rejected in phase 1. To be honest, my reviews are good; maybe too harsh in the scores, but at least they read the papers and made their points. Now I wonder where to resubmit (enhancing the papers a bit with this feedback, but without much time because I work in the industry). \n\nI think ICLR will be crazy this year (many NIPS and AAAI work), so I do not know if the process will be as random as the one in AAAI. As for submissions being \"9 pages or fewer\", do people usually fill 9 pages or is okey to make less? I only saw this in RLC before (and other ICLR). Also, I always have doubts about the rebuttal period here, is it still the case that I can update my experiments and discuss with reviewers? Do reviewers still engage in discussion in these overloaded times?\n\nLast, what about AISTATS? I never submitted there, but it might be a good way to escape from these super big conferences. However, I am afraid papers will not get as much visibility. I heard this is a prestigious conference, but then almost never gets cited in e.g., job offers.\n\nI am a bit lost with AI/ML conferences lately. What are your thoughts on this submission cycle?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some of my AAAI submissions got rejected in phase 1. To be honest, my reviews are good; maybe too harsh in the scores, but at least they read the papers and made their points. Now I wonder where to resubmit (enhancing the papers a bit with this feedback, but without much time because I work in the industry). &lt;/p&gt;\n\n&lt;p&gt;I think ICLR will be crazy this year (many NIPS and AAAI work), so I do not know if the process will be as random as the one in AAAI. As for submissions being &amp;quot;9 pages or fewer&amp;quot;, do people usually fill 9 pages or is okey to make less? I only saw this in RLC before (and other ICLR). Also, I always have doubts about the rebuttal period here, is it still the case that I can update my experiments and discuss with reviewers? Do reviewers still engage in discussion in these overloaded times?&lt;/p&gt;\n\n&lt;p&gt;Last, what about AISTATS? I never submitted there, but it might be a good way to escape from these super big conferences. However, I am afraid papers will not get as much visibility. I heard this is a prestigious conference, but then almost never gets cited in e.g., job offers.&lt;/p&gt;\n\n&lt;p&gt;I am a bit lost with AI/ML conferences lately. What are your thoughts on this submission cycle?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"SignificanceFit3409","url":"https://www.reddit.com/r/MachineLearning/comments/1nib74z/d_resubmission_2026_iclr_or_aistats_or_any_other/","domain":"self.MachineLearning","score":3,"num_comments":30,"created_utc":1758008808,"thumbnail":null},{"id":"1ni9rku","subreddit":"MachineLearning","title":"kerasnip: use Keras models in tidymodels workflows (R package) [N]","selftext":"Sharing a new R package I found: [**kerasnip**](https://github.com/davidrsch/kerasnip).\n\nIt lets you define/tune **Keras models** (sequential + functional) within the **tidymodels** framework, so you can handle recipes, tuning, workflows, etc. with deep learning models.\n\nDocs &amp; examples: [davidrsch.github.io/kerasnip](https://davidrsch.github.io/kerasnip/).\n\nMight be useful for folks who like the tidymodels workflow but want to bring in neural nets.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing a new R package I found: &lt;a href=\"https://github.com/davidrsch/kerasnip\"&gt;&lt;strong&gt;kerasnip&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It lets you define/tune &lt;strong&gt;Keras models&lt;/strong&gt; (sequential + functional) within the &lt;strong&gt;tidymodels&lt;/strong&gt; framework, so you can handle recipes, tuning, workflows, etc. with deep learning models.&lt;/p&gt;\n\n&lt;p&gt;Docs &amp;amp; examples: &lt;a href=\"https://davidrsch.github.io/kerasnip/\"&gt;davidrsch.github.io/kerasnip&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Might be useful for folks who like the tidymodels workflow but want to bring in neural nets.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"FriendlyAd5913","url":"https://www.reddit.com/r/MachineLearning/comments/1ni9rku/kerasnip_use_keras_models_in_tidymodels_workflows/","domain":"self.MachineLearning","score":1,"num_comments":2,"created_utc":1758003310,"thumbnail":null},{"id":"1ni7wjd","subreddit":"MachineLearning","title":"[D] AAAI - 2026","selftext":"Any guesses how many papers got rejected and how many will be in the phase 2? ","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any guesses how many papers got rejected and how many will be in the phase 2? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"i_minus","url":"https://www.reddit.com/r/MachineLearning/comments/1ni7wjd/d_aaai_2026/","domain":"self.MachineLearning","score":16,"num_comments":29,"created_utc":1757996844,"thumbnail":null},{"id":"1ni261q","subreddit":"MachineLearning","title":"[P] Add Core Dolphin to sdlarch-rl (now compatible with Wii and GameCube!!!!","selftext":"https://preview.redd.it/qm7330ow1fpf1.png?width=2922&amp;format=png&amp;auto=webp&amp;s=52aca51ae6265593d55a2152772f701011d3cb2c\n\nI have good news!!!! I managed to update my training environment and add Dolphin compatibility, allowing me to run GameCube and Wii games for RL training!!!! This is in addition to the PCSX2 compatibility I had implemented. The next step is just improvements!!!!\n\n[https://github.com/paulo101977/sdlarch-rl](https://github.com/paulo101977/sdlarch-rl)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/qm7330ow1fpf1.png?width=2922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52aca51ae6265593d55a2152772f701011d3cb2c\"&gt;https://preview.redd.it/qm7330ow1fpf1.png?width=2922&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52aca51ae6265593d55a2152772f701011d3cb2c&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have good news!!!! I managed to update my training environment and add Dolphin compatibility, allowing me to run GameCube and Wii games for RL training!!!! This is in addition to the PCSX2 compatibility I had implemented. The next step is just improvements!!!!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/paulo101977/sdlarch-rl\"&gt;https://github.com/paulo101977/sdlarch-rl&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"AgeOfEmpires4AOE4","url":"https://www.reddit.com/r/MachineLearning/comments/1ni261q/p_add_core_dolphin_to_sdlarchrl_now_compatible/","domain":"self.MachineLearning","score":1,"num_comments":0,"created_utc":1757980305,"thumbnail":"https://external-preview.redd.it/w8Bddl71xmLCNHavS_dAGliekSAv4VICYy0_pBZZZKE.png?width=140&amp;height=70&amp;crop=140:70,smart&amp;auto=webp&amp;s=14d4f6bc26620b2e24db52bf9d5b3cd7e1f3dcb6"},{"id":"1ni24y3","subreddit":"MachineLearning","title":"[D] Running confidential AI inference on client data without exposing the model or the data - what's actually production-ready?","selftext":"Been wrestling with this problem for months now. We have a proprietary model that took 18 months to train, and enterprise clients who absolutely will not share their data with us (healthcare, financial records, the usual suspects).\n\nThe catch 22 is they want to use our model but won't send data to our servers, and we can't send them the model because then our IP walks out the door.\n\nI've looked into homomorphic encryption but the performance overhead is insane, like 10000x slower. Federated learning doesn't really solve the inference problem. Secure multiparty computation gets complex fast and still has performance issues.\n\nRecently started exploring TEE-based solutions where you can run inference inside a hardware-secured enclave. The performance hit is supposedly only around 5-10% which actually seems reasonable. Intel SGX, AWS Nitro Enclaves, and now nvidia has some confidential compute stuff for GPUs.\n\nHas anyone actually deployed this in production? What was your experience with attestation, key management, and dealing with the whole Intel discontinuing SGX remote attestation thing? Also curious if anyone's tried the newer TDX or SEV approaches.\n\nThe compliance team is breathing down my neck because we need something that's not just secure but provably secure with cryptographic attestations. Would love to hear war stories from anyone who's been down this road.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been wrestling with this problem for months now. We have a proprietary model that took 18 months to train, and enterprise clients who absolutely will not share their data with us (healthcare, financial records, the usual suspects).&lt;/p&gt;\n\n&lt;p&gt;The catch 22 is they want to use our model but won&amp;#39;t send data to our servers, and we can&amp;#39;t send them the model because then our IP walks out the door.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve looked into homomorphic encryption but the performance overhead is insane, like 10000x slower. Federated learning doesn&amp;#39;t really solve the inference problem. Secure multiparty computation gets complex fast and still has performance issues.&lt;/p&gt;\n\n&lt;p&gt;Recently started exploring TEE-based solutions where you can run inference inside a hardware-secured enclave. The performance hit is supposedly only around 5-10% which actually seems reasonable. Intel SGX, AWS Nitro Enclaves, and now nvidia has some confidential compute stuff for GPUs.&lt;/p&gt;\n\n&lt;p&gt;Has anyone actually deployed this in production? What was your experience with attestation, key management, and dealing with the whole Intel discontinuing SGX remote attestation thing? Also curious if anyone&amp;#39;s tried the newer TDX or SEV approaches.&lt;/p&gt;\n\n&lt;p&gt;The compliance team is breathing down my neck because we need something that&amp;#39;s not just secure but provably secure with cryptographic attestations. Would love to hear war stories from anyone who&amp;#39;s been down this road.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"yenoh2025","url":"https://www.reddit.com/r/MachineLearning/comments/1ni24y3/d_running_confidential_ai_inference_on_client/","domain":"self.MachineLearning","score":5,"num_comments":12,"created_utc":1757980225,"thumbnail":null},{"id":"1ni187r","subreddit":"MachineLearning","title":"[D] AAAI 2026 Social Impact track","selftext":"Has anybody heard anything from the social impact track? They were supposed to be out on the 8th, but nobody has heard anything, so I thought they might release it alongside the main track. But we are still waiting.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anybody heard anything from the social impact track? They were supposed to be out on the 8th, but nobody has heard anything, so I thought they might release it alongside the main track. But we are still waiting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Plz_Give_Me_A_Job","url":"https://www.reddit.com/r/MachineLearning/comments/1ni187r/d_aaai_2026_social_impact_track/","domain":"self.MachineLearning","score":7,"num_comments":13,"created_utc":1757977849,"thumbnail":null},{"id":"1nhzngh","subreddit":"MachineLearning","title":"[D] The conference reviewing system is trash.","selftext":"My submission to AAAI just got rejected. The reviews didn't make any sense: lack of novelty, insufficient experiments, not clear written ... \n\n  \nThese descriptions can be used for any papers in the world. The reviewers are not responsible at all and the only thing they want to do is to reject my paper.\n\n  \nAnd it is simply because I am doing the same topic as they are working!.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My submission to AAAI just got rejected. The reviews didn&amp;#39;t make any sense: lack of novelty, insufficient experiments, not clear written ... &lt;/p&gt;\n\n&lt;p&gt;These descriptions can be used for any papers in the world. The reviewers are not responsible at all and the only thing they want to do is to reject my paper.&lt;/p&gt;\n\n&lt;p&gt;And it is simply because I am doing the same topic as they are working!.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Dangerous-Hat1402","url":"https://www.reddit.com/r/MachineLearning/comments/1nhzngh/d_the_conference_reviewing_system_is_trash/","domain":"self.MachineLearning","score":117,"num_comments":49,"created_utc":1757973917,"thumbnail":null},{"id":"1nhyanm","subreddit":"MachineLearning","title":"[D] Any comments of AAAI Review process?","selftext":"One of the reviewer mentioning weaknesses of my paper which is all included in the paper and give 3 reject, while other reviewer gives me 6,6 and I got rejected.\n\nI am really frustrated that I cannot rebut such review and see this type of review","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the reviewer mentioning weaknesses of my paper which is all included in the paper and give 3 reject, while other reviewer gives me 6,6 and I got rejected.&lt;/p&gt;\n\n&lt;p&gt;I am really frustrated that I cannot rebut such review and see this type of review&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"JicamaNormal927","url":"https://www.reddit.com/r/MachineLearning/comments/1nhyanm/d_any_comments_of_aaai_review_process/","domain":"self.MachineLearning","score":29,"num_comments":23,"created_utc":1757970625,"thumbnail":null},{"id":"1nhvv90","subreddit":"MachineLearning","title":"[D] The quality of AAAI reviews is atrocious","selftext":"Never have I seen such low-quality reviews from an A\\* conference. I understand that there was a record number of submissions, but come on. A lot of issues mentioned in the reviews can be answered by actually reading the main text. The reviews also lack so much detail to the point where it's not even constructive criticism, but rather a bunch of nitpicky reasons for rejection. AAAI needs to do better.","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Never have I seen such low-quality reviews from an A* conference. I understand that there was a record number of submissions, but come on. A lot of issues mentioned in the reviews can be answered by actually reading the main text. The reviews also lack so much detail to the point where it&amp;#39;s not even constructive criticism, but rather a bunch of nitpicky reasons for rejection. AAAI needs to do better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Zapin6","url":"https://www.reddit.com/r/MachineLearning/comments/1nhvv90/d_the_quality_of_aaai_reviews_is_atrocious/","domain":"self.MachineLearning","score":161,"num_comments":89,"created_utc":1757965236,"thumbnail":null},{"id":"1nhpwwn","subreddit":"MachineLearning","title":"[D]AAAI 2026 phase1","selftext":"I’ve seen a strange situation that many papers which got high scores like 6 6 7, 6 7 7 even 6 7 8 are rejected, but some like 4 5 6 even 2 3 are passed. Do anyone know what happened?","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I’ve seen a strange situation that many papers which got high scores like 6 6 7, 6 7 7 even 6 7 8 are rejected, but some like 4 5 6 even 2 3 are passed. Do anyone know what happened?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"Small_Bb","url":"https://www.reddit.com/r/MachineLearning/comments/1nhpwwn/daaai_2026_phase1/","domain":"self.MachineLearning","score":73,"num_comments":227,"created_utc":1757952148,"thumbnail":null},{"id":"1nhp54q","subreddit":"MachineLearning","title":"[R] r-rpe: beyond openai’s rl-hf — hedging ↓60% in eval-only tests","selftext":"openai built rl-hf on the *animal* reward prediction error—outcome-only, scalarized, blind to anticipation. it works, but it locks models into pleasing and hedging.\n\nr-rpe is the missing half: an identity-projected reward prediction error based on the model of a conscious being. it adds a pre-action appraisal channel, aligning outputs with narrative identity instead of just outcomes.\n\nin eval-only tests (tinyllama-1.1b, qwen2.5-1.5b):  \n— hedging reduced by &gt;60%  \n— framing robustness improved  \n— ablations confirm the anticipatory channel is what drives it\n\nthis is not a tweak. it’s the complete form of prediction error once aligned with conscious appraisal.\n\nlinks are filtered here—if you want the preprint and data, just google Louis J. LU and click the orcid profile (0009-0002-8071-1584)","selftext_html":"&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;openai built rl-hf on the &lt;em&gt;animal&lt;/em&gt; reward prediction error—outcome-only, scalarized, blind to anticipation. it works, but it locks models into pleasing and hedging.&lt;/p&gt;\n\n&lt;p&gt;r-rpe is the missing half: an identity-projected reward prediction error based on the model of a conscious being. it adds a pre-action appraisal channel, aligning outputs with narrative identity instead of just outcomes.&lt;/p&gt;\n\n&lt;p&gt;in eval-only tests (tinyllama-1.1b, qwen2.5-1.5b):&lt;br/&gt;\n— hedging reduced by &amp;gt;60%&lt;br/&gt;\n— framing robustness improved&lt;br/&gt;\n— ablations confirm the anticipatory channel is what drives it&lt;/p&gt;\n\n&lt;p&gt;this is not a tweak. it’s the complete form of prediction error once aligned with conscious appraisal.&lt;/p&gt;\n\n&lt;p&gt;links are filtered here—if you want the preprint and data, just google Louis J. LU and click the orcid profile (0009-0002-8071-1584)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;","author":"chicken1414","url":"https://www.reddit.com/r/MachineLearning/comments/1nhp54q/r_rrpe_beyond_openais_rlhf_hedging_60_in_evalonly/","domain":"self.MachineLearning","score":0,"num_comments":2,"created_utc":1757950459,"thumbnail":null}],"partial":false}],"fetched_at":1758552727429}