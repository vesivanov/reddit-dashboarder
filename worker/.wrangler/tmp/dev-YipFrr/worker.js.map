{
  "version": 3,
  "sources": ["../bundle-wQgKdZ/strip-cf-connecting-ip-header.js", "../../../worker.js", "../../../node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts", "../../../node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts", "../bundle-wQgKdZ/middleware-insertion-facade.js", "../../../node_modules/wrangler/templates/middleware/common.ts", "../bundle-wQgKdZ/middleware-loader.entry.ts"],
  "sourceRoot": "/Users/vesivanov/Documents/Code/reddit dashboard/worker/.wrangler/tmp/dev-YipFrr",
  "sourcesContent": ["function stripCfConnectingIPHeader(input, init) {\n\tconst request = new Request(input, init);\n\trequest.headers.delete(\"CF-Connecting-IP\");\n\treturn request;\n}\n\nglobalThis.fetch = new Proxy(globalThis.fetch, {\n\tapply(target, thisArg, argArray) {\n\t\treturn Reflect.apply(target, thisArg, [\n\t\t\tstripCfConnectingIPHeader.apply(null, argArray),\n\t\t]);\n\t},\n});\n", "// Cloudflare Worker v5 \u2014 Reddit multi-day paginator + resilient fetching + CORS\n// Usage example:\n//   GET /api?subs=programming,technology&mode=new&days=3&limit=100&max_pages=30\n// Notes:\n//   - Use mode=new for time-complete coverage (paginates until cutoff or page cap)\n//   - days: 1 | 3 | 7 (clamped to 1..7)\n//   - limit: 5..25 (Reddit max page size is ~100, but we use smaller for stability)\n//   - max_pages default 2 (safety cap per subreddit). Increase carefully if needed.\n\n// Polite User-Agent + small retry/backoff helper\nconst UA = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36';\n\nfunction sleep(ms) { return new Promise(r => setTimeout(r, ms)); }\n\nasync function fetchJSON(url, { tries = 3, baseDelay = 400 } = {}) {\n  let attempt = 0, lastErr;\n  while (attempt < tries) {\n    try {\n      // Add timeout to prevent hanging\n      const controller = new AbortController();\n      const timeoutId = setTimeout(() => controller.abort(), 10000);\n      \n      const res = await fetch(url, { \n        headers: { 'User-Agent': UA },\n        signal: controller.signal\n      });\n      clearTimeout(timeoutId);\n      \n      const text = await res.text(); // Reddit sometimes returns HTML rate pages\n      \n      // Handle rate limiting specifically\n      if (res.status === 429) {\n        throw new Error(`Rate limited by Reddit: ${text.slice(0,120)}`);\n      }\n      \n      if (!res.ok) throw new Error(`Upstream ${res.status}: ${text.slice(0,120)}`);\n      \n      // Check if response is HTML (rate limit page)\n      if (text.includes('Too Many Requests') || text.includes('<!doctype html>')) {\n        throw new Error('Reddit is rate limiting requests. Please wait a few minutes and try again. Consider using Reddit OAuth for higher limits.');\n      }\n      \n      // try parse JSON\n      try { return JSON.parse(text); } catch { throw new Error('Invalid JSON body'); }\n    } catch (e) {\n      lastErr = e;\n      attempt++;\n      // backoff with jitter (esp. on 429/5xx)\n      const delay = baseDelay * Math.pow(2, attempt-1) + Math.random()*250;\n      await sleep(delay);\n    }\n  }\n  throw lastErr || new Error('fetchJSON failed');\n}\n\n// run a list of async tasks with limited concurrency\nasync function runWithConcurrency(tasks, limit = 3) {\n  const results = new Array(tasks.length);\n  let next = 0;\n  async function worker() {\n    while (next < tasks.length) {\n      const i = next++;\n      try { results[i] = await tasks[i](); }\n      catch (e) { results[i] = { error: e.message }; }\n    }\n  }\n  const pool = Array.from({ length: Math.min(limit, tasks.length) }, worker);\n  await Promise.all(pool);\n  return results;\n}\n\nexport default {\n  async fetch(request, env, ctx) {\n    if (request.method === 'OPTIONS') {\n      return withCORS(new Response(null, { status: 204 }));\n    }\n\n    const url = new URL(request.url);\n    if (url.pathname !== '/api') {\n      return withCORS(new Response('Not Found', { status: 404 }));\n    }\n\n    const subs = (url.searchParams.get('subs') || '')\n      .split(',')\n      .map(s => s.trim())\n      .filter(Boolean);\n    const mode = (url.searchParams.get('mode') || 'new').toLowerCase();\n    const time = url.searchParams.get('time') || 'day';\n    const days = clampInt(url.searchParams.get('days'), 1, 7, 1);\n    const limit = clampInt(url.searchParams.get('limit'), 25, 100, 100);\n    const maxPages = clampInt(url.searchParams.get('max_pages'), 1, 10, 5);\n\n    if (!subs.length) {\n      return respond({ error: 'Missing subs param' }, 400);\n    }\n\n    const sortedSubs = [...subs].sort();\n    // Temporarily disabled caching to test\n    // const cacheUrl = new URL(request.url);\n    // cacheUrl.searchParams.set('subs', sortedSubs.join(','));\n    // const cacheKey = new Request(cacheUrl.toString(), request);\n    // const cache = caches.default;\n    // const cached = await cache.match(cacheKey);\n    // if (cached) {\n    //   return withCORS(cached);\n    // }\n\n    const cutoff = Math.floor(Date.now() / 1000) - days * 86400;\n    \n    // Create tasks for each subreddit with concurrency control\n    const tasks = subs.map(sub => async () => {\n      try {\n        // meta (about.json)\n        const about = await fetchJSON(`https://www.reddit.com/r/${encodeURIComponent(sub)}/about.json`);\n        const meta = about?.data ? {\n          subscribers: about.data.subscribers || null,\n          active_user_count: about.data.active_user_count || about.data.accounts_active || null,\n          title: about.data.title || null,\n          icon_img: about.data.icon_img || null,\n          description: about.data.public_description || about.data.description || '',\n        } : null;\n\n        if (mode === 'top') {\n          const top = await fetchJSON(`https://www.reddit.com/r/${encodeURIComponent(sub)}/top.json?t=${encodeURIComponent(time)}&limit=${limit}&raw_json=1`);\n          return { subreddit: sub, meta, posts: normalize(top), partial: false };\n        }\n\n        // mode === 'new' with pagination + tiny delay between pages\n        let after = '';\n        let page = 0;\n        const collected = [];\n        while (page < maxPages) {\n          const ep = `https://www.reddit.com/r/${encodeURIComponent(sub)}/new.json?limit=${limit}${after ? `&after=${after}` : ''}&raw_json=1`;\n          const json = await fetchJSON(ep);\n          const posts = normalize(json);\n          if (!posts.length) break;\n\n          for (const p of posts) if ((p.created_utc || 0) >= cutoff) collected.push(p);\n\n          after = json?.data?.after || '';\n          page += 1;\n\n          const oldest = posts[posts.length - 1];\n          if (!after || !oldest || oldest.created_utc < cutoff) break;\n\n          // small pause to be nice to Reddit\n          await sleep(250 + Math.random() * 250);\n        }\n        const capped = page >= maxPages;\n        let partial = false;\n        if (capped && collected.length) {\n          const oldest = collected[collected.length - 1];\n          if ((oldest.created_utc || 0) >= cutoff) partial = true;\n        }\n        return { subreddit: sub, meta, posts: collected, partial };\n      } catch (e) {\n        return { subreddit: sub, error: e.message, posts: [], partial: false };\n      }\n    });\n\n    const perSubResults = await runWithConcurrency(tasks, 3);\n    const results = perSubResults;\n\n    const body = JSON.stringify({\n      mode,\n      time,\n      days,\n      limit,\n      max_pages: maxPages,\n      results,\n      fetched_at: Date.now(),\n    });\n\n    const response = new Response(body, {\n      status: 200,\n      headers: {\n        'Content-Type': 'application/json; charset=utf-8',\n        'Cache-Control': 'public, max-age=0, s-maxage=600',\n      },\n    });\n    // ctx.waitUntil(cache.put(cacheKey, response.clone()));\n    return withCORS(response);\n  },\n};\n\n\nfunction normalize(data) {\n  const children = data?.data?.children || [];\n  return children.map(child => {\n    const post = child.data || {};\n    return {\n      id: post.id,\n      subreddit: post.subreddit,\n      title: post.title,\n      selftext: post.selftext || '',\n      selftext_html: post.selftext_html || '',\n      author: post.author,\n      url: `https://www.reddit.com${post.permalink}`,\n      domain: post.domain,\n      score: post.score,\n      num_comments: post.num_comments,\n      created_utc: post.created_utc,\n      thumbnail: validThumb(post.thumbnail) ? post.thumbnail : null,\n    };\n  });\n}\n\nfunction validThumb(thumbnail) {\n  if (!thumbnail) return false;\n  return !['self', 'default', 'nsfw', 'image', 'spoiler'].includes(thumbnail);\n}\n\nfunction clampInt(value, min, max, fallback) {\n  const parsed = parseInt(value || '', 10);\n  if (Number.isFinite(parsed)) {\n    return Math.max(min, Math.min(max, parsed));\n  }\n  return fallback;\n}\n\nfunction withCORS(resp) {\n  const headers = new Headers(resp.headers);\n  headers.set('Access-Control-Allow-Origin', '*');\n  headers.set('Access-Control-Allow-Methods', 'GET, OPTIONS');\n  headers.set('Access-Control-Allow-Headers', 'Content-Type');\n  return new Response(resp.body, { status: resp.status, headers });\n}\n\nfunction respond(obj, status = 200) {\n  return withCORS(new Response(JSON.stringify(obj), {\n    status,\n    headers: { 'Content-Type': 'application/json' },\n  }));\n}\n", "import type { Middleware } from \"./common\";\n\nconst drainBody: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} finally {\n\t\ttry {\n\t\t\tif (request.body !== null && !request.bodyUsed) {\n\t\t\t\tconst reader = request.body.getReader();\n\t\t\t\twhile (!(await reader.read()).done) {}\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(\"Failed to drain the unused request body.\", e);\n\t\t}\n\t}\n};\n\nexport default drainBody;\n", "import type { Middleware } from \"./common\";\n\ninterface JsonError {\n\tmessage?: string;\n\tname?: string;\n\tstack?: string;\n\tcause?: JsonError;\n}\n\nfunction reduceError(e: any): JsonError {\n\treturn {\n\t\tname: e?.name,\n\t\tmessage: e?.message ?? String(e),\n\t\tstack: e?.stack,\n\t\tcause: e?.cause === undefined ? undefined : reduceError(e.cause),\n\t};\n}\n\n// See comment in `bundle.ts` for details on why this is needed\nconst jsonError: Middleware = async (request, env, _ctx, middlewareCtx) => {\n\ttry {\n\t\treturn await middlewareCtx.next(request, env);\n\t} catch (e: any) {\n\t\tconst error = reduceError(e);\n\t\treturn Response.json(error, {\n\t\t\tstatus: 500,\n\t\t\theaders: { \"MF-Experimental-Error-Stack\": \"true\" },\n\t\t});\n\t}\n};\n\nexport default jsonError;\n", "\t\t\t\timport worker, * as OTHER_EXPORTS from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/worker.js\";\n\t\t\t\timport * as __MIDDLEWARE_0__ from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/node_modules/wrangler/templates/middleware/middleware-ensure-req-body-drained.ts\";\nimport * as __MIDDLEWARE_1__ from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/node_modules/wrangler/templates/middleware/middleware-miniflare3-json-error.ts\";\n\n\t\t\t\texport * from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/worker.js\";\n\n\t\t\t\texport const __INTERNAL_WRANGLER_MIDDLEWARE__ = [\n\t\t\t\t\t\n\t\t\t\t\t__MIDDLEWARE_0__.default,__MIDDLEWARE_1__.default\n\t\t\t\t]\n\t\t\t\texport default worker;", "export type Awaitable<T> = T | Promise<T>;\n// TODO: allow dispatching more events?\nexport type Dispatcher = (\n\ttype: \"scheduled\",\n\tinit: { cron?: string }\n) => Awaitable<void>;\n\nexport type IncomingRequest = Request<\n\tunknown,\n\tIncomingRequestCfProperties<unknown>\n>;\n\nexport interface MiddlewareContext {\n\tdispatch: Dispatcher;\n\tnext(request: IncomingRequest, env: any): Awaitable<Response>;\n}\n\nexport type Middleware = (\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tmiddlewareCtx: MiddlewareContext\n) => Awaitable<Response>;\n\nconst __facade_middleware__: Middleware[] = [];\n\n// The register functions allow for the insertion of one or many middleware,\n// We register internal middleware first in the stack, but have no way of controlling\n// the order that addMiddleware is run in service workers so need an internal function.\nexport function __facade_register__(...args: (Middleware | Middleware[])[]) {\n\t__facade_middleware__.push(...args.flat());\n}\nexport function __facade_registerInternal__(\n\t...args: (Middleware | Middleware[])[]\n) {\n\t__facade_middleware__.unshift(...args.flat());\n}\n\nfunction __facade_invokeChain__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tmiddlewareChain: Middleware[]\n): Awaitable<Response> {\n\tconst [head, ...tail] = middlewareChain;\n\tconst middlewareCtx: MiddlewareContext = {\n\t\tdispatch,\n\t\tnext(newRequest, newEnv) {\n\t\t\treturn __facade_invokeChain__(newRequest, newEnv, ctx, dispatch, tail);\n\t\t},\n\t};\n\treturn head(request, env, ctx, middlewareCtx);\n}\n\nexport function __facade_invoke__(\n\trequest: IncomingRequest,\n\tenv: any,\n\tctx: ExecutionContext,\n\tdispatch: Dispatcher,\n\tfinalMiddleware: Middleware\n): Awaitable<Response> {\n\treturn __facade_invokeChain__(request, env, ctx, dispatch, [\n\t\t...__facade_middleware__,\n\t\tfinalMiddleware,\n\t]);\n}\n", "// This loads all middlewares exposed on the middleware object and then starts\n// the invocation chain. The big idea is that we can add these to the middleware\n// export dynamically through wrangler, or we can potentially let users directly\n// add them as a sort of \"plugin\" system.\n\nimport ENTRY, { __INTERNAL_WRANGLER_MIDDLEWARE__ } from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/.wrangler/tmp/bundle-wQgKdZ/middleware-insertion-facade.js\";\nimport { __facade_invoke__, __facade_register__, Dispatcher } from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/node_modules/wrangler/templates/middleware/common.ts\";\nimport type { WorkerEntrypointConstructor } from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/.wrangler/tmp/bundle-wQgKdZ/middleware-insertion-facade.js\";\n\n// Preserve all the exports from the worker\nexport * from \"/Users/vesivanov/Documents/Code/reddit dashboard/worker/.wrangler/tmp/bundle-wQgKdZ/middleware-insertion-facade.js\";\n\nclass __Facade_ScheduledController__ implements ScheduledController {\n\treadonly #noRetry: ScheduledController[\"noRetry\"];\n\n\tconstructor(\n\t\treadonly scheduledTime: number,\n\t\treadonly cron: string,\n\t\tnoRetry: ScheduledController[\"noRetry\"]\n\t) {\n\t\tthis.#noRetry = noRetry;\n\t}\n\n\tnoRetry() {\n\t\tif (!(this instanceof __Facade_ScheduledController__)) {\n\t\t\tthrow new TypeError(\"Illegal invocation\");\n\t\t}\n\t\t// Need to call native method immediately in case uncaught error thrown\n\t\tthis.#noRetry();\n\t}\n}\n\nfunction wrapExportedHandler(worker: ExportedHandler): ExportedHandler {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn worker;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\tconst fetchDispatcher: ExportedHandlerFetchHandler = function (\n\t\trequest,\n\t\tenv,\n\t\tctx\n\t) {\n\t\tif (worker.fetch === undefined) {\n\t\t\tthrow new Error(\"Handler does not export a fetch() function.\");\n\t\t}\n\t\treturn worker.fetch(request, env, ctx);\n\t};\n\n\treturn {\n\t\t...worker,\n\t\tfetch(request, env, ctx) {\n\t\t\tconst dispatcher: Dispatcher = function (type, init) {\n\t\t\t\tif (type === \"scheduled\" && worker.scheduled !== undefined) {\n\t\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\t\tDate.now(),\n\t\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t\t() => {}\n\t\t\t\t\t);\n\t\t\t\t\treturn worker.scheduled(controller, env, ctx);\n\t\t\t\t}\n\t\t\t};\n\t\t\treturn __facade_invoke__(request, env, ctx, dispatcher, fetchDispatcher);\n\t\t},\n\t};\n}\n\nfunction wrapWorkerEntrypoint(\n\tklass: WorkerEntrypointConstructor\n): WorkerEntrypointConstructor {\n\t// If we don't have any middleware defined, just return the handler as is\n\tif (\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__ === undefined ||\n\t\t__INTERNAL_WRANGLER_MIDDLEWARE__.length === 0\n\t) {\n\t\treturn klass;\n\t}\n\t// Otherwise, register all middleware once\n\tfor (const middleware of __INTERNAL_WRANGLER_MIDDLEWARE__) {\n\t\t__facade_register__(middleware);\n\t}\n\n\t// `extend`ing `klass` here so other RPC methods remain callable\n\treturn class extends klass {\n\t\t#fetchDispatcher: ExportedHandlerFetchHandler<Record<string, unknown>> = (\n\t\t\trequest,\n\t\t\tenv,\n\t\t\tctx\n\t\t) => {\n\t\t\tthis.env = env;\n\t\t\tthis.ctx = ctx;\n\t\t\tif (super.fetch === undefined) {\n\t\t\t\tthrow new Error(\"Entrypoint class does not define a fetch() function.\");\n\t\t\t}\n\t\t\treturn super.fetch(request);\n\t\t};\n\n\t\t#dispatcher: Dispatcher = (type, init) => {\n\t\t\tif (type === \"scheduled\" && super.scheduled !== undefined) {\n\t\t\t\tconst controller = new __Facade_ScheduledController__(\n\t\t\t\t\tDate.now(),\n\t\t\t\t\tinit.cron ?? \"\",\n\t\t\t\t\t() => {}\n\t\t\t\t);\n\t\t\t\treturn super.scheduled(controller);\n\t\t\t}\n\t\t};\n\n\t\tfetch(request: Request<unknown, IncomingRequestCfProperties>) {\n\t\t\treturn __facade_invoke__(\n\t\t\t\trequest,\n\t\t\t\tthis.env,\n\t\t\t\tthis.ctx,\n\t\t\t\tthis.#dispatcher,\n\t\t\t\tthis.#fetchDispatcher\n\t\t\t);\n\t\t}\n\t};\n}\n\nlet WRAPPED_ENTRY: ExportedHandler | WorkerEntrypointConstructor | undefined;\nif (typeof ENTRY === \"object\") {\n\tWRAPPED_ENTRY = wrapExportedHandler(ENTRY);\n} else if (typeof ENTRY === \"function\") {\n\tWRAPPED_ENTRY = wrapWorkerEntrypoint(ENTRY);\n}\nexport default WRAPPED_ENTRY;\n"],
  "mappings": ";;;;AAAA,SAAS,0BAA0B,OAAO,MAAM;AAC/C,QAAM,UAAU,IAAI,QAAQ,OAAO,IAAI;AACvC,UAAQ,QAAQ,OAAO,kBAAkB;AACzC,SAAO;AACR;AAJS;AAMT,WAAW,QAAQ,IAAI,MAAM,WAAW,OAAO;AAAA,EAC9C,MAAM,QAAQ,SAAS,UAAU;AAChC,WAAO,QAAQ,MAAM,QAAQ,SAAS;AAAA,MACrC,0BAA0B,MAAM,MAAM,QAAQ;AAAA,IAC/C,CAAC;AAAA,EACF;AACD,CAAC;;;ACFD,IAAM,KAAK;AAEX,SAAS,MAAM,IAAI;AAAE,SAAO,IAAI,QAAQ,OAAK,WAAW,GAAG,EAAE,CAAC;AAAG;AAAxD;AAET,eAAe,UAAU,KAAK,EAAE,QAAQ,GAAG,YAAY,IAAI,IAAI,CAAC,GAAG;AACjE,MAAI,UAAU,GAAG;AACjB,SAAO,UAAU,OAAO;AACtB,QAAI;AAEF,YAAM,aAAa,IAAI,gBAAgB;AACvC,YAAM,YAAY,WAAW,MAAM,WAAW,MAAM,GAAG,GAAK;AAE5D,YAAM,MAAM,MAAM,MAAM,KAAK;AAAA,QAC3B,SAAS,EAAE,cAAc,GAAG;AAAA,QAC5B,QAAQ,WAAW;AAAA,MACrB,CAAC;AACD,mBAAa,SAAS;AAEtB,YAAM,OAAO,MAAM,IAAI,KAAK;AAG5B,UAAI,IAAI,WAAW,KAAK;AACtB,cAAM,IAAI,MAAM,2BAA2B,KAAK,MAAM,GAAE,GAAG,GAAG;AAAA,MAChE;AAEA,UAAI,CAAC,IAAI;AAAI,cAAM,IAAI,MAAM,YAAY,IAAI,WAAW,KAAK,MAAM,GAAE,GAAG,GAAG;AAG3E,UAAI,KAAK,SAAS,mBAAmB,KAAK,KAAK,SAAS,iBAAiB,GAAG;AAC1E,cAAM,IAAI,MAAM,2HAA2H;AAAA,MAC7I;AAGA,UAAI;AAAE,eAAO,KAAK,MAAM,IAAI;AAAA,MAAG,QAAE;AAAQ,cAAM,IAAI,MAAM,mBAAmB;AAAA,MAAG;AAAA,IACjF,SAAS,GAAP;AACA,gBAAU;AACV;AAEA,YAAM,QAAQ,YAAY,KAAK,IAAI,GAAG,UAAQ,CAAC,IAAI,KAAK,OAAO,IAAE;AACjE,YAAM,MAAM,KAAK;AAAA,IACnB;AAAA,EACF;AACA,QAAM,WAAW,IAAI,MAAM,kBAAkB;AAC/C;AAvCe;AA0Cf,eAAe,mBAAmB,OAAO,QAAQ,GAAG;AAClD,QAAM,UAAU,IAAI,MAAM,MAAM,MAAM;AACtC,MAAI,OAAO;AACX,iBAAe,SAAS;AACtB,WAAO,OAAO,MAAM,QAAQ;AAC1B,YAAM,IAAI;AACV,UAAI;AAAE,gBAAQ,CAAC,IAAI,MAAM,MAAM,CAAC,EAAE;AAAA,MAAG,SAC9B,GAAP;AAAY,gBAAQ,CAAC,IAAI,EAAE,OAAO,EAAE,QAAQ;AAAA,MAAG;AAAA,IACjD;AAAA,EACF;AANe;AAOf,QAAM,OAAO,MAAM,KAAK,EAAE,QAAQ,KAAK,IAAI,OAAO,MAAM,MAAM,EAAE,GAAG,MAAM;AACzE,QAAM,QAAQ,IAAI,IAAI;AACtB,SAAO;AACT;AAbe;AAef,IAAO,iBAAQ;AAAA,EACb,MAAM,MAAM,SAAS,KAAK,KAAK;AAC7B,QAAI,QAAQ,WAAW,WAAW;AAChC,aAAO,SAAS,IAAI,SAAS,MAAM,EAAE,QAAQ,IAAI,CAAC,CAAC;AAAA,IACrD;AAEA,UAAM,MAAM,IAAI,IAAI,QAAQ,GAAG;AAC/B,QAAI,IAAI,aAAa,QAAQ;AAC3B,aAAO,SAAS,IAAI,SAAS,aAAa,EAAE,QAAQ,IAAI,CAAC,CAAC;AAAA,IAC5D;AAEA,UAAM,QAAQ,IAAI,aAAa,IAAI,MAAM,KAAK,IAC3C,MAAM,GAAG,EACT,IAAI,OAAK,EAAE,KAAK,CAAC,EACjB,OAAO,OAAO;AACjB,UAAM,QAAQ,IAAI,aAAa,IAAI,MAAM,KAAK,OAAO,YAAY;AACjE,UAAM,OAAO,IAAI,aAAa,IAAI,MAAM,KAAK;AAC7C,UAAM,OAAO,SAAS,IAAI,aAAa,IAAI,MAAM,GAAG,GAAG,GAAG,CAAC;AAC3D,UAAM,QAAQ,SAAS,IAAI,aAAa,IAAI,OAAO,GAAG,IAAI,KAAK,GAAG;AAClE,UAAM,WAAW,SAAS,IAAI,aAAa,IAAI,WAAW,GAAG,GAAG,IAAI,CAAC;AAErE,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO,QAAQ,EAAE,OAAO,qBAAqB,GAAG,GAAG;AAAA,IACrD;AAEA,UAAM,aAAa,CAAC,GAAG,IAAI,EAAE,KAAK;AAWlC,UAAM,SAAS,KAAK,MAAM,KAAK,IAAI,IAAI,GAAI,IAAI,OAAO;AAGtD,UAAM,QAAQ,KAAK,IAAI,SAAO,YAAY;AACxC,UAAI;AAEF,cAAM,QAAQ,MAAM,UAAU,4BAA4B,mBAAmB,GAAG,cAAc;AAC9F,cAAM,OAAO,OAAO,OAAO;AAAA,UACzB,aAAa,MAAM,KAAK,eAAe;AAAA,UACvC,mBAAmB,MAAM,KAAK,qBAAqB,MAAM,KAAK,mBAAmB;AAAA,UACjF,OAAO,MAAM,KAAK,SAAS;AAAA,UAC3B,UAAU,MAAM,KAAK,YAAY;AAAA,UACjC,aAAa,MAAM,KAAK,sBAAsB,MAAM,KAAK,eAAe;AAAA,QAC1E,IAAI;AAEJ,YAAI,SAAS,OAAO;AAClB,gBAAM,MAAM,MAAM,UAAU,4BAA4B,mBAAmB,GAAG,gBAAgB,mBAAmB,IAAI,WAAW,kBAAkB;AAClJ,iBAAO,EAAE,WAAW,KAAK,MAAM,OAAO,UAAU,GAAG,GAAG,SAAS,MAAM;AAAA,QACvE;AAGA,YAAI,QAAQ;AACZ,YAAI,OAAO;AACX,cAAM,YAAY,CAAC;AACnB,eAAO,OAAO,UAAU;AACtB,gBAAM,KAAK,4BAA4B,mBAAmB,GAAG,oBAAoB,QAAQ,QAAQ,UAAU,UAAU;AACrH,gBAAM,OAAO,MAAM,UAAU,EAAE;AAC/B,gBAAM,QAAQ,UAAU,IAAI;AAC5B,cAAI,CAAC,MAAM;AAAQ;AAEnB,qBAAW,KAAK;AAAO,iBAAK,EAAE,eAAe,MAAM;AAAQ,wBAAU,KAAK,CAAC;AAE3E,kBAAQ,MAAM,MAAM,SAAS;AAC7B,kBAAQ;AAER,gBAAM,SAAS,MAAM,MAAM,SAAS,CAAC;AACrC,cAAI,CAAC,SAAS,CAAC,UAAU,OAAO,cAAc;AAAQ;AAGtD,gBAAM,MAAM,MAAM,KAAK,OAAO,IAAI,GAAG;AAAA,QACvC;AACA,cAAM,SAAS,QAAQ;AACvB,YAAI,UAAU;AACd,YAAI,UAAU,UAAU,QAAQ;AAC9B,gBAAM,SAAS,UAAU,UAAU,SAAS,CAAC;AAC7C,eAAK,OAAO,eAAe,MAAM;AAAQ,sBAAU;AAAA,QACrD;AACA,eAAO,EAAE,WAAW,KAAK,MAAM,OAAO,WAAW,QAAQ;AAAA,MAC3D,SAAS,GAAP;AACA,eAAO,EAAE,WAAW,KAAK,OAAO,EAAE,SAAS,OAAO,CAAC,GAAG,SAAS,MAAM;AAAA,MACvE;AAAA,IACF,CAAC;AAED,UAAM,gBAAgB,MAAM,mBAAmB,OAAO,CAAC;AACvD,UAAM,UAAU;AAEhB,UAAM,OAAO,KAAK,UAAU;AAAA,MAC1B;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,WAAW;AAAA,MACX;AAAA,MACA,YAAY,KAAK,IAAI;AAAA,IACvB,CAAC;AAED,UAAM,WAAW,IAAI,SAAS,MAAM;AAAA,MAClC,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,QAChB,iBAAiB;AAAA,MACnB;AAAA,IACF,CAAC;AAED,WAAO,SAAS,QAAQ;AAAA,EAC1B;AACF;AAGA,SAAS,UAAU,MAAM;AACvB,QAAM,WAAW,MAAM,MAAM,YAAY,CAAC;AAC1C,SAAO,SAAS,IAAI,WAAS;AAC3B,UAAM,OAAO,MAAM,QAAQ,CAAC;AAC5B,WAAO;AAAA,MACL,IAAI,KAAK;AAAA,MACT,WAAW,KAAK;AAAA,MAChB,OAAO,KAAK;AAAA,MACZ,UAAU,KAAK,YAAY;AAAA,MAC3B,eAAe,KAAK,iBAAiB;AAAA,MACrC,QAAQ,KAAK;AAAA,MACb,KAAK,yBAAyB,KAAK;AAAA,MACnC,QAAQ,KAAK;AAAA,MACb,OAAO,KAAK;AAAA,MACZ,cAAc,KAAK;AAAA,MACnB,aAAa,KAAK;AAAA,MAClB,WAAW,WAAW,KAAK,SAAS,IAAI,KAAK,YAAY;AAAA,IAC3D;AAAA,EACF,CAAC;AACH;AAnBS;AAqBT,SAAS,WAAW,WAAW;AAC7B,MAAI,CAAC;AAAW,WAAO;AACvB,SAAO,CAAC,CAAC,QAAQ,WAAW,QAAQ,SAAS,SAAS,EAAE,SAAS,SAAS;AAC5E;AAHS;AAKT,SAAS,SAAS,OAAO,KAAK,KAAK,UAAU;AAC3C,QAAM,SAAS,SAAS,SAAS,IAAI,EAAE;AACvC,MAAI,OAAO,SAAS,MAAM,GAAG;AAC3B,WAAO,KAAK,IAAI,KAAK,KAAK,IAAI,KAAK,MAAM,CAAC;AAAA,EAC5C;AACA,SAAO;AACT;AANS;AAQT,SAAS,SAAS,MAAM;AACtB,QAAM,UAAU,IAAI,QAAQ,KAAK,OAAO;AACxC,UAAQ,IAAI,+BAA+B,GAAG;AAC9C,UAAQ,IAAI,gCAAgC,cAAc;AAC1D,UAAQ,IAAI,gCAAgC,cAAc;AAC1D,SAAO,IAAI,SAAS,KAAK,MAAM,EAAE,QAAQ,KAAK,QAAQ,QAAQ,CAAC;AACjE;AANS;AAQT,SAAS,QAAQ,KAAK,SAAS,KAAK;AAClC,SAAO,SAAS,IAAI,SAAS,KAAK,UAAU,GAAG,GAAG;AAAA,IAChD;AAAA,IACA,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,EAChD,CAAC,CAAC;AACJ;AALS;;;AClOT,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,UAAE;AACD,QAAI;AACH,UAAI,QAAQ,SAAS,QAAQ,CAAC,QAAQ,UAAU;AAC/C,cAAM,SAAS,QAAQ,KAAK,UAAU;AACtC,eAAO,EAAE,MAAM,OAAO,KAAK,GAAG,MAAM;AAAA,QAAC;AAAA,MACtC;AAAA,IACD,SAAS,GAAP;AACD,cAAQ,MAAM,4CAA4C,CAAC;AAAA,IAC5D;AAAA,EACD;AACD,GAb8B;AAe9B,IAAO,6CAAQ;;;ACRf,SAAS,YAAY,GAAmB;AACvC,SAAO;AAAA,IACN,MAAM,GAAG;AAAA,IACT,SAAS,GAAG,WAAW,OAAO,CAAC;AAAA,IAC/B,OAAO,GAAG;AAAA,IACV,OAAO,GAAG,UAAU,SAAY,SAAY,YAAY,EAAE,KAAK;AAAA,EAChE;AACD;AAPS;AAUT,IAAM,YAAwB,8BAAO,SAAS,KAAK,MAAM,kBAAkB;AAC1E,MAAI;AACH,WAAO,MAAM,cAAc,KAAK,SAAS,GAAG;AAAA,EAC7C,SAAS,GAAP;AACD,UAAM,QAAQ,YAAY,CAAC;AAC3B,WAAO,SAAS,KAAK,OAAO;AAAA,MAC3B,QAAQ;AAAA,MACR,SAAS,EAAE,+BAA+B,OAAO;AAAA,IAClD,CAAC;AAAA,EACF;AACD,GAV8B;AAY9B,IAAO,2CAAQ;;;ACzBJ,IAAM,mCAAmC;AAAA,EAE9B;AAAA,EAAyB;AAC3C;AACA,IAAO,sCAAQ;;;ACcnB,IAAM,wBAAsC,CAAC;AAKtC,SAAS,uBAAuB,MAAqC;AAC3E,wBAAsB,KAAK,GAAG,KAAK,KAAK,CAAC;AAC1C;AAFgB;AAShB,SAAS,uBACR,SACA,KACA,KACA,UACA,iBACsB;AACtB,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AACxB,QAAM,gBAAmC;AAAA,IACxC;AAAA,IACA,KAAK,YAAY,QAAQ;AACxB,aAAO,uBAAuB,YAAY,QAAQ,KAAK,UAAU,IAAI;AAAA,IACtE;AAAA,EACD;AACA,SAAO,KAAK,SAAS,KAAK,KAAK,aAAa;AAC7C;AAfS;AAiBF,SAAS,kBACf,SACA,KACA,KACA,UACA,iBACsB;AACtB,SAAO,uBAAuB,SAAS,KAAK,KAAK,UAAU;AAAA,IAC1D,GAAG;AAAA,IACH;AAAA,EACD,CAAC;AACF;AAXgB;;;AC3ChB,IAAM,iCAAN,MAAoE;AAAA,EAGnE,YACU,eACA,MACT,SACC;AAHQ;AACA;AAGT,SAAK,WAAW;AAAA,EACjB;AAAA,EARS;AAAA,EAUT,UAAU;AACT,QAAI,EAAE,gBAAgB,iCAAiC;AACtD,YAAM,IAAI,UAAU,oBAAoB;AAAA,IACzC;AAEA,SAAK,SAAS;AAAA,EACf;AACD;AAlBM;AAoBN,SAAS,oBAAoB,QAA0C;AAEtE,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAEA,QAAM,kBAA+C,gCACpD,SACA,KACA,KACC;AACD,QAAI,OAAO,UAAU,QAAW;AAC/B,YAAM,IAAI,MAAM,6CAA6C;AAAA,IAC9D;AACA,WAAO,OAAO,MAAM,SAAS,KAAK,GAAG;AAAA,EACtC,GATqD;AAWrD,SAAO;AAAA,IACN,GAAG;AAAA,IACH,MAAM,SAAS,KAAK,KAAK;AACxB,YAAM,aAAyB,gCAAU,MAAM,MAAM;AACpD,YAAI,SAAS,eAAe,OAAO,cAAc,QAAW;AAC3D,gBAAM,aAAa,IAAI;AAAA,YACtB,KAAK,IAAI;AAAA,YACT,KAAK,QAAQ;AAAA,YACb,MAAM;AAAA,YAAC;AAAA,UACR;AACA,iBAAO,OAAO,UAAU,YAAY,KAAK,GAAG;AAAA,QAC7C;AAAA,MACD,GAT+B;AAU/B,aAAO,kBAAkB,SAAS,KAAK,KAAK,YAAY,eAAe;AAAA,IACxE;AAAA,EACD;AACD;AAxCS;AA0CT,SAAS,qBACR,OAC8B;AAE9B,MACC,qCAAqC,UACrC,iCAAiC,WAAW,GAC3C;AACD,WAAO;AAAA,EACR;AAEA,aAAW,cAAc,kCAAkC;AAC1D,wBAAoB,UAAU;AAAA,EAC/B;AAGA,SAAO,cAAc,MAAM;AAAA,IAC1B,mBAAyE,CACxE,SACA,KACA,QACI;AACJ,WAAK,MAAM;AACX,WAAK,MAAM;AACX,UAAI,MAAM,UAAU,QAAW;AAC9B,cAAM,IAAI,MAAM,sDAAsD;AAAA,MACvE;AACA,aAAO,MAAM,MAAM,OAAO;AAAA,IAC3B;AAAA,IAEA,cAA0B,CAAC,MAAM,SAAS;AACzC,UAAI,SAAS,eAAe,MAAM,cAAc,QAAW;AAC1D,cAAM,aAAa,IAAI;AAAA,UACtB,KAAK,IAAI;AAAA,UACT,KAAK,QAAQ;AAAA,UACb,MAAM;AAAA,UAAC;AAAA,QACR;AACA,eAAO,MAAM,UAAU,UAAU;AAAA,MAClC;AAAA,IACD;AAAA,IAEA,MAAM,SAAwD;AAC7D,aAAO;AAAA,QACN;AAAA,QACA,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,QACL,KAAK;AAAA,MACN;AAAA,IACD;AAAA,EACD;AACD;AAnDS;AAqDT,IAAI;AACJ,IAAI,OAAO,wCAAU,UAAU;AAC9B,kBAAgB,oBAAoB,mCAAK;AAC1C,WAAW,OAAO,wCAAU,YAAY;AACvC,kBAAgB,qBAAqB,mCAAK;AAC3C;AACA,IAAO,kCAAQ;",
  "names": []
}
